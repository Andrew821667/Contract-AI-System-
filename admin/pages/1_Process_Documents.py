"""
–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ - "–°—Ç–µ–∫–ª—è–Ω–Ω—ã–π —è—â–∏–∫"
–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –í–°–ï –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –¥–≤–∞ —Ä–µ–∂–∏–º–∞: "–ù–æ–≤—ã–π –¥–æ–≥–æ–≤–æ—Ä" –∏ "–ü–æ–¥–ø–∏—Å–∞–Ω–Ω—ã–π –¥–æ–≥–æ–≤–æ—Ä"
"""

import streamlit as st
import sys
from pathlib import Path
import asyncio
import json
import os
import tempfile
import pandas as pd
from typing import Dict, Any, List, Optional
import io
import hashlib

# Add project root to path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

st.set_page_config(
    page_title="–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ - Contract AI",
    page_icon="üìÑ",
    layout="wide"
)

st.title("üìÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
st.markdown("**–°—Ç–µ–∫–ª—è–Ω–Ω—ã–π —è—â–∏–∫:** –≤–∏–¥–Ω—ã –≤—Å–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–∞–±–æ—Ç—ã —Å–∏—Å—Ç–µ–º—ã")

st.markdown("---")


def _ensure_recommendation_state() -> None:
    """–ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –Ω–∞–ª–∏—á–∏–µ state –¥–ª—è –ø—Ä–∏–Ω—è—Ç—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π."""
    if "accepted_recommendations" not in st.session_state:
        st.session_state["accepted_recommendations"] = []
    if "accepted_recommendation_keys" not in st.session_state:
        st.session_state["accepted_recommendation_keys"] = []


def _build_recommendation_key(payload: Dict[str, Any]) -> str:
    """–î–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–ª—é—á –¥–ª—è –∑–∞—â–∏—Ç—ã –æ—Ç –¥—É–±–ª–µ–π."""
    section_number = str(payload.get("section_number", "")).strip()
    section_title = str(payload.get("section_title", "")).strip()
    source = str(payload.get("source", "")).strip()
    action_type = str(payload.get("action_type", "")).strip()
    proposed_text = str(payload.get("proposed_text", "")).strip()[:180]
    return "|".join([source, section_number, section_title, action_type, proposed_text])


def add_accepted_recommendation(payload: Dict[str, Any]) -> bool:
    """
    –î–æ–±–∞–≤–ª—è–µ—Ç –ø—Ä–∏–Ω—è—Ç—É—é —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é –≤ session_state.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True, –µ—Å–ª–∏ –∑–∞–ø–∏—Å—å –¥–æ–±–∞–≤–ª–µ–Ω–∞, –∏–Ω–∞—á–µ False (–¥—É–±–ª—å).
    """
    _ensure_recommendation_state()
    key = _build_recommendation_key(payload)
    existing_keys = st.session_state.get("accepted_recommendation_keys", [])
    if key in existing_keys:
        return False

    normalized_payload = {
        "section_number": payload.get("section_number", ""),
        "section_title": payload.get("section_title", ""),
        "original_text": payload.get("original_text", ""),
        "proposed_text": payload.get("proposed_text", ""),
        "reason": payload.get("reason", ""),
        "action_type": payload.get("action_type", "modify"),
        "priority": payload.get("priority", "optional"),
        "source": payload.get("source", "section_analysis"),
        "target": payload.get("target", "docx"),
        "rec_key": key
    }

    st.session_state["accepted_recommendations"].append(normalized_payload)
    st.session_state["accepted_recommendation_keys"] = existing_keys + [key]
    return True


def _extract_section_analysis_data(result: Any) -> Optional[Dict[str, Any]]:
    """–î–æ—Å—Ç–∞—ë—Ç –ø–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ section analysis –∏–∑ —Å—Ç–∞–¥–∏–π –æ–±—Ä–∞–±–æ—Ç–∫–∏."""
    for stage in result.stages:
        if stage.name == "section_analysis" and stage.status == "success":
            return stage.results.get("full_data")
    return None


def _risk_level_ru(level: str) -> str:
    mapping = {
        "critical": "–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π",
        "high": "–í—ã—Å–æ–∫–∏–π",
        "medium": "–°—Ä–µ–¥–Ω–∏–π",
        "low": "–ù–∏–∑–∫–∏–π",
    }
    return mapping.get(str(level).lower(), str(level))

# –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞
st.header("1Ô∏è‚É£ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞")

# –í—ã–±–æ—Ä —Ä–µ–∂–∏–º–∞ —Ä–∞–±–æ—Ç—ã
contract_mode = st.radio(
    "–†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã —Å –¥–æ–≥–æ–≤–æ—Ä–æ–º:",
    ["–ù–æ–≤—ã–π –¥–æ–≥–æ–≤–æ—Ä (Pre-Execution)", "–ü–æ–¥–ø–∏—Å–∞–Ω–Ω—ã–π –¥–æ–≥–æ–≤–æ—Ä (Post-Execution)"],
    help="**–ù–æ–≤—ã–π –¥–æ–≥–æ–≤–æ—Ä** ‚Äî –ø—Ä–∞–≤–∫–∏ –≤–Ω–æ—Å—è—Ç—Å—è –ø—Ä—è–º–æ –≤ DOCX-–¥–æ–∫—É–º–µ–Ω—Ç.\n\n"
         "**–ü–æ–¥–ø–∏—Å–∞–Ω–Ω—ã–π –¥–æ–≥–æ–≤–æ—Ä** ‚Äî –æ—Ä–∏–≥–∏–Ω–∞–ª –Ω–µ —Ç—Ä–æ–≥–∞–µ–º, —Ñ–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ—Ç–æ–∫–æ–ª —Ä–∞–∑–Ω–æ–≥–ª–∞—Å–∏–π.",
    horizontal=True
)

is_new_contract = contract_mode.startswith("–ù–æ–≤—ã–π")

uploaded_file = st.file_uploader(
    "–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª –¥–æ–≥–æ–≤–æ—Ä–∞",
    type=['pdf', 'docx', 'txt', 'xml', 'html', 'htm', 'png', 'jpg', 'jpeg'],
    help="–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è: PDF, DOCX, TXT, XML, HTML, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (—Å OCR)"
)

# –ó–∞–≥—Ä—É–∑–∫–∞ —ç—Ç–∞–ª–æ–Ω–Ω–æ–≥–æ —à–∞–±–ª–æ–Ω–∞ (Stage 2.2: Pre-Execution)
if is_new_contract:
    st.markdown("---")
    st.header("üìã –≠—Ç–∞–ª–æ–Ω–Ω—ã–π —à–∞–±–ª–æ–Ω (Playbook)")
    st.markdown("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —ç—Ç–∞–ª–æ–Ω–Ω—ã–π —à–∞–±–ª–æ–Ω –¥–æ–≥–æ–≤–æ—Ä–∞ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å —á–µ—Ä–Ω–æ–≤–∏–∫–æ–º. "
                "–°–∏—Å—Ç–µ–º–∞ –≤—ã—è–≤–∏—Ç –≤—Å–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –æ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞ –∫–æ–º–ø–∞–Ω–∏–∏.")

    template_file = st.file_uploader(
        "–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª —à–∞–±–ª–æ–Ω–∞ (—ç—Ç–∞–ª–æ–Ω)",
        type=['pdf', 'docx', 'txt', 'xml', 'html', 'htm'],
        help="–≠—Ç–∞–ª–æ–Ω–Ω—ã–π —à–∞–±–ª–æ–Ω, —Å –∫–æ—Ç–æ—Ä—ã–º –±—É–¥–µ—Ç —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å—Å—è —á–µ—Ä–Ω–æ–≤–∏–∫",
        key="template_uploader"
    )
else:
    template_file = None

def extract_text_from_file(file_path: str, file_ext: str) -> str:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞ (–¥–ª—è —à–∞–±–ª–æ–Ω–∞) —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ"""
    from src.services.text_extractor import TextExtractor
    extractor = TextExtractor(use_ocr=False)
    result = extractor.extract(file_path, file_ext)
    return result.text


async def compare_with_template_async(draft_text: str, template_text: str, contract_type: str = "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π"):
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —á–µ—Ä–Ω–æ–≤–∏–∫–∞ —Å —à–∞–±–ª–æ–Ω–æ–º"""
    from src.services.template_comparator import TemplateComparator
    import os
    from dotenv import load_dotenv

    project_root = Path(__file__).parent.parent.parent
    env_path = project_root / ".env"
    load_dotenv(env_path)

    deepseek_key = os.getenv("DEEPSEEK_API_KEY")
    openai_key = os.getenv("OPENAI_API_KEY")

    if deepseek_key:
        api_key = deepseek_key
        base_url = os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com/v1")
        model = os.getenv("DEEPSEEK_MODEL", "deepseek-chat")
    elif openai_key:
        api_key = openai_key
        base_url = None
        model = os.getenv("OPENAI_MODEL_MINI", "gpt-4o-mini")
    else:
        raise ValueError("API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω.")

    comparator = TemplateComparator(model=model, api_key=api_key, base_url=base_url)
    return await comparator.compare(draft_text, template_text, contract_type)


# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è async –æ–±—Ä–∞–±–æ—Ç–∫–∏
async def process_document_async(file_path, file_ext, use_section_analysis=False):
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º fallback"""
    from src.services.document_processor import DocumentProcessor
    import os
    from dotenv import load_dotenv

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env —Ñ–∞–π–ª–∞
    project_root = Path(__file__).parent.parent.parent
    env_path = project_root / ".env"
    load_dotenv(env_path)

    # DeepSeek ‚Äî –æ—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å (–¥–µ—à–µ–≤–ª–µ, $0.14/1M —Ç–æ–∫–µ–Ω–æ–≤)
    # GPT-4o-mini ‚Äî fallback
    deepseek_key = os.getenv("DEEPSEEK_API_KEY")
    openai_key = os.getenv("OPENAI_API_KEY")

    if deepseek_key:
        api_key = deepseek_key
        base_url = os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com/v1")
        model = os.getenv("DEEPSEEK_MODEL", "deepseek-chat")
    elif openai_key:
        api_key = openai_key
        base_url = None
        model = os.getenv("OPENAI_MODEL_MINI", "gpt-4o-mini")
    else:
        raise ValueError(
            "API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω.\n"
            "–î–æ–±–∞–≤—å—Ç–µ –≤ .env: OPENAI_API_KEY=... –∏–ª–∏ DEEPSEEK_API_KEY=..."
        )

    processor = DocumentProcessor(
        api_key=api_key,
        model=model,
        base_url=base_url,
        use_rag=False,
        use_section_analysis=use_section_analysis
    )

    result = await processor.process_document(file_path, file_ext)
    return result


def render_docx_preview(docx_bytes: bytes) -> str:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç DOCX bytes –≤ HTML —á–µ—Ä–µ–∑ mammoth –¥–ª—è –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä–∞"""
    try:
        import mammoth
        result = mammoth.convert_to_html(io.BytesIO(docx_bytes))
        html = result.value
        # –û–±–æ—Ä–∞—á–∏–≤–∞–µ–º –≤ —Å—Ç–∏–ª–∏ –¥–ª—è –ª—É—á—à–µ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        styled_html = f"""
        <div style="background: white; color: black; padding: 20px; border: 1px solid #ddd;
                    border-radius: 8px; font-family: 'Times New Roman', serif; line-height: 1.6;
                    max-height: 600px; overflow-y: auto;">
            {html}
        </div>
        """
        return styled_html
    except Exception as e:
        return f"<p style='color:red;'>–û—à–∏–±–∫–∞ –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä–∞: {e}</p>"


def get_entity_purpose(entity_type: str) -> str:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ö–û–ù–ö–†–ï–¢–ù–û–ï –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–∏ –≤ —Å–∏—Å—Ç–µ–º–µ"""
    purposes = {
        "contract_number": "üìù –ü–µ—Ä–≤–∏—á–Ω—ã–π –∫–ª—é—á –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –≤ –ë–î (—Ç–∞–±–ª–∏—Ü–∞ contracts, –ø–æ–ª–µ contract_id). –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –ø–æ–∏—Å–∫–∞ –¥–æ–≥–æ–≤–æ—Ä–∞ —á–µ—Ä–µ–∑ UI, API endpoints (/api/contracts/{id}), —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–æ–≤–æ–≥–æ –∏–º–µ–Ω–∏ –ø—Ä–∏ —ç–∫—Å–ø–æ—Ä—Ç–µ",
        "date": "üìÖ –ó–∞–ø–æ–ª–Ω—è–µ—Ç –ø–æ–ª—è: contract_date, start_date, end_date –≤ —Ç–∞–±–ª–∏—Ü–µ contracts. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è: –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π –æ —Å—Ä–æ–∫–∞—Ö (–º–æ–¥—É–ª—å notifications), —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –¥–∞—Ç–∞–º –≤ UI (—Å—Ç—Ä–∞–Ω–∏—Ü–∞ Contract List), –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç–∏ –¥–æ–≥–æ–≤–æ—Ä–∞, —Ä–∞—Å—á–µ—Ç–∞ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–æ–≥–æ–≤–æ—Ä–∞",
        "inn": "üè¢ –°–≤—è–∑—ã–≤–∞–Ω–∏–µ —Å —Ç–∞–±–ª–∏—Ü–µ–π counterparties (foreign key counterparty_inn). –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è: –∞–≤—Ç–æ–∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –∫–∞—Ä—Ç–æ—á–∫–∏ –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞, –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤ –§–ù–° —á–µ—Ä–µ–∑ API –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é, –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–æ–≤, –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∞ –≤–∑–∞–∏–º–æ—Å–≤—è–∑–µ–π –∫–æ–º–ø–∞–Ω–∏–π, —Ä–∏—Å–∫-–∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞",
        "ogrn": "üîê –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–µ–≥–∏—Ç–∏–º–Ω–æ—Å—Ç–∏ —é—Ä–ª–∏—Ü–∞ —á–µ—Ä–µ–∑ API –§–ù–°/–ï–ì–†–Æ–õ. –°–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤ counterparties.ogrn. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏, –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–∞—Ç—ã —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –∫–æ–º–ø–∞–Ω–∏–∏, –ø—Ä–æ–≤–µ—Ä–∫–∏ –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç–∏ —é—Ä–ª–∏—Ü–∞",
        "kpp": "üè¶ –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –∫–æ–º–ø–∞–Ω–∏–∏ (counterparties.kpp). –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è: –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ñ–∏–ª–∏–∞–ª–∞/–æ–±–æ—Å–æ–±–ª–µ–Ω–Ω–æ–≥–æ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è, –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –æ—Ç–ø—Ä–∞–≤–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–∞ –Ω—É–∂–Ω—ã–π –∞–¥—Ä–µ—Å, –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –¥–æ–≥–æ–≤–æ—Ä–æ–≤ –ø–æ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è–º",
        "amount": "üí∞ –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –ø–æ–ª—è: total_amount, currency, vat_amount –≤ —Ç–∞–±–ª–∏—Ü–µ contracts. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è: –ø–æ–¥—Å—á–µ—Ç–∞ –æ–±—â–µ–π —Å—É–º–º—ã –ø–æ—Ä—Ç—Ñ–µ–ª—è –¥–æ–≥–æ–≤–æ—Ä–æ–≤ (Dashboard Analytics), –ª–∏–º–∏—Ç-–∫–æ–Ω—Ç—Ä–æ–ª—è (–ø—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–µ–≤—ã—à–µ–Ω–∏—è –±—é–¥–∂–µ—Ç–∞), —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –æ—Ç—á–µ—Ç–æ–≤, –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è cash flow",
        "organization": "üèõÔ∏è –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏–π –∫–æ–º–ø–∞–Ω–∏–π –¥–ª—è –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è counterparties.name. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è: —Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤–æ–π –∑–∞–ø–∏—Å–∏ –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞, fuzzy-match –ø–æ–∏—Å–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–æ–≤ (–∏–∑–±–µ–≥–∞–Ω–∏–µ –¥—É–±–ª–µ–π), –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ UI —Å–ø–∏—Å–∫–∞ —Å—Ç–æ—Ä–æ–Ω –¥–æ–≥–æ–≤–æ—Ä–∞",
        "person": "üë§ –§–ò–û –ø–æ–¥–ø–∏—Å–∞–Ω—Ç–æ–≤ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ —Ç–∞–±–ª–∏—Ü–µ signatories (fields: full_name, position, authority_document). –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è: –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–ª–Ω–æ–º–æ—á–∏–π –ø–æ–¥–ø–∏—Å–∞–Ω—Ç–∞, –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –ø—Ä–∞–≤–∞ –ø–æ–¥–ø–∏—Å–∏ (cross-check —Å –¥–æ–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—è–º–∏), —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–π –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏ –¥–æ–≥–æ–≤–æ—Ä–∞",
        "address": "üìç –Æ—Ä. –∏ —Ñ–∞–∫—Ç. –∞–¥—Ä–µ—Å–∞ –≤ counterparties.legal_address –∏ counterparties.actual_address. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è: —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ—á—Ç–æ–≤—ã—Ö —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π, –≥–µ–æ–ª–æ–∫–∞—Ü–∏–∏ –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –∫–∞—Ä—Ç–µ (UI Dashboard), –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –∞–¥—Ä–µ—Å–æ–≤ (fraud detection)",
        "phone": "üìû –ö–æ–Ω—Ç–∞–∫—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ counterparties.phone –∏ contacts.phone. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è: –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –∑–≤–æ–Ω–∫–æ–≤/SMS —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π –æ —Å—Ä–æ–∫–∞—Ö, —Å–≤—è–∑–∏ —Å –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–æ–º —á–µ—Ä–µ–∑ CRM –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é, –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Ñ–æ—Ä–º–∞—Ç–∞ —Ç–µ–ª–µ—Ñ–æ–Ω–∞",
        "email": "üìß Email –∞–¥—Ä–µ—Å–∞ –≤ counterparties.email –∏ contacts.email. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è: –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ—Ç–ø—Ä–∞–≤–∫–∏ email —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π (–∏—Å—Ç–µ—á–µ–Ω–∏–µ —Å—Ä–æ–∫–∞, –∏–∑–º–µ–Ω–µ–Ω–∏—è), –ø—Ä–∏–≥–ª–∞—à–µ–Ω–∏–π –≤ —Å–∏—Å—Ç–µ–º—É –¥–ª—è –ø–æ–¥–ø–∏—Å–∞–Ω–∏—è, –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å email-–∫–ª–∏–µ–Ω—Ç–æ–º",
        "account": "üí≥ –ë–∞–Ω–∫–æ–≤—Å–∫–∏–µ —Å—á–µ—Ç–∞ –≤ counterparties.bank_account. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è: –∞–≤—Ç–æ–∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –ø–ª–∞—Ç–µ–∂–Ω—ã—Ö –ø–æ—Ä—É—á–µ–Ω–∏–π, –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ —Ä/—Å —á–µ—Ä–µ–∑ API –¶–ë –†–§, —Å–≤—è–∑—ã–≤–∞–Ω–∏—è —Å —Ç–∞–±–ª–∏—Ü–µ–π payments –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –æ–ø–ª–∞—Ç",
        "bic": "üè¶ –ë–ò–ö –±–∞–Ω–∫–∞ –≤ counterparties.bank_bic. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è: –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è –±–∞–Ω–∫–∞ —á–µ—Ä–µ–∑ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫ –¶–ë –†–§, –∞–≤—Ç–æ–∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è –±–∞–Ω–∫–∞ –∏ –∫–æ—Ä—Ä. —Å—á–µ—Ç–∞, –ø—Ä–æ–≤–µ—Ä–∫–∏ –±–∞–Ω–∫–∞ –Ω–∞ —Å–∞–Ω–∫—Ü–∏–æ–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏",
        "percent": "üìä –ü—Ä–æ—Ü–µ–Ω—Ç–Ω—ã–µ —Å—Ç–∞–≤–∫–∏ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ contract_terms.penalty_rate, discount_rate, interest_rate. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è: –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞—Å—á–µ—Ç–∞ –ø–µ–Ω–µ–π –∑–∞ –ø—Ä–æ—Å—Ä–æ—á–∫—É, –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —Å–∫–∏–¥–æ–∫, –Ω–∞—á–∏—Å–ª–µ–Ω–∏—è –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤ –ø–æ –¥–æ–≥–æ–≤–æ—Ä–∞–º –∑–∞–π–º–∞/–∫—Ä–µ–¥–∏—Ç–∞",
        "payment_term": "‚è∞ –£—Å–ª–æ–≤–∏—è –æ–ø–ª–∞—Ç—ã –≤ contracts.payment_terms (–ø—Ä–µ–¥–æ–ø–ª–∞—Ç–∞/–ø–æ—Å—Ç–æ–ø–ª–∞—Ç–∞/—Ä–∞—Å—Å—Ä–æ—á–∫–∞). –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è: –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –ø–ª–∞—Ç–µ–∂–µ–π –≤ –º–æ–¥—É–ª–µ Finance, —Å–æ–∑–¥–∞–Ω–∏—è –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏–π –æ –ø–ª–∞—Ç–µ–∂–∞—Ö, —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–∞ –ø–ª–∞—Ç–µ–∂–µ–π",
        "delivery_address": "üöö –ê–¥—Ä–µ—Å –ø–æ—Å—Ç–∞–≤–∫–∏ –≤ contracts.delivery_address. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è: –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è, –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω—ã–º–∏ –∫–æ–º–ø–∞–Ω–∏—è–º–∏, —Ä–∞—Å—á–µ—Ç–∞ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –¥–æ—Å—Ç–∞–≤–∫–∏",
        "warranty_period": "üõ°Ô∏è –ì–∞—Ä–∞–Ω—Ç–∏–π–Ω—ã–π —Å—Ä–æ–∫ –≤ contract_terms.warranty_months. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è: –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –≥–∞—Ä–∞–Ω—Ç–∏–π–Ω—ã—Ö –æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏–π –æ–± –æ–∫–æ–Ω—á–∞–Ω–∏–∏ –≥–∞—Ä–∞–Ω—Ç–∏–∏, —É—á–µ—Ç–∞ –≥–∞—Ä–∞–Ω—Ç–∏–π–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤"
    }
    # –ï—Å–ª–∏ —Ç–∏–ø –Ω–µ –Ω–∞–π–¥–µ–Ω - –≤–µ—Ä–Ω—É—Ç—å –¥–µ—Ç–∞–ª—å–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ
    if entity_type not in purposes:
        return f"‚ùì –°—É—â–Ω–æ—Å—Ç—å '{entity_type}' –Ω–µ –∏–º–µ–µ—Ç —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ–≥–æ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è. –°–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤ contracts.metadata (JSON) –¥–ª—è —Å–ø—Ä–∞–≤–æ—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏ –ø–æ–ª–Ω–æ—Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞"
    return purposes.get(entity_type)


def get_optimal_model_info(stage: str):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è —ç—Ç–∞–ø–∞ (–∞–∫—Ç—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ 2026)"""
    models = {
        "text_extraction": (
            "N/A (–ø—Ä—è–º–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ)",
            "pdfplumber + PaddleOCR –¥–ª—è —Å–∫–∞–Ω–æ–≤ + LayoutLMv3 –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –º–∞–∫–µ—Ç–æ–≤"
        ),
        "level1": (
            "regex + SpaCy (ru_core_news_sm)",
            "SpaCy ru_core_news_lg, DeepPavlov NER, –∏–ª–∏ Qwen2.5-VL-72B (119 —è–∑—ã–∫–æ–≤!) –¥–ª—è –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"
        ),
        "llm": (
            "gpt-4o-mini ($0.15/$0.6 per 1M) –∏–ª–∏ DeepSeek-V3.2 ($0.25/$0.38 per 1M)",
            "–õ—É—á—à–∏–µ –≤ 2026: GPT-4.1 ($2/$8, 1M context), Claude Sonnet 4.5 ($3/$15), DeepSeek-V3.2 ($0.25/$0.38, —ç–∫–æ–Ω–æ–º–∏—è 90%!), Qwen2.5-VL-72B (119 —è–∑—ã–∫–æ–≤, –≤–∏–∑—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑)"
        ),
        "rag": (
            "pgvector + text-embedding-3-large",
            "OpenAI text-embedding-3-large –∏–ª–∏ Cohere embed-multilingual-v3.0 –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ –∏ –º–Ω–æ–≥–æ—è–∑—ã—á–Ω—ã—Ö –¥–æ–≥–æ–≤–æ—Ä–æ–≤"
        ),
        "validation": (
            "Business rules + Pydantic",
            "–¢–æ–ø-3 –≤ 2026: Claude Opus 4.5 ($5/$25, —Å–∞–º—ã–π —Ç–æ—á–Ω—ã–π), GPT-4.1 ($2/$8, 1M context), Qwen2.5-VL-72B (–º–Ω–æ–≥–æ—è–∑—ã—á–Ω—ã–π + –≤–∏–∑—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑)"
        ),
        "section_analysis": (
            "DeepSeek-V3.2 ($0.25/$0.38 per 1M) –∏–ª–∏ gpt-4o-mini ($0.15/$0.6)",
            "–û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ: DeepSeek-V3.2 (90% —ç–∫–æ–Ω–æ–º–∏—è!), Claude Sonnet 4.5 ($3/$15, —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑), GPT-4.1 ($2/$8, –¥–ª–∏–Ω–Ω—ã–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã 1M)"
        )
    }
    return models.get(stage, ("N/A", "N/A"))


def display_validation_section_dynamic(section_analysis_data: Dict[str, Any], is_new_contract: bool = True):
    """–û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é –≤–∞–ª–∏–¥–∞—Ü–∏—é –ø–æ —Ä–∞–∑–¥–µ–ª–∞–º –¥–æ–≥–æ–≤–æ—Ä–∞ (–î–ò–ù–ê–ú–ò–ß–ï–°–ö–ò –∏–∑ LLM)"""

    if not section_analysis_data:
        st.warning("–ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–¥–µ–ª–æ–≤ –Ω–µ –±—ã–ª –≤—ã–ø–æ–ª–Ω–µ–Ω")
        return

    st.subheader("üìã –î–µ—Ç–∞–ª—å–Ω—ã–π —Ä–∞–∑–±–æ—Ä –ø–æ —Ä–∞–∑–¥–µ–ª–∞–º –¥–æ–≥–æ–≤–æ—Ä–∞")

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º
    if is_new_contract:
        st.info("üìù **–†–µ–∂–∏–º: –ù–æ–≤—ã–π –¥–æ–≥–æ–≤–æ—Ä** ‚Äî –ø—Ä–∏–Ω—è—Ç—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –±—É–¥—É—Ç –≤–Ω–µ—Å–µ–Ω—ã –≤ DOCX-–¥–æ–∫—É–º–µ–Ω—Ç")
    else:
        st.info("üìã **–†–µ–∂–∏–º: –ü–æ–¥–ø–∏—Å–∞–Ω–Ω—ã–π –¥–æ–≥–æ–≤–æ—Ä** ‚Äî –ø—Ä–∏–Ω—è—Ç—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –±—É–¥—É—Ç —Å–æ–±—Ä–∞–Ω—ã –≤ –ø—Ä–æ—Ç–æ–∫–æ–ª —Ä–∞–∑–Ω–æ–≥–ª–∞—Å–∏–π")

    sections = section_analysis_data.get("sections", [])
    section_analyses = section_analysis_data.get("section_analyses", [])
    complex_analysis = section_analysis_data.get("complex_analysis")

    if not sections:
        st.warning("–†–∞–∑–¥–µ–ª—ã –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã –≤ –¥–æ–≥–æ–≤–æ—Ä–µ")
        return

    st.info(f"**–ù–∞–π–¥–µ–Ω–æ —Ä–∞–∑–¥–µ–ª–æ–≤:** {len(sections)} | **–ü–æ—Ä—è–¥–æ–∫ –ø—Ä–æ–≤–µ—Ä–∫–∏:** 1Ô∏è‚É£ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ –¥–æ–≥–æ–≤–æ—Ä–∞–º–∏ ‚Üí 2Ô∏è‚É£ –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ RAG –±–∞–∑–µ (–∞–∫—Ç—É–∞–ª—å–Ω–∞—è –ø—Ä–∞–≤–æ–≤–∞—è –±–∞–∑–∞) ‚Üí 3Ô∏è‚É£ –§–æ–ª–±—ç–∫ –Ω–∞ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π –º–æ–¥–µ–ª–∏")

    # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ —Å–æ–∑–¥–∞–µ–º –≤–∫–ª–∞–¥–∫–∏
    tab_names = [f"–†–∞–∑–¥–µ–ª {s.number}" for s in sections] + ["üîç –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑"]
    tabs = st.tabs(tab_names)

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø—Ä–∏–Ω—è—Ç—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
    _ensure_recommendation_state()

    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –∫–∞–∂–¥—ã–π —Ä–∞–∑–¥–µ–ª –î–ò–ù–ê–ú–ò–ß–ï–°–ö–ò
    for idx, (section, analysis) in enumerate(zip(sections, section_analyses)):
        with tabs[idx]:
            st.markdown(f"### üìÑ –†–∞–∑–¥–µ–ª {section.number}: {section.title}")

            # –¢–µ–∫—Å—Ç —Ä–∞–∑–¥–µ–ª–∞
            st.text_area("–¢–µ–∫—Å—Ç —Ä–∞–∑–¥–µ–ª–∞:", section.text, height=150, key=f"section_{section.number}_text")

            st.markdown("---")

            # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ –¥–æ–≥–æ–≤–æ—Ä–∞–º–∏
            st.markdown("**1Ô∏è‚É£ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ –¥–æ–≥–æ–≤–æ—Ä–∞–º–∏:**")
            if analysis.own_contracts_comparison.startswith("‚úÖ"):
                st.success(analysis.own_contracts_comparison)
            elif analysis.own_contracts_comparison.startswith("‚ö†Ô∏è"):
                st.warning(analysis.own_contracts_comparison)
            else:
                st.error(analysis.own_contracts_comparison)

            # –î–µ—Ç–∞–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
            if analysis.own_contracts_details:
                st.dataframe(analysis.own_contracts_details, use_container_width=True)

            # RAG –ø—Ä–æ–≤–µ—Ä–∫–∞
            st.markdown("**2Ô∏è‚É£ –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ RAG (–∞–∫—Ç—É–∞–ª—å–Ω–∞—è –ø—Ä–∞–≤–æ–≤–∞—è –±–∞–∑–∞):**")
            st.info(analysis.rag_legal_check)

            if analysis.rag_legal_references:
                st.markdown("**–°—Å—ã–ª–∫–∏ –Ω–∞ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ:**")
                for ref in analysis.rag_legal_references:
                    st.markdown(f"- {ref}")

            st.markdown("---")

            # –í—ã–≤–æ–¥—ã –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            if analysis.conclusion.startswith("–†–∞–∑–¥–µ–ª –ø—Ä–æ—Ä–∞–±–æ—Ç–∞–Ω —Ö–æ—Ä–æ—à–æ") or "—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç" in analysis.conclusion.lower():
                st.success(f"**–í—ã–≤–æ–¥:** {analysis.conclusion}")
            elif "—Ç—Ä–µ–±—É–µ—Ç" in analysis.conclusion.lower() or "–¥–æ—Ä–∞–±–æ—Ç–∫" in analysis.conclusion.lower():
                st.warning(f"**–í—ã–≤–æ–¥:** {analysis.conclusion}")
            else:
                st.info(f"**–í—ã–≤–æ–¥:** {analysis.conclusion}")

            if analysis.warnings:
                st.markdown("**‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è:**")
                for warning in analysis.warnings:
                    st.warning(warning)

            if analysis.recommendations:
                st.markdown("**üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é:**")
                for i, rec in enumerate(analysis.recommendations):
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ü–≤–µ—Ç –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
                    if hasattr(rec, 'priority'):
                        if rec.priority == "critical":
                            priority_badge = "üî¥ **–ö–†–ò–¢–ò–ß–ù–û**"
                        elif rec.priority == "important":
                            priority_badge = "üü° **–í–ê–ñ–ù–û**"
                        else:
                            priority_badge = "üü¢ **–†–ï–ö–û–ú–ï–ù–î–û–í–ê–ù–û**"
                    else:
                        priority_badge = "üí°"

                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –¥–µ–π—Å—Ç–≤–∏—è
                    if hasattr(rec, 'action_type'):
                        if rec.action_type == "add":
                            action_badge = "‚ûï –î–æ–±–∞–≤–∏—Ç—å"
                        elif rec.action_type == "modify":
                            action_badge = "‚úèÔ∏è –ò–∑–º–µ–Ω–∏—Ç—å"
                        elif rec.action_type == "remove":
                            action_badge = "‚ùå –£–¥–∞–ª–∏—Ç—å"
                        else:
                            action_badge = "‚úèÔ∏è –ò–∑–º–µ–Ω–∏—Ç—å"
                    else:
                        action_badge = "‚úèÔ∏è –ò–∑–º–µ–Ω–∏—Ç—å"

                    with st.container():
                        st.markdown(f"##### {priority_badge} | {action_badge}")

                        # –ü—Ä–∏—á–∏–Ω–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
                        if hasattr(rec, 'reason'):
                            st.markdown(f"**–ü—Ä–∏—á–∏–Ω–∞:** {rec.reason}")
                        else:
                            st.markdown(f"**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** {rec}")

                        # –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º—ã–π —Ç–µ–∫—Å—Ç
                        if hasattr(rec, 'proposed_text') and rec.proposed_text:
                            st.markdown("**–ü—Ä–µ–¥–ª–∞–≥–∞–µ–º—ã–π —Ç–µ–∫—Å—Ç –ø—É–Ω–∫—Ç–∞:**")
                            st.text_area(
                                label="",
                                value=rec.proposed_text,
                                height=150,
                                key=f"rec_{section.number}_{i}",
                                label_visibility="collapsed"
                            )

                            # –ö–Ω–æ–ø–∫–∏ –¥–µ–π—Å—Ç–≤–∏–π ‚Äî –∑–∞–≤–∏—Å—è—Ç –æ—Ç —Ä–µ–∂–∏–º–∞
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                accept_label = "‚úÖ –ü—Ä–∏–Ω—è—Ç—å –≤ DOCX" if is_new_contract else "‚úÖ –í –ø—Ä–æ—Ç–æ–∫–æ–ª —Ä–∞–∑–Ω–æ–≥–ª–∞—Å–∏–π"
                                if st.button(accept_label, key=f"accept_{section.number}_{i}", type="primary"):
                                    payload = {
                                        "section_number": section.number,
                                        "section_title": section.title,
                                        "original_text": section.text[:400] + ("..." if len(section.text) > 400 else ""),
                                        "proposed_text": rec.proposed_text,
                                        "reason": rec.reason if hasattr(rec, "reason") else str(rec),
                                        "action_type": rec.action_type if hasattr(rec, "action_type") else "modify",
                                        "priority": rec.priority if hasattr(rec, "priority") else "optional",
                                        "source": "section_analysis",
                                        "target": "docx" if is_new_contract else "protocol",
                                    }
                                    added = add_accepted_recommendation(payload)
                                    if added:
                                        if is_new_contract:
                                            st.success("‚úÖ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –ø—Ä–∏–Ω—è—Ç–∞. –ë—É–¥–µ—Ç –≤–∫–ª—é—á–µ–Ω–∞ –≤ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π DOCX (Stage 2.4).")
                                        else:
                                            st.success("‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ –≤ –ø—Ä–æ—Ç–æ–∫–æ–ª —Ä–∞–∑–Ω–æ–≥–ª–∞—Å–∏–π.")
                                    else:
                                        st.info("‚ÑπÔ∏è –≠—Ç–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è —É–∂–µ –±—ã–ª–∞ –ø—Ä–∏–Ω—è—Ç–∞ —Ä–∞–Ω–µ–µ.")
                            with col2:
                                if st.button("‚úèÔ∏è –†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å", key=f"edit_{section.number}_{i}"):
                                    st.info("‚úèÔ∏è –û—Ç–∫—Ä–æ–π—Ç–µ —Ä–µ–¥–∞–∫—Ç–æ—Ä –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞.")
                            with col3:
                                if st.button("‚ùå –û—Ç–∫–ª–æ–Ω–∏—Ç—å", key=f"reject_{section.number}_{i}"):
                                    st.warning("‚ùå –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –æ—Ç–∫–ª–æ–Ω–µ–Ω–∞.")

                        st.markdown("---")

    # –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (–ø–æ—Å–ª–µ–¥–Ω—è—è –≤–∫–ª–∞–¥–∫–∞)
    with tabs[-1]:
        st.markdown("### üîç –ö–û–ú–ü–õ–ï–ö–°–ù–´–ô –ê–ù–ê–õ–ò–ó –î–û–ì–û–í–û–†–ê")
        st.markdown("–ê–Ω–∞–ª–∏–∑ –≤–∑–∞–∏–º–æ—Å–≤—è–∑–µ–π –º–µ–∂–¥—É —Ä–∞–∑–¥–µ–ª–∞–º–∏ –∏ –æ–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞")

        if not complex_analysis:
            st.warning("–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω")
            return

        st.markdown("---")
        st.markdown("#### 1Ô∏è‚É£ –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ –∏ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏")
        if complex_analysis.integrity_checks:
            st.dataframe(complex_analysis.integrity_checks, use_container_width=True)

        st.markdown("---")
        st.markdown("#### 2Ô∏è‚É£ –Æ—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ —Ä–∏—Å–∫–∏")

        risk_col1, risk_col2, risk_col3 = st.columns(3)

        with risk_col1:
            st.markdown("**üü¢ –ù–ò–ó–ö–ò–ô –†–ò–°–ö:**")
            for risk in complex_analysis.risk_assessment.get("low", []):
                st.success(f"‚úÖ {risk}")

        with risk_col2:
            st.markdown("**üü° –°–†–ï–î–ù–ò–ô –†–ò–°–ö:**")
            for risk in complex_analysis.risk_assessment.get("medium", []):
                st.warning(f"‚ö†Ô∏è {risk}")

        with risk_col3:
            st.markdown("**üî¥ –í–´–°–û–ö–ò–ô –†–ò–°–ö:**")
            for risk in complex_analysis.risk_assessment.get("high", []):
                st.error(f"‚ùå {risk}")

        st.markdown("---")
        st.markdown("#### 3Ô∏è‚É£ –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤—É –†–§")
        if complex_analysis.legal_compliance:
            st.dataframe(complex_analysis.legal_compliance, use_container_width=True)

        st.markdown("---")
        st.markdown("#### 4Ô∏è‚É£ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –ª—É—á—à–∏–º–∏ –ø—Ä–∞–∫—Ç–∏–∫–∞–º–∏")
        st.info("**–ò—Å—Ç–æ—á–Ω–∏–∫:** –ê–Ω–∞–ª–∏–∑ –ø–æ—Ö–æ–∂–∏—Ö –¥–æ–≥–æ–≤–æ—Ä–æ–≤ –∏–∑ –±–∞–∑—ã + RAG –∞–∫—Ç—É–∞–ª—å–Ω–∞—è –ø—Ä–∞–≤–æ–≤–∞—è –±–∞–∑–∞ + –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –º–æ–¥–µ–ª–∏")
        if complex_analysis.best_practices:
            st.dataframe(complex_analysis.best_practices, use_container_width=True)

        st.markdown("---")
        st.markdown("#### 5Ô∏è‚É£ –ò—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")

        score_col1, score_col2, score_col3 = st.columns(3)

        with score_col1:
            st.metric("–û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞", f"{complex_analysis.overall_score}/100",
                      delta="–•–æ—Ä–æ—à–æ" if complex_analysis.overall_score >= 80 else "–¢—Ä–µ–±—É–µ—Ç –¥–æ—Ä–∞–±–æ—Ç–∫–∏")

        with score_col2:
            st.metric("–Æ—Ä–∏–¥–∏—á–µ—Å–∫–∞—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å", f"{complex_analysis.legal_reliability:.1f}/10",
                      delta="–í—ã—Å–æ–∫–∞—è" if complex_analysis.legal_reliability >= 8 else "–°—Ä–µ–¥–Ω—è—è")

        with score_col3:
            st.metric("–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∑–∞–∫–æ–Ω—É", f"{complex_analysis.compliance_percent}%",
                      delta=f"+{100 - complex_analysis.compliance_percent}% –ø–æ—Å–ª–µ –¥–æ—Ä–∞–±–æ—Ç–∫–∏")

        st.markdown("---")

        rec_col1, rec_col2 = st.columns(2)

        with rec_col1:
            st.markdown("**‚úÖ –°–ò–õ–¨–ù–´–ï –°–¢–û–†–û–ù–´:**")
            for strength in complex_analysis.strengths:
                st.success(strength)

        with rec_col2:
            st.markdown("**‚ö†Ô∏è –ö–†–ò–¢–ò–ß–ù–´–ï –î–û–†–ê–ë–û–¢–ö–ò:**")
            for improvement in complex_analysis.critical_improvements:
                if improvement.startswith("–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û") or improvement.startswith("–ö–†–ò–¢–ò–ß–ù–û"):
                    st.error(improvement)
                else:
                    st.warning(improvement)

        st.markdown("---")
        avg_score = complex_analysis.overall_score
        if avg_score >= 90:
            st.success("**üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** –î–æ–≥–æ–≤–æ—Ä –≥–æ—Ç–æ–≤ –∫ –ø–æ–¥–ø–∏—Å–∞–Ω–∏—é. –û—Ç–ª–∏—á–Ω–∞—è –ø—Ä–æ—Ä–∞–±–æ—Ç–∫–∞!")
        elif avg_score >= 80:
            st.info("**üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** –î–æ–≥–æ–≤–æ—Ä –º–æ–∂–Ω–æ –ø–æ–¥–ø–∏—Å—ã–≤–∞—Ç—å –ø–æ—Å–ª–µ –≤–Ω–µ—Å–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã—Ö –¥–æ—Ä–∞–±–æ—Ç–æ–∫.")
        elif avg_score >= 70:
            st.warning("**üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** –î–æ–≥–æ–≤–æ—Ä —Ç—Ä–µ–±—É–µ—Ç –¥–æ—Ä–∞–±–æ—Ç–æ–∫. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø—Ä–∞–≤–∏—Ç—å –∫—Ä–∏—Ç–∏—á–Ω—ã–µ –∑–∞–º–µ—á–∞–Ω–∏—è –ø–µ—Ä–µ–¥ –ø–æ–¥–ø–∏—Å–∞–Ω–∏–µ–º.")
        else:
            st.error("**üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** –î–æ–≥–æ–≤–æ—Ä —Ç—Ä–µ–±—É–µ—Ç —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –ø–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∏. –ù–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∫ –ø–æ–¥–ø–∏—Å–∞–Ω–∏—é –≤ —Ç–µ–∫—É—â–µ–º –≤–∏–¥–µ.")


def extract_section_text(full_text: str, start_marker: str, end_marker: str) -> str:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∞ –¥–æ–≥–æ–≤–æ—Ä–∞"""
    try:
        start_idx = full_text.find(start_marker)
        end_idx = full_text.find(end_marker)

        if start_idx == -1:
            return "–†–∞–∑–¥–µ–ª –Ω–µ –Ω–∞–π–¥–µ–Ω"

        if end_idx == -1:
            # –ï—Å–ª–∏ —ç—Ç–æ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ä–∞–∑–¥–µ–ª
            return full_text[start_idx:start_idx + 500]

        return full_text[start_idx:end_idx].strip()
    except:
        return "–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ —Ä–∞–∑–¥–µ–ª–∞"


# –ö–Ω–æ–ø–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
if uploaded_file is not None:
    st.success(f"‚úÖ –§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω: **{uploaded_file.name}** ({uploaded_file.size} –±–∞–π—Ç)")

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
    with st.expander("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏", expanded=False):
        use_section_analysis = st.checkbox(
            "–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–∞–∑–¥–µ–ª–æ–≤ (Section Analysis)",
            value=True,
            help="LLM-–∞–Ω–∞–ª–∏–∑ –∫–∞–∂–¥–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∞ –¥–æ–≥–æ–≤–æ—Ä–∞ —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏. –î–æ–±–∞–≤–ª—è–µ—Ç ~60-90 —Å–µ–∫ –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ."
        )

    if st.button("üöÄ –ù–∞—á–∞—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É", type="primary"):
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
        with tempfile.NamedTemporaryFile(delete=False, suffix=Path(uploaded_file.name).suffix) as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            tmp_file_path = tmp_file.name

        try:
            # Progress bar
            progress_bar = st.progress(0)
            status_text = st.empty()

            # –ó–∞–ø—É—Å–∫–∞–µ–º —Ä–µ–∞–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
            if use_section_analysis:
                status_text.text("üöÄ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—É—â–µ–Ω–∞. –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–∞–∑–¥–µ–ª–æ–≤ –∑–∞–π–º—ë—Ç ~60-90 —Å–µ–∫. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ...")
            else:
                status_text.text("üöÄ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—É—â–µ–Ω–∞ (~15 —Å–µ–∫)...")
            progress_bar.progress(5)

            # –ó–∞–ø—É—Å–∫–∞–µ–º async –æ–±—Ä–∞–±–æ—Ç–∫—É
            import concurrent.futures
            def _run_async(coro):
                loop = asyncio.new_event_loop()
                try:
                    return loop.run_until_complete(coro)
                finally:
                    loop.close()

            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(
                    _run_async,
                    process_document_async(tmp_file_path, Path(uploaded_file.name).suffix, use_section_analysis=use_section_analysis)
                )
                result = future.result(timeout=300)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ session_state —á—Ç–æ–±—ã –æ–Ω –Ω–µ –ø—Ä–æ–ø–∞–¥–∞–ª –ø—Ä–∏ –ø–µ—Ä–µ—Ä–∏—Å–æ–≤–∫–µ
            st.session_state["processing_result"] = result
            st.session_state["processing_file_name"] = uploaded_file.name
            st.session_state["processing_use_section_analysis"] = use_section_analysis
            st.session_state["processing_is_new_contract"] = is_new_contract
            st.session_state["processing_result_signature"] = f"{uploaded_file.name}:{len(result.raw_text)}:{result.model_used}"

            # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ Stage 2 –ø—Ä–∏ –Ω–æ–≤–æ–º –∑–∞–ø—É—Å–∫–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
            for key in [
                "template_comparison",
                "template_comparison_signature",
                "accepted_recommendations",
                "accepted_recommendation_keys",
                "risk_scoring",
                "risk_scoring_signature",
                "final_corrected_docx",
                "final_protocol_docx",
                "final_protocol_json",
            ]:
                st.session_state.pop(key, None)

            progress_bar.progress(100)
            status_text.text("‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
            st.rerun()

        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}")
            import traceback
            st.code(traceback.format_exc())

        finally:
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            if os.path.exists(tmp_file_path):
                os.unlink(tmp_file_path)

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # –û–¢–û–ë–†–ê–ñ–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í (–≤–Ω–µ –±–ª–æ–∫–∞ –∫–Ω–æ–ø–∫–∏, –∏–∑ session_state)
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    if "processing_result" in st.session_state:
        result = st.session_state["processing_result"]
        _file_name = st.session_state.get("processing_file_name", "document")
        _use_section_analysis = st.session_state.get("processing_use_section_analysis", True)
        _is_new_contract = st.session_state.get("processing_is_new_contract", True)
        _ensure_recommendation_state()

        # –ö–Ω–æ–ø–∫–∞ —Å–±—Ä–æ—Å–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if st.button("üîÑ –ù–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑", help="–û—á–∏—Å—Ç–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç"):
            for key in [
                "processing_result",
                "processing_file_name",
                "processing_use_section_analysis",
                "processing_is_new_contract",
                "processing_result_signature",
                "template_comparison",
                "template_comparison_signature",
                "accepted_recommendations",
                "accepted_recommendation_keys",
                "risk_scoring",
                "risk_scoring_signature",
                "final_corrected_docx",
                "final_protocol_docx",
                "final_protocol_json",
            ]:
                st.session_state.pop(key, None)
            st.rerun()

        st.markdown("---")
        st.header("2Ô∏è‚É£ –•–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏")

        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–∞–∂–¥–æ–≥–æ —ç—Ç–∞–ø–∞
        for idx, stage in enumerate(result.stages):

            # Stage 1: Text Extraction
            if stage.name == "text_extraction":
                with st.expander(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ ({stage.duration_sec:.1f} —Å–µ–∫)", expanded=True):
                    used_model, optimal_model = get_optimal_model_info("text_extraction")
                    st.success(f"**–ú–µ—Ç–æ–¥:** {stage.results.get('method', 'N/A')} | **–§–æ—Ä–º–∞—Ç:** {stage.results.get('original_format', 'N/A')} | **DOCX-–≤–µ—Ä—Å–∏—è:** {'‚úÖ –ï—Å—Ç—å' if stage.results.get('has_docx') else '‚ùå –ù–µ—Ç'}")
                    st.info(f"**–ú–æ–¥–µ–ª—å:** {used_model} | **–û–ø—Ç–∏–º–∞–ª—å–Ω–æ:** {optimal_model}")

                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("–°—Ç—Ä–∞–Ω–∏—Ü", stage.results.get("pages", "N/A"))
                    with col2:
                        st.metric("–°–∏–º–≤–æ–ª–æ–≤", f"{stage.results.get('chars', 0):,}")
                    with col3:
                        confidence = stage.results.get("confidence")
                        st.metric("Confidence", f"{confidence:.2f}" if confidence else "N/A")

                    # –ò–∑–≤–ª–µ—á—ë–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
                    with st.expander("üìã –ò–∑–≤–ª–µ—á—ë–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç (plain text)", expanded=False):
                        st.text_area("–í–µ—Å—å —Ç–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞:", value=result.raw_text, height=400, key="full_text_area")

            # Stage 2: Level 1 Extraction
            elif stage.name == "level1_extraction":
                with st.expander(f"‚úÖ Level 1 Extraction ({stage.duration_sec:.1f} —Å–µ–∫)", expanded=True):
                    used_model, optimal_model = get_optimal_model_info("level1")
                    st.success(f"**–ù–∞–π–¥–µ–Ω–æ —Å—É—â–Ω–æ—Å—Ç–µ–π:** {stage.results.get('entities_count', 0)}")
                    st.info(f"**–ú–æ–¥–µ–ª—å:** {used_model} | **–û–ø—Ç–∏–º–∞–ª—å–Ω–æ:** {optimal_model}")

                    # –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ —Ç–∏–ø–∞–º
                    by_type = stage.results.get("by_type", {})
                    if by_type:
                        cols = st.columns(min(len(by_type), 3))
                        for idx2, (entity_type, count) in enumerate(by_type.items()):
                            with cols[idx2 % 3]:
                                st.metric(entity_type, count)

                    # –î–µ—Ç–∞–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞
                    st.subheader("üìã –î–µ—Ç–∞–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ —Å—É—â–Ω–æ—Å—Ç–µ–π")
                    details = stage.results.get("details", {})

                    all_entities = []
                    for entity_type, entities in details.items():
                        for ent in entities:
                            all_entities.append({
                                "–¢–∏–ø": entity_type,
                                "–ó–Ω–∞—á–µ–Ω–∏–µ": ent.get("value", ""),
                                "–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ": get_entity_purpose(entity_type),
                                "Confidence": f"{ent.get('confidence', 0):.2f}",
                                "–ö–æ–Ω—Ç–µ–∫—Å—Ç": ent.get("context", "")[:80] + "..."
                            })

                    if all_entities:
                        st.dataframe(all_entities, use_container_width=True)
                        st.caption("üí° **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ** –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –¥–ª—è —á–µ–≥–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–∞–∂–¥–∞—è —Å—É—â–Ω–æ—Å—Ç—å –≤ —Å–∏—Å—Ç–µ–º–µ")

            # Stage 3: LLM Extraction
            elif stage.name == "llm_extraction":
                with st.expander(f"‚úÖ LLM Extraction ({stage.duration_sec:.1f} —Å–µ–∫)", expanded=True):
                    model_used = stage.results.get("model", "N/A")
                    used_model, optimal_model = get_optimal_model_info("llm")

                    st.success(f"**–ú–æ–¥–µ–ª—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞:** {model_used}")
                    st.info(f"**–û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å:** {optimal_model}")

                    # –ú–µ—Ç—Ä–∏–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
                    st.subheader("üìä –ú–µ—Ç—Ä–∏–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏")
                    tokens_in = stage.results.get("tokens_input", 0)
                    tokens_out = stage.results.get("tokens_output", 0)
                    cost = stage.results.get("cost_usd", 0)
                    confidence = stage.results.get("confidence", 0)

                    metrics_data = [
                        {"–ü–∞—Ä–∞–º–µ—Ç—Ä": "–¢–æ–∫–µ–Ω—ã (–≤—Ö–æ–¥)", "–ó–Ω–∞—á–µ–Ω–∏–µ": f"{tokens_in:,}", "–û–ø–∏—Å–∞–Ω–∏–µ": "–¢–æ–∫–µ–Ω–æ–≤ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ –º–æ–¥–µ–ª—å"},
                        {"–ü–∞—Ä–∞–º–µ—Ç—Ä": "–¢–æ–∫–µ–Ω—ã (–≤—ã—Ö–æ–¥)", "–ó–Ω–∞—á–µ–Ω–∏–µ": f"{tokens_out:,}", "–û–ø–∏—Å–∞–Ω–∏–µ": "–¢–æ–∫–µ–Ω–æ–≤ –ø–æ–ª—É—á–µ–Ω–æ –æ—Ç –º–æ–¥–µ–ª–∏"},
                        {"–ü–∞—Ä–∞–º–µ—Ç—Ä": "–í—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤", "–ó–Ω–∞—á–µ–Ω–∏–µ": f"{tokens_in + tokens_out:,}", "–û–ø–∏—Å–∞–Ω–∏–µ": "–°—É–º–º–∞—Ä–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ"},
                        {"–ü–∞—Ä–∞–º–µ—Ç—Ä": "–°—Ç–æ–∏–º–æ—Å—Ç—å", "–ó–Ω–∞—á–µ–Ω–∏–µ": f"${cost:.5f}", "–û–ø–∏—Å–∞–Ω–∏–µ": f"{model_used}: —Å–º. —Ç–∞—Ä–∏—Ñ—ã –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞"},
                        {"–ü–∞—Ä–∞–º–µ—Ç—Ä": "Confidence", "–ó–Ω–∞—á–µ–Ω–∏–µ": f"{confidence:.2f} ({confidence*100:.0f}%)", "–û–ø–∏—Å–∞–Ω–∏–µ": "–°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏"},
                    ]
                    st.table(metrics_data)

                    # –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                    st.subheader("üìä –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
                    extracted_data = stage.results.get("data", {})

                    tab1, tab2, tab3, tab4, tab5 = st.tabs(["–°—Ç–æ—Ä–æ–Ω—ã", "–ü—Ä–µ–¥–º–µ—Ç", "–§–∏–Ω–∞–Ω—Å—ã", "–°—Ä–æ–∫–∏", "–°–∞–Ω–∫—Ü–∏–∏"])

                    with tab1:
                        st.json(extracted_data.get("parties", {}))

                    with tab2:
                        st.json(extracted_data.get("subject", {}))

                    with tab3:
                        st.json(extracted_data.get("financials", {}))

                    with tab4:
                        st.json(extracted_data.get("terms", {}))

                    with tab5:
                        st.json(extracted_data.get("penalties", {}))

            # Stage 4: RAG Filter
            elif stage.name == "rag_filter":
                with st.expander(f"‚úÖ RAG Filter ({stage.duration_sec:.1f} —Å–µ–∫)", expanded=False):
                    used_model, optimal_model = get_optimal_model_info("rag")
                    similar_count = stage.results.get("similar_contracts_found", 0)

                    st.success(f"**–ù–∞–π–¥–µ–Ω–æ –ø–æ—Ö–æ–∂–∏—Ö:** {similar_count} –¥–æ–≥–æ–≤–æ—Ä–æ–≤")
                    st.info(f"**–ú–æ–¥–µ–ª—å:** {used_model} | **–û–ø—Ç–∏–º–∞–ª—å–Ω–æ:** {optimal_model}")

                    contracts = stage.results.get("contracts", [])
                    if contracts:
                        similar_data = []
                        for c in contracts:
                            similar_data.append({
                                "–î–æ–≥–æ–≤–æ—Ä": c.get("contract_number", "N/A"),
                                "–°—Ö–æ–∂–µ—Å—Ç—å": f"{c.get('similarity', 0):.2f}",
                                "–¢–∏–ø": c.get("doc_type", "N/A"),
                                "–°—É–º–º–∞": f"‚ÇΩ{c.get('amount', 0):,.0f}"
                            })
                        st.dataframe(similar_data, use_container_width=True)
                    else:
                        st.info("–ü–æ—Ö–æ–∂–∏–µ –¥–æ–≥–æ–≤–æ—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã (–±–∞–∑–∞ –ø—É—Å—Ç–∞ –∏–ª–∏ –Ω–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π)")

        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # –û–¢–î–ï–õ–¨–ù–´–ô –†–ê–ó–î–ï–õ: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (DOCX-–≤–µ—Ä—Å–∏—è)
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        st.markdown("---")
        st.header("üìÑ –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞")
        st.markdown("–î–æ–∫—É–º–µ–Ω—Ç –∏–∑–≤–ª–µ—á—ë–Ω –≤ —Ñ–æ—Ä–º–∞—Ç DOCX —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è. "
                    "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã, –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤, —Å–ø–∏—Å–∫–æ–≤ –∏ –æ—Ç—Å—Ç—É–ø–æ–≤.")

        if result.docx_file_bytes:
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
            orig_fmt = result.original_format or 'unknown'
            fmt_labels = {
                'pdf': 'üìï PDF ‚Üí DOCX (pdf2docx, —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–∞–∫–µ—Ç–∞ –∏ —Ç–∞–±–ª–∏—Ü)',
                'docx': 'üìò DOCX (–æ—Ä–∏–≥–∏–Ω–∞–ª, —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –ø–æ–ª–Ω–æ—Å—Ç—å—é)',
                'txt': 'üìù TXT ‚Üí DOCX (–≤–æ—Å—Å–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∏–∑ plain text)',
                'xml': 'üìã XML ‚Üí DOCX (–∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ)',
                'html': 'üåê HTML ‚Üí DOCX (–∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Å—Ç–∏–ª–µ–π)',
                'image': 'üñºÔ∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ ‚Üí OCR ‚Üí DOCX (—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞)',
            }
            st.info(f"**–ú–µ—Ç–æ–¥ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏:** {fmt_labels.get(orig_fmt, f'–§–æ—Ä–º–∞—Ç: {orig_fmt}')}")

            # –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä DOCX –≤ –≤–∏–¥–µ HTML
            preview_html = render_docx_preview(result.docx_file_bytes)
            st.markdown(preview_html, unsafe_allow_html=True)

            # –ö–Ω–æ–ø–∫–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
            st.markdown("---")
            dl_col1, dl_col2, dl_col3 = st.columns(3)
            with dl_col1:
                if result.original_file_bytes:
                    orig_ext = result.original_format or 'bin'
                    st.download_button(
                        f"üì• –°–∫–∞—á–∞—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª (.{orig_ext})",
                        data=result.original_file_bytes,
                        file_name=f"original_{_file_name}",
                        mime="application/octet-stream",
                        key="download_original"
                    )
            with dl_col2:
                st.download_button(
                    "üì• –°–∫–∞—á–∞—Ç—å DOCX-–≤–µ—Ä—Å–∏—é",
                    data=result.docx_file_bytes,
                    file_name=f"{Path(_file_name).stem}.docx",
                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                    key="download_docx"
                )
            with dl_col3:
                docx_size_kb = len(result.docx_file_bytes) / 1024
                orig_size_kb = len(result.original_file_bytes) / 1024 if result.original_file_bytes else 0
                st.metric("–†–∞–∑–º–µ—Ä DOCX", f"{docx_size_kb:.1f} –ö–ë",
                         delta=f"–û—Ä–∏–≥–∏–Ω–∞–ª: {orig_size_kb:.1f} –ö–ë")
        else:
            st.error("DOCX-–≤–µ—Ä—Å–∏—è –Ω–µ –±—ã–ª–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∞. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–ª–∏—á–∏–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ python-docx.")

        st.markdown("---")

        # Stage 5: Validation
        section_analysis_data = _extract_section_analysis_data(result)
        validation_result = result.validation_result or {}

        with st.expander("‚ö†Ô∏è Validation", expanded=True):
            used_model, optimal_model = get_optimal_model_info("validation")

            is_valid = validation_result.get("is_valid", False)
            has_warnings = len(validation_result.get("warnings", [])) > 0
            if is_valid and not has_warnings:
                st.success("**–°—Ç–∞—Ç—É—Å:** ‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ–π–¥–µ–Ω–∞")
            elif is_valid and has_warnings:
                st.warning("**–°—Ç–∞—Ç—É—Å:** ‚ö†Ô∏è –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ–π–¥–µ–Ω–∞ —Å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è–º–∏")
            else:
                st.error("**–°—Ç–∞—Ç—É—Å:** ‚ùå –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–µ –ø—Ä–æ–π–¥–µ–Ω–∞")

            st.info(f"**–ú–æ–¥–µ–ª—å:** {used_model} | **–û–ø—Ç–∏–º–∞–ª—å–Ω–æ:** {optimal_model}")

            errors = validation_result.get("errors", [])
            warnings = validation_result.get("warnings", [])

            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("–û—à–∏–±–æ–∫", len(errors), delta="‚úÖ" if len(errors) == 0 else "‚ùå")
            with col2:
                st.metric("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π", len(warnings), delta="‚ö†Ô∏è" if len(warnings) > 0 else "‚úÖ")
            with col3:
                compliance = 100 - (len(errors) * 10 + len(warnings) * 2)
                st.metric("–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ", f"{compliance}%", delta=f"{compliance-100}%" if compliance < 100 else "‚úÖ")

            # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –æ—à–∏–±–æ–∫ –∏ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π
            if errors:
                st.markdown("### ‚ùå –û—à–∏–±–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏:")
                for i, error in enumerate(errors, 1):
                    if isinstance(error, dict):
                        st.error(f"**{i}.** `{error.get('field', 'N/A')}`: {error.get('message', 'N/A')}")
                    else:
                        st.error(f"**{i}.** {error}")

            if warnings:
                st.markdown("### ‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è:")
                for i, warning in enumerate(warnings, 1):
                    if isinstance(warning, dict):
                        st.warning(f"**{i}.** `{warning.get('field', 'N/A')}`: {warning.get('message', 'N/A')}")
                    else:
                        st.warning(f"**{i}.** {warning}")

            st.markdown("---")

            if section_analysis_data:
                display_validation_section_dynamic(section_analysis_data, is_new_contract=_is_new_contract)
            elif _use_section_analysis:
                st.warning("‚ö†Ô∏è –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–∞–∑–¥–µ–ª–æ–≤ –Ω–µ –±—ã–ª –≤—ã–ø–æ–ª–Ω–µ–Ω –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏.")
            else:
                st.info("‚ÑπÔ∏è –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–∞–∑–¥–µ–ª–æ–≤ –æ—Ç–∫–ª—é—á–µ–Ω. –í–∫–ª—é—á–∏—Ç–µ –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞.")

        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # Stage 2.2: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —à–∞–±–ª–æ–Ω–æ–º (Pre-Execution only)
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        template_signature = None
        if _is_new_contract and template_file is not None:
            template_bytes = template_file.getvalue()
            template_signature = hashlib.sha256(template_bytes).hexdigest()
        else:
            # –í —Ä–µ–∂–∏–º–µ –±–µ–∑ —à–∞–±–ª–æ–Ω–∞ —É–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è, —á—Ç–æ–±—ã –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ –¥–∞–Ω–Ω—ã–µ
            st.session_state.pop("template_comparison", None)
            st.session_state.pop("template_comparison_signature", None)

        needs_template_comparison = (
            _is_new_contract
            and template_file is not None
            and st.session_state.get("template_comparison_signature") != template_signature
        )

        if needs_template_comparison:
            st.markdown("---")
            st.header("üìã –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —ç—Ç–∞–ª–æ–Ω–Ω—ã–º —à–∞–±–ª–æ–Ω–æ–º (Playbook)")
            st.markdown("–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –≤—ã—è–≤–ª–µ–Ω–∏–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–π —á–µ—Ä–Ω–æ–≤–∏–∫–∞ –æ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞ –∫–æ–º–ø–∞–Ω–∏–∏")

            with st.spinner("üîç –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —á–µ—Ä–Ω–æ–≤–∏–∫–∞ —Å —à–∞–±–ª–æ–Ω–æ–º..."):
                tmp_tpl_path = None
                try:
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç —à–∞–±–ª–æ–Ω–∞
                    with tempfile.NamedTemporaryFile(delete=False, suffix=Path(template_file.name).suffix) as tmp_tpl:
                        tmp_tpl.write(template_file.getvalue())
                        tmp_tpl_path = tmp_tpl.name

                    template_text = extract_text_from_file(tmp_tpl_path, Path(template_file.name).suffix)

                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –¥–æ–≥–æ–≤–æ—Ä–∞ –∏–∑ LLM extraction
                    contract_type = "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π"
                    if result.extracted_data:
                        ct = result.extracted_data.get("metadata", {}).get("doc_type", "")
                        if ct:
                            contract_type = ct

                    # –ó–∞–ø—É—Å–∫–∞–µ–º —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
                    def _run_comparison():
                        loop = asyncio.new_event_loop()
                        try:
                            return loop.run_until_complete(
                                compare_with_template_async(result.raw_text, template_text, contract_type)
                            )
                        finally:
                            loop.close()

                    import concurrent.futures
                    with concurrent.futures.ThreadPoolExecutor() as executor:
                        future = executor.submit(_run_comparison)
                        comparison = future.result(timeout=120)

                    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –≤ session_state
                    st.session_state["template_comparison"] = comparison
                    st.session_state["template_comparison_signature"] = template_signature
                    st.rerun()

                except Exception as e:
                    st.error(f"–û—à–∏–±–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å —à–∞–±–ª–æ–Ω–æ–º: {str(e)}")
                    import traceback
                    st.code(traceback.format_exc())
                finally:
                    if tmp_tpl_path and os.path.exists(tmp_tpl_path):
                        os.unlink(tmp_tpl_path)

        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å —à–∞–±–ª–æ–Ω–æ–º
        if "template_comparison" in st.session_state:
            comparison = st.session_state["template_comparison"]

            st.markdown("---")
            st.header("üìã –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —ç—Ç–∞–ª–æ–Ω–Ω—ã–º —à–∞–±–ª–æ–Ω–æ–º (Playbook)")
            st.markdown("–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –≤—ã—è–≤–ª–µ–Ω–∏–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–π —á–µ—Ä–Ω–æ–≤–∏–∫–∞ –æ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞ –∫–æ–º–ø–∞–Ω–∏–∏")

            # –í–µ—Ä–¥–∏–∫—Ç
            verdict_map = {
                "approved": ("‚úÖ –°–û–û–¢–í–ï–¢–°–¢–í–£–ï–¢", "success"),
                "minor_changes": ("‚ö†Ô∏è –ù–ï–ó–ù–ê–ß–ò–¢–ï–õ–¨–ù–´–ï –û–¢–ö–õ–û–ù–ï–ù–ò–Ø", "warning"),
                "major_changes": ("üî¥ –°–£–©–ï–°–¢–í–ï–ù–ù–´–ï –û–¢–ö–õ–û–ù–ï–ù–ò–Ø", "error"),
                "reject": ("‚ùå –ù–ï –°–û–û–¢–í–ï–¢–°–¢–í–£–ï–¢ –®–ê–ë–õ–û–ù–£", "error"),
            }
            verdict_text, verdict_type = verdict_map.get(comparison.verdict, ("‚ùì", "info"))

            if verdict_type == "success":
                st.success(f"**–í–µ—Ä–¥–∏–∫—Ç:** {verdict_text}")
            elif verdict_type == "warning":
                st.warning(f"**–í–µ—Ä–¥–∏–∫—Ç:** {verdict_text}")
            else:
                st.error(f"**–í–µ—Ä–¥–∏–∫—Ç:** {verdict_text}")

            st.markdown(f"**–ò—Ç–æ–≥:** {comparison.summary}")

            # –ú–µ—Ç—Ä–∏–∫–∏
            mc1, mc2, mc3, mc4, mc5 = st.columns(5)
            with mc1:
                score_delta = "‚úÖ" if comparison.compliance_score >= 80 else ("‚ö†Ô∏è" if comparison.compliance_score >= 60 else "‚ùå")
                st.metric("–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —à–∞–±–ª–æ–Ω—É", f"{comparison.compliance_score}%", delta=score_delta)
            with mc2:
                st.metric("üî¥ –ö—Ä–∏—Ç–∏—á–Ω—ã—Ö", comparison.critical_count)
            with mc3:
                st.metric("üü† –í—ã—Å–æ–∫–∏—Ö", comparison.high_count)
            with mc4:
                st.metric("üü° –°—Ä–µ–¥–Ω–∏—Ö", comparison.medium_count)
            with mc5:
                st.metric("üü¢ –ù–∏–∑–∫–∏—Ö", comparison.low_count)

            # –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∏ –ª–∏—à–Ω–∏–µ —Ä–∞–∑–¥–µ–ª—ã
            if comparison.missing_sections or comparison.extra_sections:
                miss_col, extra_col = st.columns(2)
                with miss_col:
                    if comparison.missing_sections:
                        st.markdown("**‚ùå –†–∞–∑–¥–µ–ª—ã —à–∞–±–ª–æ–Ω–∞, –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –≤ —á–µ—Ä–Ω–æ–≤–∏–∫–µ:**")
                        for ms in comparison.missing_sections:
                            st.error(f"‚Ä¢ {ms}")
                with extra_col:
                    if comparison.extra_sections:
                        st.markdown("**‚ûï –†–∞–∑–¥–µ–ª—ã —á–µ—Ä–Ω–æ–≤–∏–∫–∞, –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –≤ —à–∞–±–ª–æ–Ω–µ:**")
                        for es in comparison.extra_sections:
                            st.info(f"‚Ä¢ {es}")

            # –¢–∞–±–ª–∏—Ü–∞ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–π
            if comparison.deviations:
                st.markdown("---")
                st.subheader(f"üìä –î–µ—Ç–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–π ({comparison.total_deviations})")

                # –§–∏–ª—å—Ç—Ä –ø–æ severity
                severity_filter = st.multiselect(
                    "–§–∏–ª—å—Ç—Ä –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏:",
                    ["critical", "high", "medium", "low"],
                    default=["critical", "high", "medium", "low"],
                    key="severity_filter"
                )

                severity_icons = {
                    "critical": "üî¥",
                    "high": "üü†",
                    "medium": "üü°",
                    "low": "üü¢"
                }
                type_icons = {
                    "missing": "‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç",
                    "modified": "‚úèÔ∏è –ò–∑–º–µ–Ω–µ–Ω–æ",
                    "added": "‚ûï –î–æ–±–∞–≤–ª–µ–Ω–æ",
                    "weakened": "‚¨áÔ∏è –û—Å–ª–∞–±–ª–µ–Ω–æ",
                    "contradicts": "‚ö° –ü—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—Ç"
                }

                for dev_idx, dev in enumerate(comparison.deviations):
                    if dev.severity not in severity_filter:
                        continue

                    sev_icon = severity_icons.get(dev.severity, "‚ùì")
                    type_label = type_icons.get(dev.deviation_type, dev.deviation_type)

                    with st.expander(
                        f"{sev_icon} {dev.section} ‚Äî {type_label}: {dev.description[:80]}...",
                        expanded=(dev.severity in ["critical", "high"])
                    ):
                        st.markdown(f"**–í–∞–∂–Ω–æ—Å—Ç—å:** {sev_icon} {dev.severity.upper()}")
                        st.markdown(f"**–¢–∏–ø –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è:** {type_label}")
                        st.markdown(f"**–û–ø–∏—Å–∞–Ω–∏–µ:** {dev.description}")
                        st.markdown(f"**–†–∏—Å–∫:** {dev.risk}")

                        if dev.template_text:
                            st.markdown("**–¢–µ–∫—Å—Ç –≤ —à–∞–±–ª–æ–Ω–µ (—ç—Ç–∞–ª–æ–Ω):**")
                            st.text_area("", value=dev.template_text, height=100,
                                        key=f"tpl_text_{dev_idx}", disabled=True)

                        if dev.draft_text:
                            st.markdown("**–¢–µ–∫—Å—Ç –≤ —á–µ—Ä–Ω–æ–≤–∏–∫–µ:**")
                            st.text_area("", value=dev.draft_text, height=100,
                                        key=f"draft_text_{dev_idx}", disabled=True)

                        st.markdown(f"**üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** {dev.recommendation}")

                        # –ö–Ω–æ–ø–∫–∏ –¥–µ–π—Å—Ç–≤–∏–π
                        bc1, bc2, bc3 = st.columns(3)
                        with bc1:
                            if st.button("‚úÖ –ü—Ä–∏–Ω—è—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é", key=f"cmp_accept_{dev_idx}", type="primary"):
                                priority_map = {
                                    "critical": "critical",
                                    "high": "important",
                                    "medium": "optional",
                                    "low": "optional",
                                }
                                payload = {
                                    "section_number": dev.section,
                                    "section_title": dev.section,
                                    "original_text": dev.draft_text or dev.template_text or "",
                                    "proposed_text": dev.recommendation,
                                    "reason": f"{dev.description}. –†–∏—Å–∫: {dev.risk}",
                                    "action_type": dev.deviation_type,
                                    "priority": priority_map.get(dev.severity, "optional"),
                                    "source": "template_comparison",
                                    "target": "docx",
                                }
                                added = add_accepted_recommendation(payload)
                                if added:
                                    st.success("‚úÖ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ —Å–ø–∏—Å–æ–∫ –ø—Ä–∞–≤–æ–∫ Stage 2.4.")
                                else:
                                    st.info("‚ÑπÔ∏è –≠—Ç–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è —É–∂–µ –±—ã–ª–∞ –ø—Ä–∏–Ω—è—Ç–∞ —Ä–∞–Ω–µ–µ.")
                        with bc2:
                            if st.button("‚è≠Ô∏è –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å", key=f"cmp_skip_{dev_idx}"):
                                st.info("–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—â–µ–Ω–æ.")
                        with bc3:
                            if st.button("‚ùå –û—Å—Ç–∞–≤–∏—Ç—å –∫–∞–∫ –µ—Å—Ç—å", key=f"cmp_keep_{dev_idx}"):
                                st.warning("–û—Å—Ç–∞–≤–ª–µ–Ω–æ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π.")

        st.markdown("---")
        st.header("üéØ Risk Scoring Engine (Stage 2.3)")

        template_comparison = st.session_state.get("template_comparison")
        template_deviations = 0
        if template_comparison is not None:
            template_deviations = int(getattr(template_comparison, "total_deviations", 0))

        accepted_count = len(st.session_state.get("accepted_recommendations", []))
        result_signature = st.session_state.get("processing_result_signature", "")
        risk_signature = f"{result_signature}:{template_deviations}:{accepted_count}"

        if st.session_state.get("risk_scoring_signature") != risk_signature:
            try:
                from src.services.risk_scorer import RiskScorer

                scorer = RiskScorer()
                risk_scoring = scorer.score(
                    raw_text=result.raw_text,
                    extracted_data=result.extracted_data or {},
                    validation_result=result.validation_result or {},
                    template_comparison=template_comparison,
                    section_analysis=section_analysis_data,
                    accepted_recommendations=st.session_state.get("accepted_recommendations", []),
                )
                st.session_state["risk_scoring"] = risk_scoring
                st.session_state["risk_scoring_signature"] = risk_signature
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ —Ä–∏—Å–∫-—Å–∫–æ—Ä–∏–Ω–≥–∞: {str(e)}")

        risk_scoring = st.session_state.get("risk_scoring")
        if risk_scoring is not None:
            risk_data = risk_scoring.to_dict() if hasattr(risk_scoring, "to_dict") else risk_scoring
            base_level = risk_data.get("risk_level", "low")
            residual_level = risk_data.get("residual_risk_level", "low")

            if base_level == "critical":
                st.error(f"üî¥ **–¢–µ–∫—É—â–∏–π —Ä–∏—Å–∫:** {_risk_level_ru(base_level)}")
            elif base_level == "high":
                st.warning(f"üü† **–¢–µ–∫—É—â–∏–π —Ä–∏—Å–∫:** {_risk_level_ru(base_level)}")
            elif base_level == "medium":
                st.warning(f"üü° **–¢–µ–∫—É—â–∏–π —Ä–∏—Å–∫:** {_risk_level_ru(base_level)}")
            else:
                st.success(f"üü¢ **–¢–µ–∫—É—â–∏–π —Ä–∏—Å–∫:** {_risk_level_ru(base_level)}")

            st.markdown(risk_data.get("summary", ""))

            rc1, rc2, rc3, rc4, rc5 = st.columns(5)
            with rc1:
                st.metric("–ë–∞–∑–æ–≤—ã–π —Ä–∏—Å–∫", f"{risk_data.get('overall_score', 0)}/100")
            with rc2:
                st.metric("–û—Å—Ç–∞—Ç–æ—á–Ω—ã–π —Ä–∏—Å–∫", f"{risk_data.get('mitigated_score', 0)}/100")
            with rc3:
                st.metric("–£—Ä–æ–≤–µ–Ω—å –ø–æ—Å–ª–µ –ø—Ä–∞–≤–æ–∫", _risk_level_ru(residual_level))
            with rc4:
                st.metric("–ö—Ä–∏—Ç–∏—á–Ω—ã—Ö —Ñ–∞–∫—Ç–æ—Ä–æ–≤", risk_data.get("critical_factors", 0))
            with rc5:
                st.metric("–ü—Ä–∏–Ω—è—Ç–æ –ø—Ä–∞–≤–æ–∫", accepted_count)

            factors = risk_data.get("factors", [])
            if factors:
                st.subheader("üìã –§–∞–∫—Ç–æ—Ä—ã —Ä–∏—Å–∫–∞")
                factor_rows = []
                severity_order = {"critical": 4, "high": 3, "medium": 2, "low": 1}
                sorted_factors = sorted(
                    factors,
                    key=lambda x: (
                        severity_order.get(str(x.get("severity", "low")).lower(), 0),
                        int(x.get("points", 0))
                    ),
                    reverse=True
                )
                for item in sorted_factors:
                    factor_rows.append(
                        {
                            "–í–∞–∂–Ω–æ—Å—Ç—å": _risk_level_ru(item.get("severity", "low")),
                            "–§–∞–∫—Ç–æ—Ä": item.get("title", ""),
                            "–ë–∞–ª–ª—ã": item.get("points", 0),
                            "–û–ø–∏—Å–∞–Ω–∏–µ": item.get("description", ""),
                            "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è": item.get("recommendation", ""),
                            "–ò—Å—Ç–æ—á–Ω–∏–∫": item.get("source", ""),
                        }
                    )
                st.dataframe(factor_rows, use_container_width=True)

            section_risks = risk_data.get("section_risks", [])
            if section_risks:
                st.subheader("üìä –†–∏—Å–∫ –ø–æ —Ä–∞–∑–¥–µ–ª–∞–º")
                section_rows = []
                for item in section_risks:
                    section_rows.append(
                        {
                            "–†–∞–∑–¥–µ–ª": f"{item.get('section_number', '')}. {item.get('section_title', '')}",
                            "–†–∏—Å–∫ (0-100)": item.get("score", 0),
                            "–£—Ä–æ–≤–µ–Ω—å": _risk_level_ru(item.get("level", "low")),
                            "–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π": item.get("warnings_count", 0),
                            "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π": item.get("recommendations_count", 0),
                        }
                    )
                st.dataframe(section_rows, use_container_width=True)

        st.markdown("---")
        st.header("üõ†Ô∏è –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏—Ç–æ–≥–æ–≤–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ (Stage 2.4)")

        accepted_recommendations = st.session_state.get("accepted_recommendations", [])
        st.info(f"–ü—Ä–∏–Ω—è—Ç–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏–∏: {len(accepted_recommendations)}")

        if accepted_recommendations:
            preview_rows = []
            for idx, rec in enumerate(accepted_recommendations, 1):
                preview_rows.append(
                    {
                        "‚Ññ": idx,
                        "–†–∞–∑–¥–µ–ª": f"{rec.get('section_number', '')}. {rec.get('section_title', '')}",
                        "–¢–∏–ø": rec.get("action_type", "modify"),
                        "–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç": rec.get("priority", "optional"),
                        "–ò—Å—Ç–æ—á–Ω–∏–∫": rec.get("source", "section_analysis"),
                    }
                )
            st.dataframe(preview_rows, use_container_width=True)

            if _is_new_contract:
                generation_variant = st.radio(
                    "–í—ã–±–µ—Ä–∏—Ç–µ –≤–∞—Ä–∏–∞–Ω—Ç —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞:",
                    ["–í–∞—Ä–∏–∞–Ω—Ç A: –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π DOCX", "–í–∞—Ä–∏–∞–Ω—Ç B: –ü—Ä–æ—Ç–æ–∫–æ–ª —Ä–∞–∑–Ω–æ–≥–ª–∞—Å–∏–π"],
                    horizontal=True,
                    key="stage24_variant",
                )
            else:
                generation_variant = "–í–∞—Ä–∏–∞–Ω—Ç B: –ü—Ä–æ—Ç–æ–∫–æ–ª —Ä–∞–∑–Ω–æ–≥–ª–∞—Å–∏–π"
                st.info("–î–ª—è –ø–æ–¥–ø–∏—Å–∞–Ω–Ω—ã—Ö –¥–æ–≥–æ–≤–æ—Ä–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤–∞—Ä–∏–∞–Ω—Ç B: —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ —Ä–∞–∑–Ω–æ–≥–ª–∞—Å–∏–π.")

            if st.button("‚öôÔ∏è –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏—Ç–æ–≥–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç", key="stage24_generate_btn", type="primary"):
                try:
                    from src.services.stage2_document_generator import Stage2DocumentGenerator

                    generator = Stage2DocumentGenerator()
                    if generation_variant.startswith("–í–∞—Ä–∏–∞–Ω—Ç A"):
                        final_docx = generator.generate_corrected_docx(
                            base_docx_bytes=result.docx_file_bytes,
                            accepted_recommendations=accepted_recommendations,
                            source_file_name=_file_name,
                        )
                        st.session_state["final_corrected_docx"] = final_docx
                        st.session_state.pop("final_protocol_docx", None)
                        st.session_state.pop("final_protocol_json", None)
                        st.success("‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π DOCX —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω.")
                    else:
                        protocol_docx = generator.generate_disagreement_protocol_docx(
                            accepted_recommendations=accepted_recommendations,
                            source_file_name=_file_name,
                        )
                        protocol_json = generator.generate_disagreement_protocol_json(
                            accepted_recommendations=accepted_recommendations
                        )
                        st.session_state["final_protocol_docx"] = protocol_docx
                        st.session_state["final_protocol_json"] = protocol_json
                        st.success("‚úÖ –ü—Ä–æ—Ç–æ–∫–æ–ª —Ä–∞–∑–Ω–æ–≥–ª–∞—Å–∏–π —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω.")
                except Exception as e:
                    st.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {str(e)}")

            fd_col1, fd_col2, fd_col3 = st.columns(3)
            with fd_col1:
                if st.session_state.get("final_corrected_docx"):
                    st.download_button(
                        "üì• –°–∫–∞—á–∞—Ç—å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π DOCX",
                        data=st.session_state["final_corrected_docx"],
                        file_name=f"{Path(_file_name).stem}_corrected.docx",
                        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                        key="download_final_corrected_docx",
                    )
            with fd_col2:
                if st.session_state.get("final_protocol_docx"):
                    st.download_button(
                        "üì• –°–∫–∞—á–∞—Ç—å –ø—Ä–æ—Ç–æ–∫–æ–ª (DOCX)",
                        data=st.session_state["final_protocol_docx"],
                        file_name=f"{Path(_file_name).stem}_protocol.docx",
                        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                        key="download_final_protocol_docx",
                    )
            with fd_col3:
                if st.session_state.get("final_protocol_json"):
                    st.download_button(
                        "üì• –°–∫–∞—á–∞—Ç—å –ø—Ä–æ—Ç–æ–∫–æ–ª (JSON)",
                        data=st.session_state["final_protocol_json"],
                        file_name=f"{Path(_file_name).stem}_protocol.json",
                        mime="application/json",
                        key="download_final_protocol_json",
                    )
        else:
            st.warning("–ü—Ä–∏–º–∏—Ç–µ –º–∏–Ω–∏–º—É–º –æ–¥–Ω—É —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é –≤ —Ä–∞–∑–¥–µ–ª–∞—Ö –∞–Ω–∞–ª–∏–∑–∞ –∏–ª–∏ –≤ —Å—Ä–∞–≤–Ω–µ–Ω–∏–∏ —Å —à–∞–±–ª–æ–Ω–æ–º.")

        st.markdown("---")

        # –§–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        st.header("3Ô∏è‚É£ –ò—Ç–æ–≥–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏")

        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric("‚è±Ô∏è –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏", f"{result.total_time_sec:.1f} —Å–µ–∫")

        with col2:
            st.metric("üí∞ –°—Ç–æ–∏–º–æ—Å—Ç—å", f"${result.total_cost_usd:.5f}")

        with col3:
            st.metric("ü§ñ –ú–æ–¥–µ–ª—å", result.model_used)

        with col4:
            avg_confidence = 0
            for stg in result.stages:
                if stg.name == "llm_extraction":
                    avg_confidence = stg.results.get("confidence", 0)
            st.metric("üéØ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å", f"{avg_confidence*100:.0f}%")

        st.markdown("---")

        # –ö–Ω–æ–ø–∫–∏ –¥–µ–π—Å—Ç–≤–∏–π
        st.header("4Ô∏è‚É£ –î–µ–π—Å—Ç–≤–∏—è —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏")

        col1, col2, col3, col4 = st.columns(4)

        with col1:
            if st.button("‚úÖ –£—Ç–≤–µ—Ä–¥–∏—Ç—å", type="primary", use_container_width=True):
                st.success("‚úÖ –î–æ–∫—É–º–µ–Ω—Ç —É—Ç–≤–µ—Ä–∂–¥–µ–Ω –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö!")
                st.balloons()

        with col2:
            json_data = json.dumps(result.to_dict(), ensure_ascii=False, indent=2)
            st.download_button(
                "üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å JSON",
                json_data,
                file_name=f"contract_analysis_{_file_name}.json",
                mime="application/json",
                use_container_width=True
            )

        with col3:
            # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ DOCX-–≤–µ—Ä—Å–∏–∏ (–≤—Å–µ–≥–¥–∞ –¥–æ—Å—Ç—É–ø–Ω–∞)
            if result.docx_file_bytes:
                st.download_button(
                    "üìÑ –°–∫–∞—á–∞—Ç—å DOCX",
                    data=result.docx_file_bytes,
                    file_name=f"{Path(_file_name).stem}_result.docx",
                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                    use_container_width=True,
                    key="download_docx_final"
                )

        with col4:
            if st.button("‚ùå –û—Ç–∫–ª–æ–Ω–∏—Ç—å", use_container_width=True):
                st.error("–î–æ–∫—É–º–µ–Ω—Ç –æ—Ç–∫–ª–æ–Ω–µ–Ω")

        # –ü—Ä–æ—Ç–æ–∫–æ–ª —Ä–∞–∑–Ω–æ–≥–ª–∞—Å–∏–π (—Ç–æ–ª—å–∫–æ –¥–ª—è –ø–æ–¥–ø–∏—Å–∞–Ω–Ω—ã—Ö –¥–æ–≥–æ–≤–æ—Ä–æ–≤)
        if not _is_new_contract and st.session_state.get("accepted_recommendations"):
            st.markdown("---")
            st.header("üìã –ü—Ä–æ—Ç–æ–∫–æ–ª —Ä–∞–∑–Ω–æ–≥–ª–∞—Å–∏–π (–ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä)")
            st.info(f"–°–æ–±—Ä–∞–Ω–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {len(st.session_state.get('accepted_recommendations', []))}")

            protocol_data = []
            for i, rec in enumerate(st.session_state.get("accepted_recommendations", []), 1):
                protocol_data.append({
                    "‚Ññ": i,
                    "–†–∞–∑–¥–µ–ª": f"{rec.get('section_number', '')}. {rec.get('section_title', '')}",
                    "–¢–µ–∫—Å—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª–∞": rec.get("original_text", ""),
                    "–ü—Ä–µ–¥–ª–∞–≥–∞–µ–º–∞—è —Ä–µ–¥–∞–∫—Ü–∏—è": rec.get("proposed_text", ""),
                    "–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ": rec.get("reason", "")
                })

            st.dataframe(protocol_data, use_container_width=True)

            st.caption("–î–ª—è –≤—ã–≥—Ä—É–∑–∫–∏ DOCX/JSON –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–ª–æ–∫ Stage 2.4 –≤—ã—à–µ.")

else:
    st.info("üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –¥–æ–≥–æ–≤–æ—Ä–∞ –¥–ª—è –Ω–∞—á–∞–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏")

    # –°—Å—ã–ª–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
    st.markdown("---")
    st.markdown("**üí° –î–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:** –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ–∞–π–ª `tests/fixtures/test_supply_contract.txt`")

st.markdown("---")
st.caption("Contract AI System v2.0 - –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ | –ú–æ–¥–µ–ª–∏ 2026: Claude Opus/Sonnet 4.5, GPT-4.1, DeepSeek-V3.2, Qwen2.5-VL-72B (119 —è–∑—ã–∫–æ–≤)")
