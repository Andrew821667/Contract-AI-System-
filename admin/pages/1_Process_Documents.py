"""
–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ - "–°—Ç–µ–∫–ª—è–Ω–Ω—ã–π —è—â–∏–∫"
–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –í–°–ï –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –¥–≤–∞ —Ä–µ–∂–∏–º–∞: "–ù–æ–≤—ã–π –¥–æ–≥–æ–≤–æ—Ä" –∏ "–ü–æ–¥–ø–∏—Å–∞–Ω–Ω—ã–π –¥–æ–≥–æ–≤–æ—Ä"
"""

import streamlit as st
import sys
from pathlib import Path
import asyncio
import json
import os
import tempfile
import pandas as pd
from typing import Dict, Any
import io

# Add project root to path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

st.set_page_config(
    page_title="–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ - Contract AI",
    page_icon="üìÑ",
    layout="wide"
)

st.title("üìÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
st.markdown("**–°—Ç–µ–∫–ª—è–Ω–Ω—ã–π —è—â–∏–∫:** –≤–∏–¥–Ω—ã –≤—Å–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–∞–±–æ—Ç—ã —Å–∏—Å—Ç–µ–º—ã")

st.markdown("---")

# –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞
st.header("1Ô∏è‚É£ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞")

# –í—ã–±–æ—Ä —Ä–µ–∂–∏–º–∞ —Ä–∞–±–æ—Ç—ã
contract_mode = st.radio(
    "–†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã —Å –¥–æ–≥–æ–≤–æ—Ä–æ–º:",
    ["–ù–æ–≤—ã–π –¥–æ–≥–æ–≤–æ—Ä (Pre-Execution)", "–ü–æ–¥–ø–∏—Å–∞–Ω–Ω—ã–π –¥–æ–≥–æ–≤–æ—Ä (Post-Execution)"],
    help="**–ù–æ–≤—ã–π –¥–æ–≥–æ–≤–æ—Ä** ‚Äî –ø—Ä–∞–≤–∫–∏ –≤–Ω–æ—Å—è—Ç—Å—è –ø—Ä—è–º–æ –≤ DOCX-–¥–æ–∫—É–º–µ–Ω—Ç.\n\n"
         "**–ü–æ–¥–ø–∏—Å–∞–Ω–Ω—ã–π –¥–æ–≥–æ–≤–æ—Ä** ‚Äî –æ—Ä–∏–≥–∏–Ω–∞–ª –Ω–µ —Ç—Ä–æ–≥–∞–µ–º, —Ñ–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ—Ç–æ–∫–æ–ª —Ä–∞–∑–Ω–æ–≥–ª–∞—Å–∏–π.",
    horizontal=True
)

is_new_contract = contract_mode.startswith("–ù–æ–≤—ã–π")

uploaded_file = st.file_uploader(
    "–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª –¥–æ–≥–æ–≤–æ—Ä–∞",
    type=['pdf', 'docx', 'txt', 'xml', 'html', 'htm', 'png', 'jpg', 'jpeg'],
    help="–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è: PDF, DOCX, TXT, XML, HTML, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (—Å OCR)"
)

# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è async –æ–±—Ä–∞–±–æ—Ç–∫–∏
async def process_document_async(file_path, file_ext, use_section_analysis=False):
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º fallback"""
    from src.services.document_processor import DocumentProcessor
    import os
    from dotenv import load_dotenv

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env —Ñ–∞–π–ª–∞
    project_root = Path(__file__).parent.parent.parent
    env_path = project_root / ".env"
    load_dotenv(env_path)

    # DeepSeek ‚Äî –æ—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å (–¥–µ—à–µ–≤–ª–µ, $0.14/1M —Ç–æ–∫–µ–Ω–æ–≤)
    # GPT-4o-mini ‚Äî fallback
    deepseek_key = os.getenv("DEEPSEEK_API_KEY")
    openai_key = os.getenv("OPENAI_API_KEY")

    if deepseek_key:
        api_key = deepseek_key
        base_url = os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com/v1")
        model = os.getenv("DEEPSEEK_MODEL", "deepseek-chat")
    elif openai_key:
        api_key = openai_key
        base_url = None
        model = os.getenv("OPENAI_MODEL_MINI", "gpt-4o-mini")
    else:
        raise ValueError(
            "API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω.\n"
            "–î–æ–±–∞–≤—å—Ç–µ –≤ .env: OPENAI_API_KEY=... –∏–ª–∏ DEEPSEEK_API_KEY=..."
        )

    processor = DocumentProcessor(
        api_key=api_key,
        model=model,
        base_url=base_url,
        use_rag=False,
        use_section_analysis=use_section_analysis
    )

    result = await processor.process_document(file_path, file_ext)
    return result


def render_docx_preview(docx_bytes: bytes) -> str:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç DOCX bytes –≤ HTML —á–µ—Ä–µ–∑ mammoth –¥–ª—è –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä–∞"""
    try:
        import mammoth
        result = mammoth.convert_to_html(io.BytesIO(docx_bytes))
        html = result.value
        # –û–±–æ—Ä–∞—á–∏–≤–∞–µ–º –≤ —Å—Ç–∏–ª–∏ –¥–ª—è –ª—É—á—à–µ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        styled_html = f"""
        <div style="background: white; color: black; padding: 20px; border: 1px solid #ddd;
                    border-radius: 8px; font-family: 'Times New Roman', serif; line-height: 1.6;
                    max-height: 600px; overflow-y: auto;">
            {html}
        </div>
        """
        return styled_html
    except Exception as e:
        return f"<p style='color:red;'>–û—à–∏–±–∫–∞ –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä–∞: {e}</p>"


def get_entity_purpose(entity_type: str) -> str:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ö–û–ù–ö–†–ï–¢–ù–û–ï –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–∏ –≤ —Å–∏—Å—Ç–µ–º–µ"""
    purposes = {
        "contract_number": "üìù –ü–µ—Ä–≤–∏—á–Ω—ã–π –∫–ª—é—á –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –≤ –ë–î (—Ç–∞–±–ª–∏—Ü–∞ contracts, –ø–æ–ª–µ contract_id). –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –ø–æ–∏—Å–∫–∞ –¥–æ–≥–æ–≤–æ—Ä–∞ —á–µ—Ä–µ–∑ UI, API endpoints (/api/contracts/{id}), —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–æ–≤–æ–≥–æ –∏–º–µ–Ω–∏ –ø—Ä–∏ —ç–∫—Å–ø–æ—Ä—Ç–µ",
        "date": "üìÖ –ó–∞–ø–æ–ª–Ω—è–µ—Ç –ø–æ–ª—è: contract_date, start_date, end_date –≤ —Ç–∞–±–ª–∏—Ü–µ contracts. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è: –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π –æ —Å—Ä–æ–∫–∞—Ö (–º–æ–¥—É–ª—å notifications), —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –¥–∞—Ç–∞–º –≤ UI (—Å—Ç—Ä–∞–Ω–∏—Ü–∞ Contract List), –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç–∏ –¥–æ–≥–æ–≤–æ—Ä–∞, —Ä–∞—Å—á–µ—Ç–∞ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–æ–≥–æ–≤–æ—Ä–∞",
        "inn": "üè¢ –°–≤—è–∑—ã–≤–∞–Ω–∏–µ —Å —Ç–∞–±–ª–∏—Ü–µ–π counterparties (foreign key counterparty_inn). –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è: –∞–≤—Ç–æ–∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –∫–∞—Ä—Ç–æ—á–∫–∏ –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞, –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤ –§–ù–° —á–µ—Ä–µ–∑ API –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é, –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–æ–≤, –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∞ –≤–∑–∞–∏–º–æ—Å–≤—è–∑–µ–π –∫–æ–º–ø–∞–Ω–∏–π, —Ä–∏—Å–∫-–∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞",
        "ogrn": "üîê –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–µ–≥–∏—Ç–∏–º–Ω–æ—Å—Ç–∏ —é—Ä–ª–∏—Ü–∞ —á–µ—Ä–µ–∑ API –§–ù–°/–ï–ì–†–Æ–õ. –°–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤ counterparties.ogrn. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏, –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–∞—Ç—ã —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –∫–æ–º–ø–∞–Ω–∏–∏, –ø—Ä–æ–≤–µ—Ä–∫–∏ –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç–∏ —é—Ä–ª–∏—Ü–∞",
        "kpp": "üè¶ –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –∫–æ–º–ø–∞–Ω–∏–∏ (counterparties.kpp). –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è: –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ñ–∏–ª–∏–∞–ª–∞/–æ–±–æ—Å–æ–±–ª–µ–Ω–Ω–æ–≥–æ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è, –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –æ—Ç–ø—Ä–∞–≤–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–∞ –Ω—É–∂–Ω—ã–π –∞–¥—Ä–µ—Å, –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –¥–æ–≥–æ–≤–æ—Ä–æ–≤ –ø–æ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è–º",
        "amount": "üí∞ –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –ø–æ–ª—è: total_amount, currency, vat_amount –≤ —Ç–∞–±–ª–∏—Ü–µ contracts. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è: –ø–æ–¥—Å—á–µ—Ç–∞ –æ–±—â–µ–π —Å—É–º–º—ã –ø–æ—Ä—Ç—Ñ–µ–ª—è –¥–æ–≥–æ–≤–æ—Ä–æ–≤ (Dashboard Analytics), –ª–∏–º–∏—Ç-–∫–æ–Ω—Ç—Ä–æ–ª—è (–ø—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–µ–≤—ã—à–µ–Ω–∏—è –±—é–¥–∂–µ—Ç–∞), —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –æ—Ç—á–µ—Ç–æ–≤, –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è cash flow",
        "organization": "üèõÔ∏è –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏–π –∫–æ–º–ø–∞–Ω–∏–π –¥–ª—è –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è counterparties.name. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è: —Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤–æ–π –∑–∞–ø–∏—Å–∏ –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞, fuzzy-match –ø–æ–∏—Å–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–æ–≤ (–∏–∑–±–µ–≥–∞–Ω–∏–µ –¥—É–±–ª–µ–π), –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ UI —Å–ø–∏—Å–∫–∞ —Å—Ç–æ—Ä–æ–Ω –¥–æ–≥–æ–≤–æ—Ä–∞",
        "person": "üë§ –§–ò–û –ø–æ–¥–ø–∏—Å–∞–Ω—Ç–æ–≤ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ —Ç–∞–±–ª–∏—Ü–µ signatories (fields: full_name, position, authority_document). –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è: –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–ª–Ω–æ–º–æ—á–∏–π –ø–æ–¥–ø–∏—Å–∞–Ω—Ç–∞, –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –ø—Ä–∞–≤–∞ –ø–æ–¥–ø–∏—Å–∏ (cross-check —Å –¥–æ–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—è–º–∏), —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–π –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏ –¥–æ–≥–æ–≤–æ—Ä–∞",
        "address": "üìç –Æ—Ä. –∏ —Ñ–∞–∫—Ç. –∞–¥—Ä–µ—Å–∞ –≤ counterparties.legal_address –∏ counterparties.actual_address. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è: —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ—á—Ç–æ–≤—ã—Ö —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π, –≥–µ–æ–ª–æ–∫–∞—Ü–∏–∏ –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –∫–∞—Ä—Ç–µ (UI Dashboard), –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –∞–¥—Ä–µ—Å–æ–≤ (fraud detection)",
        "phone": "üìû –ö–æ–Ω—Ç–∞–∫—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ counterparties.phone –∏ contacts.phone. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è: –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –∑–≤–æ–Ω–∫–æ–≤/SMS —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π –æ —Å—Ä–æ–∫–∞—Ö, —Å–≤—è–∑–∏ —Å –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–æ–º —á–µ—Ä–µ–∑ CRM –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é, –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Ñ–æ—Ä–º–∞—Ç–∞ —Ç–µ–ª–µ—Ñ–æ–Ω–∞",
        "email": "üìß Email –∞–¥—Ä–µ—Å–∞ –≤ counterparties.email –∏ contacts.email. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è: –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ—Ç–ø—Ä–∞–≤–∫–∏ email —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π (–∏—Å—Ç–µ—á–µ–Ω–∏–µ —Å—Ä–æ–∫–∞, –∏–∑–º–µ–Ω–µ–Ω–∏—è), –ø—Ä–∏–≥–ª–∞—à–µ–Ω–∏–π –≤ —Å–∏—Å—Ç–µ–º—É –¥–ª—è –ø–æ–¥–ø–∏—Å–∞–Ω–∏—è, –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å email-–∫–ª–∏–µ–Ω—Ç–æ–º",
        "account": "üí≥ –ë–∞–Ω–∫–æ–≤—Å–∫–∏–µ —Å—á–µ—Ç–∞ –≤ counterparties.bank_account. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è: –∞–≤—Ç–æ–∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –ø–ª–∞—Ç–µ–∂–Ω—ã—Ö –ø–æ—Ä—É—á–µ–Ω–∏–π, –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ —Ä/—Å —á–µ—Ä–µ–∑ API –¶–ë –†–§, —Å–≤—è–∑—ã–≤–∞–Ω–∏—è —Å —Ç–∞–±–ª–∏—Ü–µ–π payments –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –æ–ø–ª–∞—Ç",
        "bic": "üè¶ –ë–ò–ö –±–∞–Ω–∫–∞ –≤ counterparties.bank_bic. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è: –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è –±–∞–Ω–∫–∞ —á–µ—Ä–µ–∑ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫ –¶–ë –†–§, –∞–≤—Ç–æ–∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è –±–∞–Ω–∫–∞ –∏ –∫–æ—Ä—Ä. —Å—á–µ—Ç–∞, –ø—Ä–æ–≤–µ—Ä–∫–∏ –±–∞–Ω–∫–∞ –Ω–∞ —Å–∞–Ω–∫—Ü–∏–æ–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏",
        "percent": "üìä –ü—Ä–æ—Ü–µ–Ω—Ç–Ω—ã–µ —Å—Ç–∞–≤–∫–∏ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ contract_terms.penalty_rate, discount_rate, interest_rate. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è: –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞—Å—á–µ—Ç–∞ –ø–µ–Ω–µ–π –∑–∞ –ø—Ä–æ—Å—Ä–æ—á–∫—É, –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —Å–∫–∏–¥–æ–∫, –Ω–∞—á–∏—Å–ª–µ–Ω–∏—è –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤ –ø–æ –¥–æ–≥–æ–≤–æ—Ä–∞–º –∑–∞–π–º–∞/–∫—Ä–µ–¥–∏—Ç–∞",
        "payment_term": "‚è∞ –£—Å–ª–æ–≤–∏—è –æ–ø–ª–∞—Ç—ã –≤ contracts.payment_terms (–ø—Ä–µ–¥–æ–ø–ª–∞—Ç–∞/–ø–æ—Å—Ç–æ–ø–ª–∞—Ç–∞/—Ä–∞—Å—Å—Ä–æ—á–∫–∞). –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è: –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –ø–ª–∞—Ç–µ–∂–µ–π –≤ –º–æ–¥—É–ª–µ Finance, —Å–æ–∑–¥–∞–Ω–∏—è –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏–π –æ –ø–ª–∞—Ç–µ–∂–∞—Ö, —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–∞ –ø–ª–∞—Ç–µ–∂–µ–π",
        "delivery_address": "üöö –ê–¥—Ä–µ—Å –ø–æ—Å—Ç–∞–≤–∫–∏ –≤ contracts.delivery_address. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è: –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è, –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω—ã–º–∏ –∫–æ–º–ø–∞–Ω–∏—è–º–∏, —Ä–∞—Å—á–µ—Ç–∞ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –¥–æ—Å—Ç–∞–≤–∫–∏",
        "warranty_period": "üõ°Ô∏è –ì–∞—Ä–∞–Ω—Ç–∏–π–Ω—ã–π —Å—Ä–æ–∫ –≤ contract_terms.warranty_months. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è: –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –≥–∞—Ä–∞–Ω—Ç–∏–π–Ω—ã—Ö –æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏–π –æ–± –æ–∫–æ–Ω—á–∞–Ω–∏–∏ –≥–∞—Ä–∞–Ω—Ç–∏–∏, —É—á–µ—Ç–∞ –≥–∞—Ä–∞–Ω—Ç–∏–π–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤"
    }
    # –ï—Å–ª–∏ —Ç–∏–ø –Ω–µ –Ω–∞–π–¥–µ–Ω - –≤–µ—Ä–Ω—É—Ç—å –¥–µ—Ç–∞–ª—å–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ
    if entity_type not in purposes:
        return f"‚ùì –°—É—â–Ω–æ—Å—Ç—å '{entity_type}' –Ω–µ –∏–º–µ–µ—Ç —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ–≥–æ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è. –°–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤ contracts.metadata (JSON) –¥–ª—è —Å–ø—Ä–∞–≤–æ—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏ –ø–æ–ª–Ω–æ—Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞"
    return purposes.get(entity_type)


def get_optimal_model_info(stage: str) -> tuple[str, str]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è —ç—Ç–∞–ø–∞ (–∞–∫—Ç—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ 2026)"""
    models = {
        "text_extraction": (
            "N/A (–ø—Ä—è–º–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ)",
            "pdfplumber + PaddleOCR –¥–ª—è —Å–∫–∞–Ω–æ–≤ + LayoutLMv3 –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –º–∞–∫–µ—Ç–æ–≤"
        ),
        "level1": (
            "regex + SpaCy (ru_core_news_sm)",
            "SpaCy ru_core_news_lg, DeepPavlov NER, –∏–ª–∏ Qwen2.5-VL-72B (119 —è–∑—ã–∫–æ–≤!) –¥–ª—è –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"
        ),
        "llm": (
            "gpt-4o-mini ($0.15/$0.6 per 1M) –∏–ª–∏ DeepSeek-V3.2 ($0.25/$0.38 per 1M)",
            "–õ—É—á—à–∏–µ –≤ 2026: GPT-4.1 ($2/$8, 1M context), Claude Sonnet 4.5 ($3/$15), DeepSeek-V3.2 ($0.25/$0.38, —ç–∫–æ–Ω–æ–º–∏—è 90%!), Qwen2.5-VL-72B (119 —è–∑—ã–∫–æ–≤, –≤–∏–∑—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑)"
        ),
        "rag": (
            "pgvector + text-embedding-3-large",
            "OpenAI text-embedding-3-large –∏–ª–∏ Cohere embed-multilingual-v3.0 –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ –∏ –º–Ω–æ–≥–æ—è–∑—ã—á–Ω—ã—Ö –¥–æ–≥–æ–≤–æ—Ä–æ–≤"
        ),
        "validation": (
            "Business rules + Pydantic",
            "–¢–æ–ø-3 –≤ 2026: Claude Opus 4.5 ($5/$25, —Å–∞–º—ã–π —Ç–æ—á–Ω—ã–π), GPT-4.1 ($2/$8, 1M context), Qwen2.5-VL-72B (–º–Ω–æ–≥–æ—è–∑—ã—á–Ω—ã–π + –≤–∏–∑—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑)"
        ),
        "section_analysis": (
            "DeepSeek-V3.2 ($0.25/$0.38 per 1M) –∏–ª–∏ gpt-4o-mini ($0.15/$0.6)",
            "–û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ: DeepSeek-V3.2 (90% —ç–∫–æ–Ω–æ–º–∏—è!), Claude Sonnet 4.5 ($3/$15, —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑), GPT-4.1 ($2/$8, –¥–ª–∏–Ω–Ω—ã–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã 1M)"
        )
    }
    return models.get(stage, ("N/A", "N/A"))


def display_validation_section_dynamic(section_analysis_data: Dict[str, Any], is_new_contract: bool = True):
    """–û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é –≤–∞–ª–∏–¥–∞—Ü–∏—é –ø–æ —Ä–∞–∑–¥–µ–ª–∞–º –¥–æ–≥–æ–≤–æ—Ä–∞ (–î–ò–ù–ê–ú–ò–ß–ï–°–ö–ò –∏–∑ LLM)"""

    if not section_analysis_data:
        st.warning("–ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–¥–µ–ª–æ–≤ –Ω–µ –±—ã–ª –≤—ã–ø–æ–ª–Ω–µ–Ω")
        return

    st.subheader("üìã –î–µ—Ç–∞–ª—å–Ω—ã–π —Ä–∞–∑–±–æ—Ä –ø–æ —Ä–∞–∑–¥–µ–ª–∞–º –¥–æ–≥–æ–≤–æ—Ä–∞")

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º
    if is_new_contract:
        st.info("üìù **–†–µ–∂–∏–º: –ù–æ–≤—ã–π –¥–æ–≥–æ–≤–æ—Ä** ‚Äî –ø—Ä–∏–Ω—è—Ç—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –±—É–¥—É—Ç –≤–Ω–µ—Å–µ–Ω—ã –≤ DOCX-–¥–æ–∫—É–º–µ–Ω—Ç")
    else:
        st.info("üìã **–†–µ–∂–∏–º: –ü–æ–¥–ø–∏—Å–∞–Ω–Ω—ã–π –¥–æ–≥–æ–≤–æ—Ä** ‚Äî –ø—Ä–∏–Ω—è—Ç—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –±—É–¥—É—Ç —Å–æ–±—Ä–∞–Ω—ã –≤ –ø—Ä–æ—Ç–æ–∫–æ–ª —Ä–∞–∑–Ω–æ–≥–ª–∞—Å–∏–π")

    sections = section_analysis_data.get("sections", [])
    section_analyses = section_analysis_data.get("section_analyses", [])
    complex_analysis = section_analysis_data.get("complex_analysis")

    if not sections:
        st.warning("–†–∞–∑–¥–µ–ª—ã –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã –≤ –¥–æ–≥–æ–≤–æ—Ä–µ")
        return

    st.info(f"**–ù–∞–π–¥–µ–Ω–æ —Ä–∞–∑–¥–µ–ª–æ–≤:** {len(sections)} | **–ü–æ—Ä—è–¥–æ–∫ –ø—Ä–æ–≤–µ—Ä–∫–∏:** 1Ô∏è‚É£ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ –¥–æ–≥–æ–≤–æ—Ä–∞–º–∏ ‚Üí 2Ô∏è‚É£ –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ RAG –±–∞–∑–µ (–∞–∫—Ç—É–∞–ª—å–Ω–∞—è –ø—Ä–∞–≤–æ–≤–∞—è –±–∞–∑–∞) ‚Üí 3Ô∏è‚É£ –§–æ–ª–±—ç–∫ –Ω–∞ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π –º–æ–¥–µ–ª–∏")

    # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ —Å–æ–∑–¥–∞–µ–º –≤–∫–ª–∞–¥–∫–∏
    tab_names = [f"–†–∞–∑–¥–µ–ª {s.number}" for s in sections] + ["üîç –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑"]
    tabs = st.tabs(tab_names)

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–Ω—è—Ç—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ —Ä–∞–∑–Ω–æ–≥–ª–∞—Å–∏–π
    if "accepted_recommendations" not in st.session_state:
        st.session_state.accepted_recommendations = []

    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –∫–∞–∂–¥—ã–π —Ä–∞–∑–¥–µ–ª –î–ò–ù–ê–ú–ò–ß–ï–°–ö–ò
    for idx, (section, analysis) in enumerate(zip(sections, section_analyses)):
        with tabs[idx]:
            st.markdown(f"### üìÑ –†–∞–∑–¥–µ–ª {section.number}: {section.title}")

            # –¢–µ–∫—Å—Ç —Ä–∞–∑–¥–µ–ª–∞
            st.text_area("–¢–µ–∫—Å—Ç —Ä–∞–∑–¥–µ–ª–∞:", section.text, height=150, key=f"section_{section.number}_text")

            st.markdown("---")

            # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ –¥–æ–≥–æ–≤–æ—Ä–∞–º–∏
            st.markdown("**1Ô∏è‚É£ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ –¥–æ–≥–æ–≤–æ—Ä–∞–º–∏:**")
            if analysis.own_contracts_comparison.startswith("‚úÖ"):
                st.success(analysis.own_contracts_comparison)
            elif analysis.own_contracts_comparison.startswith("‚ö†Ô∏è"):
                st.warning(analysis.own_contracts_comparison)
            else:
                st.error(analysis.own_contracts_comparison)

            # –î–µ—Ç–∞–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
            if analysis.own_contracts_details:
                st.dataframe(analysis.own_contracts_details, use_container_width=True)

            # RAG –ø—Ä–æ–≤–µ—Ä–∫–∞
            st.markdown("**2Ô∏è‚É£ –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ RAG (–∞–∫—Ç—É–∞–ª—å–Ω–∞—è –ø—Ä–∞–≤–æ–≤–∞—è –±–∞–∑–∞):**")
            st.info(analysis.rag_legal_check)

            if analysis.rag_legal_references:
                st.markdown("**–°—Å—ã–ª–∫–∏ –Ω–∞ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ:**")
                for ref in analysis.rag_legal_references:
                    st.markdown(f"- {ref}")

            st.markdown("---")

            # –í—ã–≤–æ–¥—ã –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            if analysis.conclusion.startswith("–†–∞–∑–¥–µ–ª –ø—Ä–æ—Ä–∞–±–æ—Ç–∞–Ω —Ö–æ—Ä–æ—à–æ") or "—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç" in analysis.conclusion.lower():
                st.success(f"**–í—ã–≤–æ–¥:** {analysis.conclusion}")
            elif "—Ç—Ä–µ–±—É–µ—Ç" in analysis.conclusion.lower() or "–¥–æ—Ä–∞–±–æ—Ç–∫" in analysis.conclusion.lower():
                st.warning(f"**–í—ã–≤–æ–¥:** {analysis.conclusion}")
            else:
                st.info(f"**–í—ã–≤–æ–¥:** {analysis.conclusion}")

            if analysis.warnings:
                st.markdown("**‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è:**")
                for warning in analysis.warnings:
                    st.warning(warning)

            if analysis.recommendations:
                st.markdown("**üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é:**")
                for i, rec in enumerate(analysis.recommendations):
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ü–≤–µ—Ç –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
                    if hasattr(rec, 'priority'):
                        if rec.priority == "critical":
                            priority_badge = "üî¥ **–ö–†–ò–¢–ò–ß–ù–û**"
                        elif rec.priority == "important":
                            priority_badge = "üü° **–í–ê–ñ–ù–û**"
                        else:
                            priority_badge = "üü¢ **–†–ï–ö–û–ú–ï–ù–î–û–í–ê–ù–û**"
                    else:
                        priority_badge = "üí°"

                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –¥–µ–π—Å—Ç–≤–∏—è
                    if hasattr(rec, 'action_type'):
                        if rec.action_type == "add":
                            action_badge = "‚ûï –î–æ–±–∞–≤–∏—Ç—å"
                        elif rec.action_type == "modify":
                            action_badge = "‚úèÔ∏è –ò–∑–º–µ–Ω–∏—Ç—å"
                        elif rec.action_type == "remove":
                            action_badge = "‚ùå –£–¥–∞–ª–∏—Ç—å"
                        else:
                            action_badge = "‚úèÔ∏è –ò–∑–º–µ–Ω–∏—Ç—å"
                    else:
                        action_badge = "‚úèÔ∏è –ò–∑–º–µ–Ω–∏—Ç—å"

                    with st.container():
                        st.markdown(f"##### {priority_badge} | {action_badge}")

                        # –ü—Ä–∏—á–∏–Ω–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
                        if hasattr(rec, 'reason'):
                            st.markdown(f"**–ü—Ä–∏—á–∏–Ω–∞:** {rec.reason}")
                        else:
                            st.markdown(f"**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** {rec}")

                        # –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º—ã–π —Ç–µ–∫—Å—Ç
                        if hasattr(rec, 'proposed_text') and rec.proposed_text:
                            st.markdown("**–ü—Ä–µ–¥–ª–∞–≥–∞–µ–º—ã–π —Ç–µ–∫—Å—Ç –ø—É–Ω–∫—Ç–∞:**")
                            st.text_area(
                                label="",
                                value=rec.proposed_text,
                                height=150,
                                key=f"rec_{section.number}_{i}",
                                label_visibility="collapsed"
                            )

                            # –ö–Ω–æ–ø–∫–∏ –¥–µ–π—Å—Ç–≤–∏–π ‚Äî –∑–∞–≤–∏—Å—è—Ç –æ—Ç —Ä–µ–∂–∏–º–∞
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                accept_label = "‚úÖ –ü—Ä–∏–Ω—è—Ç—å –≤ DOCX" if is_new_contract else "‚úÖ –í –ø—Ä–æ—Ç–æ–∫–æ–ª —Ä–∞–∑–Ω–æ–≥–ª–∞—Å–∏–π"
                                if st.button(accept_label, key=f"accept_{section.number}_{i}", type="primary"):
                                    if is_new_contract:
                                        st.success("‚úÖ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –ø—Ä–∏–Ω—è—Ç–∞. –ü—Ä–∞–≤–∫–∞ –±—É–¥–µ—Ç –≤–Ω–µ—Å–µ–Ω–∞ –≤ DOCX-–¥–æ–∫—É–º–µ–Ω—Ç.")
                                    else:
                                        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –ø—Ä–æ—Ç–æ–∫–æ–ª —Ä–∞–∑–Ω–æ–≥–ª–∞—Å–∏–π
                                        st.session_state.accepted_recommendations.append({
                                            "section_number": section.number,
                                            "section_title": section.title,
                                            "original_text": section.text[:200] + "...",
                                            "proposed_text": rec.proposed_text,
                                            "reason": rec.reason if hasattr(rec, 'reason') else str(rec)
                                        })
                                        st.success("‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ –≤ –ø—Ä–æ—Ç–æ–∫–æ–ª —Ä–∞–∑–Ω–æ–≥–ª–∞—Å–∏–π.")
                            with col2:
                                if st.button("‚úèÔ∏è –†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å", key=f"edit_{section.number}_{i}"):
                                    st.info("‚úèÔ∏è –û—Ç–∫—Ä–æ–π—Ç–µ —Ä–µ–¥–∞–∫—Ç–æ—Ä –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞.")
                            with col3:
                                if st.button("‚ùå –û—Ç–∫–ª–æ–Ω–∏—Ç—å", key=f"reject_{section.number}_{i}"):
                                    st.warning("‚ùå –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –æ—Ç–∫–ª–æ–Ω–µ–Ω–∞.")

                        st.markdown("---")

    # –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (–ø–æ—Å–ª–µ–¥–Ω—è—è –≤–∫–ª–∞–¥–∫–∞)
    with tabs[-1]:
        st.markdown("### üîç –ö–û–ú–ü–õ–ï–ö–°–ù–´–ô –ê–ù–ê–õ–ò–ó –î–û–ì–û–í–û–†–ê")
        st.markdown("–ê–Ω–∞–ª–∏–∑ –≤–∑–∞–∏–º–æ—Å–≤—è–∑–µ–π –º–µ–∂–¥—É —Ä–∞–∑–¥–µ–ª–∞–º–∏ –∏ –æ–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞")

        if not complex_analysis:
            st.warning("–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω")
            return

        st.markdown("---")
        st.markdown("#### 1Ô∏è‚É£ –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ –∏ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏")
        if complex_analysis.integrity_checks:
            st.dataframe(complex_analysis.integrity_checks, use_container_width=True)

        st.markdown("---")
        st.markdown("#### 2Ô∏è‚É£ –Æ—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ —Ä–∏—Å–∫–∏")

        risk_col1, risk_col2, risk_col3 = st.columns(3)

        with risk_col1:
            st.markdown("**üü¢ –ù–ò–ó–ö–ò–ô –†–ò–°–ö:**")
            for risk in complex_analysis.risk_assessment.get("low", []):
                st.success(f"‚úÖ {risk}")

        with risk_col2:
            st.markdown("**üü° –°–†–ï–î–ù–ò–ô –†–ò–°–ö:**")
            for risk in complex_analysis.risk_assessment.get("medium", []):
                st.warning(f"‚ö†Ô∏è {risk}")

        with risk_col3:
            st.markdown("**üî¥ –í–´–°–û–ö–ò–ô –†–ò–°–ö:**")
            for risk in complex_analysis.risk_assessment.get("high", []):
                st.error(f"‚ùå {risk}")

        st.markdown("---")
        st.markdown("#### 3Ô∏è‚É£ –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤—É –†–§")
        if complex_analysis.legal_compliance:
            st.dataframe(complex_analysis.legal_compliance, use_container_width=True)

        st.markdown("---")
        st.markdown("#### 4Ô∏è‚É£ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –ª—É—á—à–∏–º–∏ –ø—Ä–∞–∫—Ç–∏–∫–∞–º–∏")
        st.info("**–ò—Å—Ç–æ—á–Ω–∏–∫:** –ê–Ω–∞–ª–∏–∑ –ø–æ—Ö–æ–∂–∏—Ö –¥–æ–≥–æ–≤–æ—Ä–æ–≤ –∏–∑ –±–∞–∑—ã + RAG –∞–∫—Ç—É–∞–ª—å–Ω–∞—è –ø—Ä–∞–≤–æ–≤–∞—è –±–∞–∑–∞ + –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –º–æ–¥–µ–ª–∏")
        if complex_analysis.best_practices:
            st.dataframe(complex_analysis.best_practices, use_container_width=True)

        st.markdown("---")
        st.markdown("#### 5Ô∏è‚É£ –ò—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")

        score_col1, score_col2, score_col3 = st.columns(3)

        with score_col1:
            st.metric("–û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞", f"{complex_analysis.overall_score}/100",
                      delta="–•–æ—Ä–æ—à–æ" if complex_analysis.overall_score >= 80 else "–¢—Ä–µ–±—É–µ—Ç –¥–æ—Ä–∞–±–æ—Ç–∫–∏")

        with score_col2:
            st.metric("–Æ—Ä–∏–¥–∏—á–µ—Å–∫–∞—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å", f"{complex_analysis.legal_reliability:.1f}/10",
                      delta="–í—ã—Å–æ–∫–∞—è" if complex_analysis.legal_reliability >= 8 else "–°—Ä–µ–¥–Ω—è—è")

        with score_col3:
            st.metric("–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∑–∞–∫–æ–Ω—É", f"{complex_analysis.compliance_percent}%",
                      delta=f"+{100 - complex_analysis.compliance_percent}% –ø–æ—Å–ª–µ –¥–æ—Ä–∞–±–æ—Ç–∫–∏")

        st.markdown("---")

        rec_col1, rec_col2 = st.columns(2)

        with rec_col1:
            st.markdown("**‚úÖ –°–ò–õ–¨–ù–´–ï –°–¢–û–†–û–ù–´:**")
            for strength in complex_analysis.strengths:
                st.success(strength)

        with rec_col2:
            st.markdown("**‚ö†Ô∏è –ö–†–ò–¢–ò–ß–ù–´–ï –î–û–†–ê–ë–û–¢–ö–ò:**")
            for improvement in complex_analysis.critical_improvements:
                if improvement.startswith("–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û") or improvement.startswith("–ö–†–ò–¢–ò–ß–ù–û"):
                    st.error(improvement)
                else:
                    st.warning(improvement)

        st.markdown("---")
        avg_score = complex_analysis.overall_score
        if avg_score >= 90:
            st.success("**üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** –î–æ–≥–æ–≤–æ—Ä –≥–æ—Ç–æ–≤ –∫ –ø–æ–¥–ø–∏—Å–∞–Ω–∏—é. –û—Ç–ª–∏—á–Ω–∞—è –ø—Ä–æ—Ä–∞–±–æ—Ç–∫–∞!")
        elif avg_score >= 80:
            st.info("**üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** –î–æ–≥–æ–≤–æ—Ä –º–æ–∂–Ω–æ –ø–æ–¥–ø–∏—Å—ã–≤–∞—Ç—å –ø–æ—Å–ª–µ –≤–Ω–µ—Å–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã—Ö –¥–æ—Ä–∞–±–æ—Ç–æ–∫.")
        elif avg_score >= 70:
            st.warning("**üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** –î–æ–≥–æ–≤–æ—Ä —Ç—Ä–µ–±—É–µ—Ç –¥–æ—Ä–∞–±–æ—Ç–æ–∫. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø—Ä–∞–≤–∏—Ç—å –∫—Ä–∏—Ç–∏—á–Ω—ã–µ –∑–∞–º–µ—á–∞–Ω–∏—è –ø–µ—Ä–µ–¥ –ø–æ–¥–ø–∏—Å–∞–Ω–∏–µ–º.")
        else:
            st.error("**üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** –î–æ–≥–æ–≤–æ—Ä —Ç—Ä–µ–±—É–µ—Ç —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –ø–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∏. –ù–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∫ –ø–æ–¥–ø–∏—Å–∞–Ω–∏—é –≤ —Ç–µ–∫—É—â–µ–º –≤–∏–¥–µ.")


def extract_section_text(full_text: str, start_marker: str, end_marker: str) -> str:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∞ –¥–æ–≥–æ–≤–æ—Ä–∞"""
    try:
        start_idx = full_text.find(start_marker)
        end_idx = full_text.find(end_marker)

        if start_idx == -1:
            return "–†–∞–∑–¥–µ–ª –Ω–µ –Ω–∞–π–¥–µ–Ω"

        if end_idx == -1:
            # –ï—Å–ª–∏ —ç—Ç–æ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ä–∞–∑–¥–µ–ª
            return full_text[start_idx:start_idx + 500]

        return full_text[start_idx:end_idx].strip()
    except:
        return "–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ —Ä–∞–∑–¥–µ–ª–∞"


# –ö–Ω–æ–ø–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
if uploaded_file is not None:
    st.success(f"‚úÖ –§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω: **{uploaded_file.name}** ({uploaded_file.size} –±–∞–π—Ç)")

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
    with st.expander("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏", expanded=False):
        use_section_analysis = st.checkbox(
            "–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–∞–∑–¥–µ–ª–æ–≤ (Section Analysis)",
            value=True,
            help="LLM-–∞–Ω–∞–ª–∏–∑ –∫–∞–∂–¥–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∞ –¥–æ–≥–æ–≤–æ—Ä–∞ —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏. –î–æ–±–∞–≤–ª—è–µ—Ç ~60-90 —Å–µ–∫ –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ."
        )

    if st.button("üöÄ –ù–∞—á–∞—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É", type="primary"):
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
        with tempfile.NamedTemporaryFile(delete=False, suffix=Path(uploaded_file.name).suffix) as tmp_file:
            tmp_file.write(uploaded_file.read())
            tmp_file_path = tmp_file.name

        try:
            # Progress bar
            progress_bar = st.progress(0)
            status_text = st.empty()

            # –ó–∞–ø—É—Å–∫–∞–µ–º —Ä–µ–∞–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
            if use_section_analysis:
                status_text.text("üöÄ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—É—â–µ–Ω–∞. –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–∞–∑–¥–µ–ª–æ–≤ –∑–∞–π–º—ë—Ç ~60-90 —Å–µ–∫. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ...")
            else:
                status_text.text("üöÄ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—É—â–µ–Ω–∞ (~15 —Å–µ–∫)...")
            progress_bar.progress(5)

            # –ó–∞–ø—É—Å–∫–∞–µ–º async –æ–±—Ä–∞–±–æ—Ç–∫—É
            import concurrent.futures
            def _run_async(coro):
                loop = asyncio.new_event_loop()
                try:
                    return loop.run_until_complete(coro)
                finally:
                    loop.close()

            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(
                    _run_async,
                    process_document_async(tmp_file_path, Path(uploaded_file.name).suffix, use_section_analysis=use_section_analysis)
                )
                result = future.result(timeout=300)

            st.markdown("---")
            st.header("2Ô∏è‚É£ –•–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏")

            # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–∞–∂–¥–æ–≥–æ —ç—Ç–∞–ø–∞
            total_stages = len(result.stages)

            for idx, stage in enumerate(result.stages):
                progress = int((idx + 1) / total_stages * 90)
                progress_bar.progress(progress)

                # Stage 1: Text Extraction
                if stage.name == "text_extraction":
                    status_text.text("üìÑ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞...")

                    with st.expander(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ ({stage.duration_sec:.1f} —Å–µ–∫)", expanded=True):
                        used_model, optimal_model = get_optimal_model_info("text_extraction")
                        st.success(f"**–ú–µ—Ç–æ–¥:** {stage.results.get('method', 'N/A')} | **–§–æ—Ä–º–∞—Ç:** {stage.results.get('original_format', 'N/A')} | **DOCX-–≤–µ—Ä—Å–∏—è:** {'‚úÖ –ï—Å—Ç—å' if stage.results.get('has_docx') else '‚ùå –ù–µ—Ç'}")
                        st.info(f"**–ú–æ–¥–µ–ª—å:** {used_model} | **–û–ø—Ç–∏–º–∞–ª—å–Ω–æ:** {optimal_model}")

                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("–°—Ç—Ä–∞–Ω–∏—Ü", stage.results.get("pages", "N/A"))
                        with col2:
                            st.metric("–°–∏–º–≤–æ–ª–æ–≤", f"{stage.results.get('chars', 0):,}")
                        with col3:
                            confidence = stage.results.get("confidence")
                            st.metric("Confidence", f"{confidence:.2f}" if confidence else "N/A")

                        # –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä —Å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º (–µ—Å–ª–∏ –µ—Å—Ç—å DOCX)
                        if result.docx_file_bytes:
                            st.subheader("üìÑ –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –¥–æ–∫—É–º–µ–Ω—Ç–∞ (—Å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º)")
                            preview_html = render_docx_preview(result.docx_file_bytes)
                            st.markdown(preview_html, unsafe_allow_html=True)

                            # –ö–Ω–æ–ø–∫–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
                            st.markdown("---")
                            dl_col1, dl_col2 = st.columns(2)
                            with dl_col1:
                                if result.original_file_bytes:
                                    orig_ext = result.original_format or 'bin'
                                    st.download_button(
                                        f"üì• –°–∫–∞—á–∞—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª (.{orig_ext})",
                                        data=result.original_file_bytes,
                                        file_name=f"original_{uploaded_file.name}",
                                        mime="application/octet-stream",
                                        key="download_original"
                                    )
                            with dl_col2:
                                st.download_button(
                                    "üì• –°–∫–∞—á–∞—Ç—å DOCX-–≤–µ—Ä—Å–∏—é",
                                    data=result.docx_file_bytes,
                                    file_name=f"{Path(uploaded_file.name).stem}.docx",
                                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                                    key="download_docx"
                                )
                        else:
                            st.subheader("üìã –ò–∑–≤–ª–µ—á—ë–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç")
                            st.text_area("–í–µ—Å—å —Ç–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–ø—Ä–æ–∫—Ä—É—Ç–∏—Ç–µ –≤–Ω–∏–∑):", value=result.raw_text, height=400, key="full_text_area")

                # Stage 2: Level 1 Extraction
                elif stage.name == "level1_extraction":
                    status_text.text("üîç Level 1: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –±–∞–∑–æ–≤—ã—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π...")

                    with st.expander(f"‚úÖ Level 1 Extraction ({stage.duration_sec:.1f} —Å–µ–∫)", expanded=True):
                        used_model, optimal_model = get_optimal_model_info("level1")
                        st.success(f"**–ù–∞–π–¥–µ–Ω–æ —Å—É—â–Ω–æ—Å—Ç–µ–π:** {stage.results.get('entities_count', 0)}")
                        st.info(f"**–ú–æ–¥–µ–ª—å:** {used_model} | **–û–ø—Ç–∏–º–∞–ª—å–Ω–æ:** {optimal_model}")

                        # –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ —Ç–∏–ø–∞–º
                        by_type = stage.results.get("by_type", {})
                        cols = st.columns(min(len(by_type), 3))
                        for idx2, (entity_type, count) in enumerate(by_type.items()):
                            with cols[idx2 % 3]:
                                st.metric(entity_type, count)

                        # –î–µ—Ç–∞–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞
                        st.subheader("üìã –î–µ—Ç–∞–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ —Å—É—â–Ω–æ—Å—Ç–µ–π")
                        details = stage.results.get("details", {})

                        all_entities = []
                        for entity_type, entities in details.items():
                            for ent in entities:
                                all_entities.append({
                                    "–¢–∏–ø": entity_type,
                                    "–ó–Ω–∞—á–µ–Ω–∏–µ": ent.get("value", ""),
                                    "–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ": get_entity_purpose(entity_type),
                                    "Confidence": f"{ent.get('confidence', 0):.2f}",
                                    "–ö–æ–Ω—Ç–µ–∫—Å—Ç": ent.get("context", "")[:80] + "..."
                                })

                        if all_entities:
                            st.dataframe(all_entities, use_container_width=True)
                            st.caption("üí° **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ** –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –¥–ª—è —á–µ–≥–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–∞–∂–¥–∞—è —Å—É—â–Ω–æ—Å—Ç—å –≤ —Å–∏—Å—Ç–µ–º–µ")

                # Stage 3: LLM Extraction
                elif stage.name == "llm_extraction":
                    status_text.text("ü§ñ LLM –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")

                    with st.expander(f"‚úÖ LLM Extraction ({stage.duration_sec:.1f} —Å–µ–∫)", expanded=True):
                        model_used = stage.results.get("model", "N/A")
                        used_model, optimal_model = get_optimal_model_info("llm")

                        st.success(f"**–ú–æ–¥–µ–ª—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞:** {model_used}")
                        st.info(f"**–û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å:** {optimal_model}")

                        # –ú–µ—Ç—Ä–∏–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
                        st.subheader("üìä –ú–µ—Ç—Ä–∏–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏")
                        tokens_in = stage.results.get("tokens_input", 0)
                        tokens_out = stage.results.get("tokens_output", 0)
                        cost = stage.results.get("cost_usd", 0)
                        confidence = stage.results.get("confidence", 0)

                        metrics_data = [
                            {"–ü–∞—Ä–∞–º–µ—Ç—Ä": "–¢–æ–∫–µ–Ω—ã (–≤—Ö–æ–¥)", "–ó–Ω–∞—á–µ–Ω–∏–µ": f"{tokens_in:,}", "–û–ø–∏—Å–∞–Ω–∏–µ": "–¢–æ–∫–µ–Ω–æ–≤ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ –º–æ–¥–µ–ª—å"},
                            {"–ü–∞—Ä–∞–º–µ—Ç—Ä": "–¢–æ–∫–µ–Ω—ã (–≤—ã—Ö–æ–¥)", "–ó–Ω–∞—á–µ–Ω–∏–µ": f"{tokens_out:,}", "–û–ø–∏—Å–∞–Ω–∏–µ": "–¢–æ–∫–µ–Ω–æ–≤ –ø–æ–ª—É—á–µ–Ω–æ –æ—Ç –º–æ–¥–µ–ª–∏"},
                            {"–ü–∞—Ä–∞–º–µ—Ç—Ä": "–í—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤", "–ó–Ω–∞—á–µ–Ω–∏–µ": f"{tokens_in + tokens_out:,}", "–û–ø–∏—Å–∞–Ω–∏–µ": "–°—É–º–º–∞—Ä–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ"},
                            {"–ü–∞—Ä–∞–º–µ—Ç—Ä": "–°—Ç–æ–∏–º–æ—Å—Ç—å", "–ó–Ω–∞—á–µ–Ω–∏–µ": f"${cost:.5f}", "–û–ø–∏—Å–∞–Ω–∏–µ": f"{model_used}: —Å–º. —Ç–∞—Ä–∏—Ñ—ã –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞"},
                            {"–ü–∞—Ä–∞–º–µ—Ç—Ä": "Confidence", "–ó–Ω–∞—á–µ–Ω–∏–µ": f"{confidence:.2f} ({confidence*100:.0f}%)", "–û–ø–∏—Å–∞–Ω–∏–µ": "–°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏"},
                        ]
                        st.table(metrics_data)

                        # –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                        st.subheader("üìä –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
                        extracted_data = stage.results.get("data", {})

                        tab1, tab2, tab3, tab4, tab5 = st.tabs(["–°—Ç–æ—Ä–æ–Ω—ã", "–ü—Ä–µ–¥–º–µ—Ç", "–§–∏–Ω–∞–Ω—Å—ã", "–°—Ä–æ–∫–∏", "–°–∞–Ω–∫—Ü–∏–∏"])

                        with tab1:
                            st.json(extracted_data.get("parties", {}))

                        with tab2:
                            st.json(extracted_data.get("subject", {}))

                        with tab3:
                            st.json(extracted_data.get("financials", {}))

                        with tab4:
                            st.json(extracted_data.get("terms", {}))

                        with tab5:
                            st.json(extracted_data.get("penalties", {}))

                # Stage 4: RAG Filter
                elif stage.name == "rag_filter":
                    status_text.text("üîç RAG: –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –¥–æ–≥–æ–≤–æ—Ä–æ–≤...")

                    with st.expander(f"‚úÖ RAG Filter ({stage.duration_sec:.1f} —Å–µ–∫)", expanded=False):
                        used_model, optimal_model = get_optimal_model_info("rag")
                        similar_count = stage.results.get("similar_contracts_found", 0)

                        st.success(f"**–ù–∞–π–¥–µ–Ω–æ –ø–æ—Ö–æ–∂–∏—Ö:** {similar_count} –¥–æ–≥–æ–≤–æ—Ä–æ–≤")
                        st.info(f"**–ú–æ–¥–µ–ª—å:** {used_model} | **–û–ø—Ç–∏–º–∞–ª—å–Ω–æ:** {optimal_model}")

                        contracts = stage.results.get("contracts", [])
                        if contracts:
                            similar_data = []
                            for c in contracts:
                                similar_data.append({
                                    "–î–æ–≥–æ–≤–æ—Ä": c.get("contract_number", "N/A"),
                                    "–°—Ö–æ–∂–µ—Å—Ç—å": f"{c.get('similarity', 0):.2f}",
                                    "–¢–∏–ø": c.get("doc_type", "N/A"),
                                    "–°—É–º–º–∞": f"‚ÇΩ{c.get('amount', 0):,.0f}"
                                })
                            st.dataframe(similar_data, use_container_width=True)
                        else:
                            st.info("–ü–æ—Ö–æ–∂–∏–µ –¥–æ–≥–æ–≤–æ—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã (–±–∞–∑–∞ –ø—É—Å—Ç–∞ –∏–ª–∏ –Ω–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π)")

            # Stage 5: Validation
            progress_bar.progress(95)
            status_text.text("‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")

            validation_result = result.validation_result or {}

            with st.expander("‚ö†Ô∏è Validation", expanded=True):
                used_model, optimal_model = get_optimal_model_info("validation")

                is_valid = validation_result.get("is_valid", False)
                has_warnings = len(validation_result.get("warnings", [])) > 0
                if is_valid and not has_warnings:
                    st.success("**–°—Ç–∞—Ç—É—Å:** ‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ–π–¥–µ–Ω–∞")
                elif is_valid and has_warnings:
                    st.warning("**–°—Ç–∞—Ç—É—Å:** ‚ö†Ô∏è –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ–π–¥–µ–Ω–∞ —Å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è–º–∏")
                else:
                    st.error("**–°—Ç–∞—Ç—É—Å:** ‚ùå –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–µ –ø—Ä–æ–π–¥–µ–Ω–∞")

                st.info(f"**–ú–æ–¥–µ–ª—å:** {used_model} | **–û–ø—Ç–∏–º–∞–ª—å–Ω–æ:** {optimal_model}")

                errors = validation_result.get("errors", [])
                warnings = validation_result.get("warnings", [])

                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("–û—à–∏–±–æ–∫", len(errors), delta="‚úÖ" if len(errors) == 0 else "‚ùå")
                with col2:
                    st.metric("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π", len(warnings), delta="‚ö†Ô∏è" if len(warnings) > 0 else "‚úÖ")
                with col3:
                    compliance = 100 - (len(errors) * 10 + len(warnings) * 2)
                    st.metric("–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ", f"{compliance}%", delta=f"{compliance-100}%" if compliance < 100 else "‚úÖ")

                # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –æ—à–∏–±–æ–∫ –∏ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π
                if errors:
                    st.markdown("### ‚ùå –û—à–∏–±–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏:")
                    for i, error in enumerate(errors, 1):
                        if isinstance(error, dict):
                            st.error(f"**{i}.** `{error.get('field', 'N/A')}`: {error.get('message', 'N/A')}")
                        else:
                            st.error(f"**{i}.** {error}")

                if warnings:
                    st.markdown("### ‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è:")
                    for i, warning in enumerate(warnings, 1):
                        if isinstance(warning, dict):
                            st.warning(f"**{i}.** `{warning.get('field', 'N/A')}`: {warning.get('message', 'N/A')}")
                        else:
                            st.warning(f"**{i}.** {warning}")

                st.markdown("---")

                # –î–µ—Ç–∞–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –ø–æ —Ä–∞–∑–¥–µ–ª–∞–º (–î–ò–ù–ê–ú–ò–ß–ï–°–ö–ò –∏–∑ LLM)
                section_analysis_data = None
                for stage in result.stages:
                    if stage.name == "section_analysis" and stage.status == "success":
                        section_analysis_data = stage.results.get("full_data")
                        break

                if section_analysis_data:
                    display_validation_section_dynamic(section_analysis_data, is_new_contract=is_new_contract)
                elif use_section_analysis:
                    st.warning("‚ö†Ô∏è –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–∞–∑–¥–µ–ª–æ–≤ –Ω–µ –±—ã–ª –≤—ã–ø–æ–ª–Ω–µ–Ω –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏.")
                else:
                    st.info("‚ÑπÔ∏è –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–∞–∑–¥–µ–ª–æ–≤ –æ—Ç–∫–ª—é—á–µ–Ω. –í–∫–ª—é—á–∏—Ç–µ –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞.")

            progress_bar.progress(100)
            status_text.empty()

            st.markdown("---")

            # –§–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            st.header("3Ô∏è‚É£ –ò—Ç–æ–≥–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏")

            col1, col2, col3, col4 = st.columns(4)

            with col1:
                st.metric("‚è±Ô∏è –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏", f"{result.total_time_sec:.1f} —Å–µ–∫")

            with col2:
                st.metric("üí∞ –°—Ç–æ–∏–º–æ—Å—Ç—å", f"${result.total_cost_usd:.5f}")

            with col3:
                st.metric("ü§ñ –ú–æ–¥–µ–ª—å", result.model_used)

            with col4:
                avg_confidence = 0
                for stage in result.stages:
                    if stage.name == "llm_extraction":
                        avg_confidence = stage.results.get("confidence", 0)
                st.metric("üéØ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å", f"{avg_confidence*100:.0f}%")

            st.markdown("---")

            # –ö–Ω–æ–ø–∫–∏ –¥–µ–π—Å—Ç–≤–∏–π
            st.header("4Ô∏è‚É£ –î–µ–π—Å—Ç–≤–∏—è —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏")

            col1, col2, col3, col4 = st.columns(4)

            with col1:
                if st.button("‚úÖ –£—Ç–≤–µ—Ä–¥–∏—Ç—å", type="primary", use_container_width=True):
                    st.success("‚úÖ –î–æ–∫—É–º–µ–Ω—Ç —É—Ç–≤–µ—Ä–∂–¥–µ–Ω –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö!")
                    st.balloons()

            with col2:
                if st.button("üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å JSON", use_container_width=True):
                    json_data = json.dumps(result.to_dict(), ensure_ascii=False, indent=2)
                    st.download_button(
                        "–°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç",
                        json_data,
                        file_name=f"contract_analysis_{uploaded_file.name}.json",
                        mime="application/json"
                    )

            with col3:
                # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ DOCX-–≤–µ—Ä—Å–∏–∏
                if result.docx_file_bytes:
                    st.download_button(
                        "üìÑ –°–∫–∞—á–∞—Ç—å DOCX",
                        data=result.docx_file_bytes,
                        file_name=f"{Path(uploaded_file.name).stem}_result.docx",
                        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                        use_container_width=True,
                        key="download_docx_final"
                    )
                else:
                    if st.button("üìÑ –≠–∫—Å–ø–æ—Ä—Ç –≤ Word", use_container_width=True):
                        st.info("DOCX-–≤–µ—Ä—Å–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞")

            with col4:
                if st.button("‚ùå –û—Ç–∫–ª–æ–Ω–∏—Ç—å", use_container_width=True):
                    st.error("–î–æ–∫—É–º–µ–Ω—Ç –æ—Ç–∫–ª–æ–Ω–µ–Ω")

            # –ü—Ä–æ—Ç–æ–∫–æ–ª —Ä–∞–∑–Ω–æ–≥–ª–∞—Å–∏–π (—Ç–æ–ª—å–∫–æ –¥–ª—è –ø–æ–¥–ø–∏—Å–∞–Ω–Ω—ã—Ö –¥–æ–≥–æ–≤–æ—Ä–æ–≤)
            if not is_new_contract and st.session_state.get("accepted_recommendations"):
                st.markdown("---")
                st.header("üìã –ü—Ä–æ—Ç–æ–∫–æ–ª —Ä–∞–∑–Ω–æ–≥–ª–∞—Å–∏–π")
                st.info(f"–°–æ–±—Ä–∞–Ω–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {len(st.session_state.accepted_recommendations)}")

                protocol_data = []
                for i, rec in enumerate(st.session_state.accepted_recommendations, 1):
                    protocol_data.append({
                        "‚Ññ": i,
                        "–†–∞–∑–¥–µ–ª": f"{rec['section_number']}. {rec['section_title']}",
                        "–¢–µ–∫—Å—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª–∞": rec["original_text"],
                        "–ü—Ä–µ–¥–ª–∞–≥–∞–µ–º–∞—è —Ä–µ–¥–∞–∫—Ü–∏—è": rec["proposed_text"],
                        "–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ": rec["reason"]
                    })

                st.dataframe(protocol_data, use_container_width=True)

                # –°–∫–∞—á–∞—Ç—å –ø—Ä–æ—Ç–æ–∫–æ–ª –∫–∞–∫ JSON
                protocol_json = json.dumps(protocol_data, ensure_ascii=False, indent=2)
                st.download_button(
                    "üì• –°–∫–∞—á–∞—Ç—å –ø—Ä–æ—Ç–æ–∫–æ–ª —Ä–∞–∑–Ω–æ–≥–ª–∞—Å–∏–π (JSON)",
                    protocol_json,
                    file_name=f"protocol_{uploaded_file.name}.json",
                    mime="application/json",
                    key="download_protocol"
                )

        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}")
            import traceback
            st.code(traceback.format_exc())

        finally:
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            if os.path.exists(tmp_file_path):
                os.unlink(tmp_file_path)

else:
    st.info("üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –¥–æ–≥–æ–≤–æ—Ä–∞ –¥–ª—è –Ω–∞—á–∞–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏")

    # –°—Å—ã–ª–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
    st.markdown("---")
    st.markdown("**üí° –î–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:** –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ–∞–π–ª `tests/fixtures/test_supply_contract.txt`")

st.markdown("---")
st.caption("Contract AI System v2.0 - –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ | –ú–æ–¥–µ–ª–∏ 2026: Claude Opus/Sonnet 4.5, GPT-4.1, DeepSeek-V3.2, Qwen2.5-VL-72B (119 —è–∑—ã–∫–æ–≤)")
