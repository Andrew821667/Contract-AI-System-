# -*- coding: utf-8 -*-
"""
Contract Analyzer Agent - Deep analysis of contracts with risk identification
"""
import json
from typing import Dict, Any, List, Optional
from datetime import datetime
from lxml import etree
from loguru import logger

from .base_agent import BaseAgent, AgentResult
from ..services.llm_gateway import LLMGateway
from ..services.template_manager import TemplateManager
from ..services.counterparty_service import CounterpartyService
from ..models.analyzer_models import (
    ContractRisk, ContractRecommendation, ContractAnnotation,
    ContractSuggestedChange
)
from ..models.database import Contract, AnalysisResult
from config.settings import settings

# Optional RAG import
try:
    from ..services.rag_system import RAGSystem
except ImportError:
    RAGSystem = None


class ContractAnalyzerAgent(BaseAgent):
    """
    Agent for deep contract analysis

    Capabilities:
    - Maximum depth analysis (all risk types)
    - RAG integration (analogues + precedents + legal norms)
    - Risk identification (financial, legal, operational, reputational)
    - Automatic change suggestions with LLM
    - Template comparison
    - Counterparty checking (optional)
    - Dispute probability prediction
    - Annotated XML generation
    """

    def __init__(
        self,
        llm_gateway: LLMGateway = None,
        db_session = None,
        template_manager: Optional[TemplateManager] = None,
        rag_system: Optional['RAGSystem'] = None,
        counterparty_service: Optional[CounterpartyService] = None
    ):
        # –ï—Å–ª–∏ LLM –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω, —Å–æ–∑–¥–∞—ë–º —Å –±—ã—Å—Ç—Ä–æ–π –º–æ–¥–µ–ª—å—é –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è
        if llm_gateway is None:
            from config.settings import settings
            llm_gateway = LLMGateway(model=settings.llm_quick_model)
        
        super().__init__(llm_gateway, db_session)
        self.template_manager = template_manager or TemplateManager(db_session)
        self.rag_system = rag_system
        self.counterparty_service = counterparty_service or CounterpartyService()

    def get_name(self) -> str:
        return "ContractAnalyzerAgent"

    def get_system_prompt(self) -> str:
        return """You are a contract analysis expert specializing in Russian contract law.

Your task is to perform deep analysis of contracts and identify:
1. RISKS (financial, legal, operational, reputational)
   - Severity: critical, significant, minor
   - Probability: high, medium, low
   - Consequences: qualitative assessment (no monetary values)

2. RECOMMENDATIONS for contract improvement
   - Priority: critical, high, medium, low
   - Category: legal_compliance, risk_mitigation, financial_optimization, etc.
   - Expected benefit and implementation complexity

3. SUGGESTED CHANGES (automatic via LLM)
   - Original text and suggested replacement
   - Issue description and reasoning
   - Legal basis (references to laws, articles)
   - Change type: addition, modification, deletion, clarification

4. DISPUTE PROBABILITY PREDICTION
   - Overall score and reasoning
   - Specific clauses that may lead to disputes

5. ANNOTATIONS for document sections
   - Type: risk, warning, info, suggestion
   - Location via xpath
   - Related risks/recommendations

Always provide structured JSON output with all identified issues.
Use RAG sources (precedents, legal norms, analogues) to support your analysis.
"""

    def execute(self, state: Dict[str, Any]) -> AgentResult:
        """
        Execute contract analysis

        Expected state:
        - contract_id: ID of contract to analyze
        - parsed_xml: Parsed XML content
        - metadata: Contract metadata
        - check_counterparty: Optional flag to check counterparty info

        Returns:
        - analysis_id: ID of created analysis
        - risks: List of identified risks
        - recommendations: List of recommendations
        - suggested_changes: List of suggested changes
        - annotations: List of annotations
        - dispute_probability: Dispute prediction
        - counterparty_data: Optional counterparty check results
        - next_action: 'review_queue' or 'export'
        """
        try:
            contract_id = state.get('contract_id')
            parsed_xml = state.get('parsed_xml')
            metadata = state.get('metadata', {})
            check_counterparty = state.get('check_counterparty', False)

            if not contract_id or not parsed_xml:
                return AgentResult(
                    success=False,
                    data={},
                    error="Missing contract_id or parsed_xml"
                )

            logger.info(f"Starting analysis for contract {contract_id}")

            # 1. Get contract from DB
            contract = self.db.query(Contract).filter(
                Contract.id == contract_id
            ).first()

            if not contract:
                return AgentResult(
                    success=False,
                    data={},
                    error=f"Contract {contract_id} not found"
                )

            # 2. Create analysis result record
            analysis = self._create_analysis_record(contract)

            # 3. Extract contract structure
            structure = self._extract_structure(parsed_xml)

            # 4. Optional: Check counterparty
            counterparty_data = None
            if check_counterparty:
                counterparty_data = self._check_counterparties(parsed_xml, metadata)

            # 5. Analyze with RAG context
            rag_context = self._get_rag_context(parsed_xml, metadata)

            # 6. Identify risks
            risks = self._identify_risks(
                parsed_xml, structure, rag_context, counterparty_data
            )
            self._save_risks(analysis.id, contract.id, risks)

            # 7. Generate recommendations
            recommendations = self._generate_recommendations(
                parsed_xml, structure, risks, rag_context
            )
            self._save_recommendations(analysis.id, contract.id, recommendations)

            # 8. Generate suggested changes (LLM)
            suggested_changes = self._generate_suggested_changes(
                parsed_xml, structure, risks, recommendations, rag_context
            )
            self._save_suggested_changes(analysis.id, contract.id, suggested_changes)

            # 9. Generate annotations
            annotations = self._generate_annotations(
                risks, recommendations, suggested_changes
            )
            self._save_annotations(analysis.id, contract.id, annotations)

            # 10. Predict dispute probability
            dispute_prediction = self._predict_disputes(
                parsed_xml, risks, rag_context
            )

            # 11. Compare with templates (if available)
            template_comparison = self._compare_with_templates(
                parsed_xml, metadata.get('contract_type')
            )

            # 12. Update analysis record with results
            # Store metadata in risks_by_category as JSON
            import json
            analysis.risks_by_category = json.dumps({
                'risk_count': len(risks),
                'recommendation_count': len(recommendations),
                'suggested_changes_count': len(suggested_changes),
                'dispute_probability': dispute_prediction.get('score'),
                'template_comparison': template_comparison,
                'counterparty_checked': counterparty_data is not None
            }, ensure_ascii=False)
            self.db.commit()
            self.db.refresh(analysis)

            # 13. Determine next action
            next_action = self._determine_next_action(risks, dispute_prediction)

            logger.info(f"Analysis completed: {len(risks)} risks, {len(recommendations)} recommendations")

            # Get detailed clause analyses if available
            clause_analyses = getattr(self, '_clause_analyses', [])

            return AgentResult(
                success=True,
                data={
                    'analysis_id': analysis.id,
                    'contract_id': contract.id,
                    'risks': [self._risk_to_dict(r) for r in risks],
                    'recommendations': [self._recommendation_to_dict(r) for r in recommendations],
                    'suggested_changes': [self._change_to_dict(c) for c in suggested_changes],
                    'annotations': [self._annotation_to_dict(a) for a in annotations],
                    'dispute_prediction': dispute_prediction,
                    'template_comparison': template_comparison,
                    'counterparty_data': counterparty_data,
                    'clause_analyses': clause_analyses  # –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–∞–∂–¥–æ–≥–æ –ø—É–Ω–∫—Ç–∞
                },
                next_action=next_action,
                metadata={
                    'message': f"Analysis completed: {len(risks)} risks identified, {len(recommendations)} recommendations, {len(clause_analyses)} clauses analyzed"
                }
            )

        except Exception as e:
            logger.error(f"Contract analysis failed: {e}")
            import traceback
            traceback.print_exc()
            return AgentResult(
                success=False,
                data={},
                error=str(e)
            )

    def _create_analysis_record(self, contract: Contract) -> AnalysisResult:
        """Create analysis result record"""
        analysis = AnalysisResult(
            contract_id=contract.id,
            entities='{}',
            compliance_issues='{}',
            legal_issues='{}',
            risks_by_category='{}',
            recommendations='{}',
            version=1
        )
        self.db.add(analysis)
        self.db.commit()
        self.db.refresh(analysis)
        return analysis

    def _extract_structure(self, xml_content: str) -> Dict[str, Any]:
        """Extract contract structure for analysis"""
        try:
            tree = etree.fromstring(xml_content.encode('utf-8'))
            root = tree

            structure = {
                'sections': [],
                'parties': [],
                'price_info': {},
                'term_info': {},
                'payment_terms': [],
                'liability_clauses': [],
                'dispute_resolution': {}
            }

            # Extract parties
            parties = root.findall('.//party')
            for party in parties:
                party_info = {
                    'role': party.get('role', 'unknown'),
                    'name': party.findtext('name', ''),
                    'inn': party.findtext('inn', ''),
                    'xpath': f'//{party.tag}[@role="{party.get("role", "")}"]'
                }
                structure['parties'].append(party_info)

            # Extract price info
            price_elem = root.find('.//price')
            if price_elem is not None:
                structure['price_info'] = {
                    'amount': price_elem.findtext('amount', ''),
                    'currency': price_elem.findtext('currency', 'RUB'),
                    'xpath': f'//{price_elem.tag}'
                }

            # Extract term info
            term_elem = root.find('.//term')
            if term_elem is not None:
                structure['term_info'] = {
                    'start': term_elem.findtext('start', ''),
                    'end': term_elem.findtext('end', ''),
                    'xpath': f'//{term_elem.tag}'
                }

            # Extract all sections with detailed info
            for elem in root.iter():
                if elem.tag not in ['contract', 'party', 'price', 'term']:
                    text_content = elem.text or ''
                    # Also capture text from child elements
                    full_text = ''.join(elem.itertext()).strip()

                    structure['sections'].append({
                        'tag': elem.tag,
                        'text': text_content,
                        'full_text': full_text,
                        'xpath': f'//{elem.tag}',
                        'attributes': dict(elem.attrib)
                    })

            return structure

        except Exception as e:
            logger.error(f"Structure extraction failed: {e}")
            import traceback
            traceback.print_exc()
            return {}

    def _extract_contract_clauses(self, xml_content: str) -> List[Dict[str, Any]]:
        """
        Extract individual contract clauses for detailed analysis
        –†–∞–∑–±–∏–≤–∞–µ—Ç –¥–æ–≥–æ–≤–æ—Ä –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –ø—É–Ω–∫—Ç—ã –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        """
        try:
            logger.info("Starting clause extraction from XML...")
            tree = etree.fromstring(xml_content.encode('utf-8'))
            root = tree

            logger.info(f"Root tag: {root.tag}, children: {len(list(root))}")

            clauses = []
            clause_counter = 1

            # –†–µ–∫—É—Ä—Å–∏–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—É–Ω–∫—Ç–æ–≤
            def extract_recursive(element, parent_path="", level=0):
                nonlocal clause_counter

                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–æ–ª—å–∫–æ contract –∏ metadata –Ω–∞ –≤–µ—Ä—Ö–Ω–µ–º —É—Ä–æ–≤–Ω–µ
                if level == 0 and element.tag in ['contract', 'document', 'root']:
                    logger.info(f"Processing root element: {element.tag}")
                    for child in element:
                        extract_recursive(child, element.tag, level + 1)
                    return

                # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç —ç–ª–µ–º–µ–Ω—Ç–∞
                elem_text = (element.text or '').strip()

                # –°–æ–±–∏—Ä–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç –∏–∑ –¥–æ—á–µ—Ä–Ω–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
                full_text = ''.join(element.itertext()).strip()

                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –ø—É–Ω–∫—Ç–∞
                clause_type = self._determine_clause_type(element.tag, full_text)

                # –ü—É—Ç—å –∫ –ø—É–Ω–∫—Ç—É
                current_path = f"{parent_path}/{element.tag}" if parent_path else element.tag

                # –ï—Å–ª–∏ –µ—Å—Ç—å —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç - —ç—Ç–æ –ø—É–Ω–∫—Ç –¥–æ–≥–æ–≤–æ—Ä–∞
                # –°–Ω–∏–∂–∞–µ–º –ø–æ—Ä–æ–≥ –¥–æ 5 —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –∑–∞—Ö–≤–∞—Ç–∞ –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø—É–Ω–∫—Ç–æ–≤
                if full_text and len(full_text) > 5:
                    clause = {
                        'id': f"clause_{clause_counter}",
                        'number': clause_counter,
                        'tag': element.tag,
                        'path': current_path,
                        'xpath': current_path,  # Use path instead of getpath
                        'title': self._extract_clause_title(element.tag, full_text),
                        'text': full_text[:2000],  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç 2000 —Å–∏–º–≤–æ–ª–æ–≤
                        'type': clause_type,
                        'level': level,
                        'attributes': dict(element.attrib),
                        'children_count': len(list(element))
                    }
                    clauses.append(clause)
                    logger.debug(f"Clause {clause_counter}: {element.tag} - {full_text[:50]}")
                    clause_counter += 1

                    # –ï—Å–ª–∏ —É —ç–ª–µ–º–µ–Ω—Ç–∞ –Ω–µ—Ç –¥–µ—Ç–µ–π - –Ω–µ –∏–¥—ë–º –¥–∞–ª—å—à–µ
                    if len(list(element)) == 0:
                        return

                # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–æ—á–µ—Ä–Ω–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã
                for child in element:
                    extract_recursive(child, current_path, level + 1)

            extract_recursive(root)

            logger.info(f"‚úì Extracted {len(clauses)} contract clauses for detailed analysis")

            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ø—É–Ω–∫—Ç–æ–≤ - –ø–æ–ø—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥
            if len(clauses) == 0:
                logger.warning("No clauses found with standard extraction, trying alternative method...")
                clauses = self._extract_clauses_alternative(xml_content)
                logger.info(f"Alternative method found {len(clauses)} clauses")

            return clauses

        except Exception as e:
            logger.error(f"Clause extraction failed: {e}")
            import traceback
            traceback.print_exc()
            return []

    def _extract_clauses_alternative(self, xml_content: str) -> List[Dict[str, Any]]:
        """
        Alternative method: split contract into sections based on XML structure
        –°–ø–µ—Ü–∏–∞–ª—å–Ω–æ –¥–ª—è DocumentParser –∫–æ—Ç–æ—Ä—ã–π —Å–æ–∑–¥–∞—ë—Ç <clauses><clause>...</clause></clauses>
        """
        try:
            tree = etree.fromstring(xml_content.encode('utf-8'))
            clauses = []

            # –°–ù–ê–ß–ê–õ–ê –ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ <clauses><clause> —Å—Ç—Ä—É–∫—Ç—É—Ä—É –æ—Ç DocumentParser
            clauses_container = tree.find('.//clauses')
            if clauses_container is not None:
                logger.info("Found <clauses> container from DocumentParser")
                clause_elements = clauses_container.findall('clause')
                logger.info(f"Found {len(clause_elements)} clause elements")

                for idx, clause_elem in enumerate(clause_elements, 1):
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º title –∏ content
                    title_elem = clause_elem.find('title')
                    content_elem = clause_elem.find('content')

                    title = title_elem.text if title_elem is not None and title_elem.text else f"–ü—É–Ω–∫—Ç {idx}"

                    # –°–æ–±–∏—Ä–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç –∏–∑ content
                    if content_elem is not None:
                        paragraphs = content_elem.findall('paragraph')
                        full_text = '\n'.join([p.text for p in paragraphs if p.text])
                    else:
                        full_text = ''.join(clause_elem.itertext()).strip()

                    if full_text and len(full_text) > 10:
                        clause = {
                            'id': clause_elem.get('id', f"clause_{idx}"),
                            'number': idx,
                            'tag': 'clause',
                            'path': f"/clauses/clause[{idx}]",
                            'xpath': f"/clauses/clause[{idx}]",  # Use path instead of getpath
                            'title': title,
                            'text': full_text[:2000],
                            'type': clause_elem.get('type', self._determine_clause_type(title, full_text)),
                            'level': 0,
                            'attributes': dict(clause_elem.attrib),
                            'children_count': len(list(clause_elem))
                        }
                        clauses.append(clause)
                        logger.info(f"‚úì Extracted clause {idx}: {title[:50]}")

                if len(clauses) > 0:
                    logger.info(f"‚úÖ Successfully extracted {len(clauses)} clauses from DocumentParser format")
                    return clauses[:50]  # Limit to 50

            # FALLBACK: –µ—Å–ª–∏ –Ω–µ—Ç <clauses>, –±–µ—Ä—ë–º –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã —Å —Ç–µ–∫—Å—Ç–æ–º
            logger.info("No <clauses> found, trying generic element extraction...")
            all_elements = list(tree.iter())
            logger.info(f"Found {len(all_elements)} total XML elements")

            clause_counter = 1
            for elem in all_elements:
                full_text = ''.join(elem.itertext()).strip()

                # –ë–µ—Ä—ë–º —ç–ª–µ–º–µ–Ω—Ç—ã —Å —Ç–µ–∫—Å—Ç–æ–º –¥–ª–∏–Ω–Ω–µ–µ 10 —Å–∏–º–≤–æ–ª–æ–≤
                if full_text and len(full_text) > 10:
                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã, —á–µ–π —Ç–µ–∫—Å—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å —Ä–æ–¥–∏—Ç–µ–ª–µ–º
                    parent = elem.getparent()
                    if parent is not None:
                        parent_text = ''.join(parent.itertext()).strip()
                        if full_text == parent_text:
                            continue

                    clause = {
                        'id': f"clause_{clause_counter}",
                        'number': clause_counter,
                        'tag': elem.tag,
                        'path': f"/{elem.tag}",
                        'xpath': f"/{elem.tag}",  # Use path instead of getpath
                        'title': self._extract_clause_title(elem.tag, full_text),
                        'text': full_text[:2000],
                        'type': self._determine_clause_type(elem.tag, full_text),
                        'level': 0,
                        'attributes': dict(elem.attrib),
                        'children_count': len(list(elem))
                    }
                    clauses.append(clause)
                    clause_counter += 1

            return clauses[:50]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 50 –ø—É–Ω–∫—Ç–æ–≤ –¥–ª—è —Ä–∞–∑—É–º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –∞–Ω–∞–ª–∏–∑–∞

        except Exception as e:
            logger.error(f"Alternative extraction failed: {e}")
            import traceback
            traceback.print_exc()
            return []

    def _determine_clause_type(self, tag: str, text: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –ø—É–Ω–∫—Ç–∞ –¥–æ–≥–æ–≤–æ—Ä–∞"""
        tag_lower = tag.lower()
        text_lower = text.lower()

        if any(word in tag_lower for word in ['price', 'payment', 'cost', '—Ü–µ–Ω–∞', '–æ–ø–ª–∞—Ç–∞', '—Å—Ç–æ–∏–º–æ—Å—Ç—å']):
            return 'financial'
        elif any(word in tag_lower for word in ['term', 'deadline', '—Å—Ä–æ–∫', '–ø–µ—Ä–∏–æ–¥']):
            return 'temporal'
        elif any(word in tag_lower for word in ['party', '—Å—Ç–æ—Ä–æ–Ω', '–∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç']):
            return 'parties'
        elif any(word in tag_lower for word in ['liability', 'penalty', '–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å', '—à—Ç—Ä–∞—Ñ', '–ø–µ–Ω—è']):
            return 'liability'
        elif any(word in tag_lower for word in ['dispute', 'arbitration', '—Å–ø–æ—Ä', '–∞—Ä–±–∏—Ç—Ä–∞–∂']):
            return 'dispute'
        elif any(word in tag_lower for word in ['subject', '–ø—Ä–µ–¥–º–µ—Ç', '–æ–±—ä–µ–∫—Ç']):
            return 'subject'
        elif any(word in tag_lower for word in ['termination', '—Ä–∞—Å—Ç–æ—Ä–∂–µ–Ω–∏–µ']):
            return 'termination'
        else:
            return 'general'

    def _extract_clause_title(self, tag: str, text: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∑–∞–≥–æ–ª–æ–≤–æ–∫ –ø—É–Ω–∫—Ç–∞"""
        # –ë–µ—Ä—ë–º –ø–µ—Ä–≤—ã–µ 100 —Å–∏–º–≤–æ–ª–æ–≤ –∏–ª–∏ –¥–æ –ø–µ—Ä–≤–æ–π —Ç–æ—á–∫–∏
        lines = text.split('\n')
        first_line = lines[0].strip() if lines else text

        if len(first_line) > 80:
            return first_line[:80] + "..."

        return first_line or tag

    def _check_counterparties(
        self, xml_content: str, metadata: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Check counterparty information via APIs"""
        try:
            root = etree.fromstring(xml_content.encode('utf-8'))
            parties = root.findall('.//party')

            results = {}
            for party in parties:
                inn = party.findtext('inn', '').strip()
                name = party.findtext('name', '')

                if inn:
                    logger.info(f"Checking counterparty: {name} (INN: {inn})")
                    check_result = self.counterparty_service.check_counterparty(
                        inn=inn,
                        check_bankruptcy=True
                    )
                    results[name] = check_result

            return results

        except Exception as e:
            logger.error(f"Counterparty check failed: {e}")
            return {}

    def _get_rag_context(
        self, xml_content: str, metadata: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Get RAG context (analogues + precedents + legal norms) + contract summary"""
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –±–∞–∑–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–æ–≥–æ–≤–æ—Ä–µ –∏–∑ XML
            from lxml import etree
            tree = etree.fromstring(xml_content.encode('utf-8'))

            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç–æ—Ä–æ–Ω—ã
            parties = []
            for party in tree.findall('.//party'):
                parties.append({
                    'name': party.findtext('name', '–ù–µ —É–∫–∞–∑–∞–Ω–æ'),
                    'role': party.get('role', 'unknown'),
                    'inn': party.findtext('inn', '')
                })

            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–∏–ø –¥–æ–≥–æ–≤–æ—Ä–∞ –∏–∑ —Ç–µ–≥–∞ –∏–ª–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            contract_type = metadata.get('contract_type', 'unknown')
            if contract_type == 'unknown':
                # –ü—ã—Ç–∞–µ–º—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∏–∑ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ
                root_tag = tree.tag if hasattr(tree, 'tag') else 'contract'
                contract_type = root_tag.replace('_', ' ').replace('contract', '–¥–æ–≥–æ–≤–æ—Ä')

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–µ–¥–º–µ—Ç –¥–æ–≥–æ–≤–æ—Ä–∞
            subject = metadata.get('subject', '')
            if not subject:
                # –ò—â–µ–º –≤ first paragraph –∏–ª–∏ description
                desc_elem = tree.find('.//description')
                if desc_elem is not None and desc_elem.text:
                    subject = desc_elem.text[:200]
                else:
                    subject = "–ù–µ —É–∫–∞–∑–∞–Ω —è–≤–Ω–æ"

            contract_summary = {
                'type': contract_type,
                'parties': parties,
                'subject': subject,
                'party_count': len(parties)
            }

            # Search RAG if available
            rag_results = []
            rag_context = ""

            if self.rag_system:
                query = f"–î–æ–≥–æ–≤–æ—Ä {contract_type}: {subject}"
                rag_results = self.rag_system.search(
                    query=query,
                    n_results=10,
                    filter_metadata={'type': ['analogue', 'precedent', 'legal_norm']}
                )
                rag_context = "\n\n".join([
                    f"[{r['metadata'].get('type', 'unknown')}] {r['text']}"
                    for r in rag_results
                ])

            return {
                'sources': rag_results,
                'context': rag_context,
                'contract_summary': contract_summary
            }

        except Exception as e:
            logger.error(f"RAG context retrieval failed: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
            return {
                'sources': [],
                'context': '',
                'contract_summary': {
                    'type': metadata.get('contract_type', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π'),
                    'parties': [],
                    'subject': metadata.get('subject', '–Ω–µ —É–∫–∞–∑–∞–Ω')
                }
            }


    def _analyze_clauses_batch(
        self, clauses: List[Dict[str, Any]], rag_context: Dict[str, Any], batch_size: int = 5
    ) -> List[Dict[str, Any]]:
        """
        –ë–∞—Ç—á-–∞–Ω–∞–ª–∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø—É–Ω–∫—Ç–æ–≤ –¥–æ–≥–æ–≤–æ—Ä–∞ –∑–∞ –æ–¥–∏–Ω LLM –≤—ã–∑–æ–≤
        –≠–∫–æ–Ω–æ–º–∏—Ç —Ç–æ–∫–µ–Ω—ã –Ω–∞ system prompt

        Args:
            clauses: –°–ø–∏—Å–æ–∫ –ø—É–Ω–∫—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            rag_context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ RAG
            batch_size: –°–∫–æ–ª—å–∫–æ –ø—É–Ω–∫—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∑–∞ —Ä–∞–∑

        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
        """
        all_analyses = []

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–æ–≥–æ–≤–æ—Ä–∞ –∏–∑ RAG
        contract_summary = rag_context.get('contract_summary', {})
        contract_type = contract_summary.get('type', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π')
        parties = contract_summary.get('parties', [])
        subject = contract_summary.get('subject', '–Ω–µ —É–∫–∞–∑–∞–Ω')

        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –±–∞—Ç—á–∏
        for i in range(0, len(clauses), batch_size):
            batch = clauses[i:i + batch_size]

            logger.info(f"Analyzing batch {i//batch_size + 1}: clauses {i+1}-{i+len(batch)}")

            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –±–∞—Ç—á–∞
            clauses_text = ""
            for idx, clause in enumerate(batch, 1):
                clauses_text += f"""
[–ü–£–ù–ö–¢ {clause['number']}]
–ó–∞–≥–æ–ª–æ–≤–æ–∫: {clause['title']}
–¢–µ–∫—Å—Ç: {clause['text'][:300]}{'...' if len(clause['text']) > 300 else ''}
---
"""

            prompt = f"""–¢—ã - –æ–ø—ã—Ç–Ω—ã–π —é—Ä–∏—Å—Ç-—ç–∫—Å–ø–µ—Ä—Ç –ø–æ –¥–æ–≥–æ–≤–æ—Ä–Ω–æ–º—É –ø—Ä–∞–≤—É –†–§.

–ö–û–ù–¢–ï–ö–°–¢ –î–û–ì–û–í–û–†–ê:
- –¢–∏–ø –¥–æ–≥–æ–≤–æ—Ä–∞: {contract_type}
- –°—Ç–æ—Ä–æ–Ω—ã: {', '.join([p.get('name', '') for p in parties]) if parties else '–Ω–µ —É–∫–∞–∑–∞–Ω—ã'}
- –ü—Ä–µ–¥–º–µ—Ç: {subject}

–ó–ê–î–ê–ß–ê: –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π {len(batch)} –ø—É–Ω–∫—Ç–æ–≤ –¥–æ–≥–æ–≤–æ—Ä–∞ –∫–∞–∫ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —é—Ä–∏—Å—Ç.

{clauses_text}

–î–ª—è –ö–ê–ñ–î–û–ì–û –ø—É–Ω–∫—Ç–∞ –ø—Ä–æ–≤–µ–¥–∏ –¥–µ—Ç–∞–ª—å–Ω—É—é —é—Ä–∏–¥–∏—á–µ—Å–∫—É—é —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—É –∏ –≤–µ—Ä–Ω–∏ JSON –≤ –º–∞—Å—Å–∏–≤–µ:
[
  {{
    "clause_number": <–Ω–æ–º–µ—Ä –ø—É–Ω–∫—Ç–∞>,
    "clarity_score": <0-10, –≥–¥–µ 10 - –∏–¥–µ–∞–ª—å–Ω–æ —á—ë—Ç–∫–∞—è —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞>,
    "legal_compliance": {{
      "score": <0-10, –≥–¥–µ 10 - –ø–æ–ª–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ì–ö –†–§>,
      "issues": ["–∫–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞ —Å–æ —Å—Å—ã–ª–∫–æ–π –Ω–∞ —Å—Ç–∞—Ç—å—é –ì–ö –†–§"],
      "relevant_laws": ["—Å—Ç. 421 –ì–ö –†–§ - —Å–≤–æ–±–æ–¥–∞ –¥–æ–≥–æ–≤–æ—Ä–∞"]
    }},
    "risks": [
      {{
        "risk_type": "legal|financial|operational|reputational",
        "severity": "high|medium|low",
        "probability": "high|medium|low",
        "title": "–ö—Ä–∞—Ç–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ä–∏—Å–∫–∞",
        "description": "–ü–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ä–∏—Å–∫–∞ –∏ –µ–≥–æ –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏–π",
        "consequences": "–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è –¥–ª—è –≤–∞—à–µ–π –∫–æ–º–ø–∞–Ω–∏–∏"
      }}
    ],
    "recommendations": [
      {{
        "priority": "critical|high|medium|low",
        "category": "legal_compliance|risk_mitigation|financial_optimization|clarity_improvement",
        "title": "–ö—Ä–∞—Ç–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏",
        "description": "–ö–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è —Å –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ–º",
        "reasoning": "–ü–æ—á–µ–º—É —ç—Ç–æ –≤–∞–∂–Ω–æ",
        "expected_benefit": "–û–∂–∏–¥–∞–µ–º–∞—è –ø–æ–ª—å–∑–∞ –æ—Ç –≤–Ω–µ–¥—Ä–µ–Ω–∏—è"
      }}
    ],
    "ambiguities": ["–ö–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è –¥–≤—É—Å–º—ã—Å–ª–µ–Ω–Ω–æ—Å—Ç—å –≤ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–µ"],
    "missing_elements": ["–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–π —ç–ª–µ–º–µ–Ω—Ç, –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π –ø–æ –ì–ö –†–§"]
  }}
]

–¢–†–ï–ë–û–í–ê–ù–ò–Ø –ö –ê–ù–ê–õ–ò–ó–£:
1. **–í–ê–ñ–ù–û:** –ù–µ —Å—Ç–∞–≤—å –æ—Ü–µ–Ω–∫–∏ 0/10 –∏–ª–∏ 1/10 –±–µ–∑ –ö–†–ê–ô–ù–ï –≤–µ—Å–∫–æ–π –ø—Ä–∏—á–∏–Ω—ã. –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –¥–ª—è –æ–±—ã—á–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ - 3/10. –û—Ü–µ–Ω–∫–∞ 0/10 –¥–æ–ø—É—Å—Ç–∏–º–∞ –¢–û–õ–¨–ö–û –µ—Å–ª–∏:
   - –¢–µ–∫—Å—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –Ω–µ—á–∏—Ç–∞–µ–º
   - –ü—É–Ω–∫—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—Ä—è–º–æ–µ –Ω–∞—Ä—É—à–µ–Ω–∏–µ –∑–∞–∫–æ–Ω–∞
   - –§–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞ –∞–±—Å–æ–ª—é—Ç–Ω–æ –Ω–µ–ø—Ä–∏–≥–æ–¥–Ω–∞ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
2. –û—Ü–µ–Ω–∏–≤–∞–π —Ä–µ–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç –ø–æ —Å—É—â–µ—Å—Ç–≤—É, –∞ –Ω–µ —Ñ–æ—Ä–º–∞–ª—å–Ω–æ
3. –í legal_compliance —É–∫–∞–∑—ã–≤–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Å—Ç–∞—Ç—å–∏ –ì–ö –†–§ (—Å—Ç. 309, 310, 330, 421, 431, 450, 451, 702, 708 –∏ –¥—Ä.)
4. –í risks –æ–ø–∏—Å—ã–≤–∞–π –†–ï–ê–õ–¨–ù–´–ï —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ —Ä–∏—Å–∫–∏ —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è–º–∏
5. –í recommendations –¥–∞–≤–∞–π –ö–û–ù–ö–†–ï–¢–ù–´–ï –ø—Ä–∏–º–µ–Ω–∏–º—ã–µ —Å–æ–≤–µ—Ç—ã, –Ω–µ –æ–±—â–∏–µ —Ñ—Ä–∞–∑—ã
6. –ï—Å–ª–∏ –ø—É–Ω–∫—Ç –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–æ–±–ª–µ–º–Ω—ã–π - —É–∫–∞–∂–∏ —ç—Ç–æ —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ–º"""

            try:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±—ã—Å—Ç—Ä—É—é –º–æ–¥–µ–ª—å –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è
                logger.info(f"üîç DEBUG: Using model = {self.llm.model}, provider = {self.llm.provider}")
                logger.info(f"üîç DEBUG: Prompt length = {len(prompt)} characters (batch of {len(batch)} clauses)")
                response = self.llm.call(
                    prompt=prompt,
                    system_prompt="""–¢—ã - –≤–µ–¥—É—â–∏–π —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –¥–æ–≥–æ–≤–æ—Ä–Ω–æ–º—É –ø—Ä–∞–≤—É –†–§ —Å 15-–ª–µ—Ç–Ω–∏–º –æ–ø—ã—Ç–æ–º.

–¢–í–û–Ø –†–û–õ–¨: –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–æ–≥–æ–≤–æ—Ä—ã –∫–∞–∫ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —é—Ä–∏—Å—Ç, –≤—ã—è–≤–ª—è—è –†–ï–ê–õ–¨–ù–´–ï —Ä–∏—Å–∫–∏ –∏ –¥–∞–≤–∞—è –ö–û–ù–ö–†–ï–¢–ù–´–ï —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏.

–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û:
1. –û—Ç–≤–µ—á–∞–π –°–¢–†–û–ì–û –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON –º–∞—Å—Å–∏–≤–∞
2. –ü—Ä–æ–≤–æ–¥–∏ –†–ï–ê–õ–¨–ù–£–Æ —é—Ä–∏–¥–∏—á–µ—Å–∫—É—é —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—É, –Ω–µ —Ñ–æ—Ä–º–∞–ª—å–Ω—É—é
3. –°—Å—ã–ª–∞–π—Å—è –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Å—Ç–∞—Ç—å–∏ –ì–ö –†–§ (—Å—Ç. 309, 310, 330, 421, 431, 450, 451 –∏ –¥—Ä.)
4. –û—Ü–µ–Ω–∫–∏ –¥–∞–≤–∞–π –ø–æ —Ä–µ–∞–ª—å–Ω–æ–º—É –∫–∞—á–µ—Å—Ç–≤—É —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–æ–∫, –Ω–µ —Å—Ç–∞–≤—å 0/10 –±–µ–∑ –ø—Ä–∏—á–∏–Ω—ã
5. –†–∏—Å–∫–∏ –æ–ø–∏—Å—ã–≤–∞–π —Å –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è–º–∏ –∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é
6. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ö–û–ù–ö–†–ï–¢–ù–´–ú–ò –∏ –ü–†–ò–ú–ï–ù–ò–ú–´–ú–ò

–¢–≤–æ–π –∞–Ω–∞–ª–∏–∑ –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω —é—Ä–∏—Å—Ç–∞–º–∏ –∫–æ–º–ø–∞–Ω–∏–∏ –¥–ª—è –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π!""",
                    response_format="json",
                    temperature=0.2,
                    max_tokens=settings.llm_test_max_tokens if settings.llm_test_mode else settings.llm_max_tokens
                )

                # Parse response
                batch_analyses = response if isinstance(response, list) else []

                # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ—Ü–µ–Ω–æ–∫ 0/10
                for analysis in batch_analyses:
                    # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –æ—Ü–µ–Ω–∫—É —á—ë—Ç–∫–æ—Å—Ç–∏ –µ—Å–ª–∏ 0
                    if analysis.get('clarity_score', 0) == 0:
                        logger.warning(f"Clause {analysis.get('clause_number')} has clarity_score=0, setting to 3 (needs review)")
                        analysis['clarity_score'] = 3

                    # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –æ—Ü–µ–Ω–∫—É —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –µ—Å–ª–∏ 0
                    if isinstance(analysis.get('legal_compliance'), dict):
                        if analysis['legal_compliance'].get('score', 0) == 0:
                            logger.warning(f"Clause {analysis.get('clause_number')} has legal_compliance=0, setting to 3 (needs review)")
                            analysis['legal_compliance']['score'] = 3
                            if not analysis['legal_compliance'].get('issues'):
                                analysis['legal_compliance']['issues'] = ['–¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–∞–≤–æ–≤–∞—è —ç–∫—Å–ø–µ—Ä—Ç–∏–∑–∞']

                if not batch_analyses:
                    logger.warning(f"Batch analysis returned empty/invalid response, falling back to individual analysis")
                    # Fallback: analyze individually
                    for clause in batch:
                        try:
                            analysis = self._analyze_clause_detailed(clause, rag_context)
                            all_analyses.append(analysis)
                        except Exception as e:
                            logger.error(f"Individual analysis failed for clause {clause['number']}: {e}")
                            all_analyses.append(self._get_fallback_analysis(clause))
                else:
                    # Add xpath from original clauses
                    for analysis in batch_analyses:
                        clause_num = analysis.get('clause_number')
                        # Find matching clause
                        for clause in batch:
                            if clause['number'] == clause_num:
                                analysis['clause_xpath'] = clause['xpath']
                                analysis['clause_title'] = clause['title']
                                break
                        all_analyses.append(analysis)

                logger.info(f"‚úì Batch {i//batch_size + 1} analyzed: {len(batch_analyses)} clauses")

            except Exception as e:
                logger.error(f"Batch analysis failed: {e}, falling back to individual analysis")
                # Fallback: analyze individually
                for clause in batch:
                    try:
                        analysis = self._analyze_clause_detailed(clause, rag_context)
                        all_analyses.append(analysis)
                    except Exception as e2:
                        logger.error(f"Individual analysis failed for clause {clause['number']}: {e2}")
                        all_analyses.append(self._get_fallback_analysis(clause))

        return all_analyses

    def analyze_deep(self, clause_ids: list, contract_id: str, xml_content: str, rag_context: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        –ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º gpt-4o (–£—Ä–æ–≤–µ–Ω—å 2)
        
        Args:
            clause_ids: –°–ø–∏—Å–æ–∫ ID –ø—É–Ω–∫—Ç–æ–≤ –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
            contract_id: ID –¥–æ–≥–æ–≤–æ—Ä–∞
            xml_content: XML –∫–æ–Ω—Ç–µ–Ω—Ç –¥–æ–≥–æ–≤–æ—Ä–∞
            rag_context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ RAG
            
        Returns:
            –°–ø–∏—Å–æ–∫ –¥–µ—Ç–∞–ª—å–Ω—ã—Ö –∞–Ω–∞–ª–∏–∑–æ–≤ –ø—É–Ω–∫—Ç–æ–≤ —Å –ø—Ä–µ—Ü–µ–¥–µ–Ω—Ç–∞–º–∏ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏
        """
        from config.settings import settings
        from ..services.llm_gateway import LLMGateway
        
        logger.info(f"Starting DEEP analysis (Level 2) for {len(clause_ids)} clauses with {settings.llm_deep_model}")
        
        # Create deep LLM with gpt-4o
        deep_llm = LLMGateway(model=settings.llm_deep_model)
        
        # Extract clauses
        all_clauses = self._extract_contract_clauses(xml_content)
        selected_clauses = [c for c in all_clauses if c['id'] in clause_ids or c['number'] in clause_ids]
        
        if not selected_clauses:
            logger.warning(f"No clauses found for deep analysis with ids: {clause_ids}")
            return []
        
        deep_analyses = []
        
        for clause in selected_clauses:
            logger.info(f"Deep analyzing clause {clause['number']}: {clause['title'][:60]}")
            
            # Detailed prompt for deep analysis
            prompt = f"""–í—ã–ø–æ–ª–Ω–∏ –ì–õ–£–ë–û–ö–ò–ô —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –ø—É–Ω–∫—Ç–∞ –¥–æ–≥–æ–≤–æ—Ä–∞.

–ü–£–ù–ö–¢ ‚Ññ{clause['number']}: {clause['title']}
–¢–ï–ö–°–¢:
{clause['text']}

–ö–û–ù–¢–ï–ö–°–¢ –ò–ó –ë–ê–ó–´ –ó–ù–ê–ù–ò–ô:
{rag_context.get('context', '')[:1000]}

–ü—Ä–æ–≤–µ–¥–∏ –¥–µ—Ç–∞–ª—å–Ω—É—é —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—É:

1. –Æ–†–ò–î–ò–ß–ï–°–ö–ò–ô –ê–ù–ê–õ–ò–ó:
   - –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ì–ö –†–§, —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–º –∑–∞–∫–æ–Ω–∞–º
   - –°—Å—ã–ª–∫–∏ –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Å—Ç–∞—Ç—å–∏ –∑–∞–∫–æ–Ω–æ–≤
   - –í—ã—è–≤–ª–µ–Ω–∏–µ —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö –∫–æ–ª–ª–∏–∑–∏–π
   - –ê–Ω–∞–ª–∏–∑ –∏—Å–ø–æ–ª–Ω–∏–º–æ—Å—Ç–∏ —á–µ—Ä–µ–∑ —Å—É–¥

2. –†–ò–°–ö–ò –° –ü–†–ï–¶–ï–î–ï–ù–¢–ê–ú–ò:
   - –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Å—É–¥–µ–±–Ω—ã–µ –¥–µ–ª–∞ (–Ω–æ–º–µ—Ä–∞, –¥–∞—Ç—ã, —Å—É–¥—ã)
   - –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–ø–æ—Ä–æ–≤ –ø–æ –∞–Ω–∞–ª–æ–≥–∏—á–Ω—ã–º –ø—É–Ω–∫—Ç–∞–º
   - –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è (–¥–∏–∞–ø–∞–∑–æ–Ω—ã —Å—É–º–º)
   - –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –≤–æ–∑–Ω–∏–∫–Ω–æ–≤–µ–Ω–∏—è —Å–ø–æ—Ä–∞ (%)

3. –ê–õ–¨–¢–ï–†–ù–ê–¢–ò–í–ù–´–ï –§–û–†–ú–£–õ–ò–†–û–í–ö–ò:
   - 2-3 –≤–∞—Ä–∏–∞–Ω—Ç–∞ —É–ª—É—á—à–µ–Ω–Ω—ã—Ö —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–æ–∫
   - –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –∫–∞–∂–¥–æ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞
   - –°—Å—ã–ª–∫–∏ –Ω–∞ best practices

4. –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –≠–ö–°–ü–ï–†–¢–û–í:
   - –ü–æ–∑–∏—Ü–∏—è –í–° –†–§ –ø–æ –∞–Ω–∞–ª–æ–≥–∏—á–Ω—ã–º –≤–æ–ø—Ä–æ—Å–∞–º
   - –ú–Ω–µ–Ω–∏—è –≤–µ–¥—É—â–∏—Ö —é—Ä–∏—Å—Ç–æ–≤
   - –û—Ç—Ä–∞—Å–ª–µ–≤—ã–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã

–í–µ—Ä–Ω–∏ JSON:
{{
  "clause_number": {clause['number']},
  "deep_legal_analysis": {{
    "compliance_score": 0-10,
    "relevant_laws": [
      {{
        "law": "–ì–ö –†–§",
        "article": "—Å—Ç. 421",
        "relevance": "–æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç–∏",
        "compliance_status": "compliant|non_compliant|unclear"
      }}
    ],
    "legal_conflicts": ["–∫–æ–Ω—Ñ–ª–∏–∫—Ç 1", "–∫–æ–Ω—Ñ–ª–∏–∫—Ç 2"],
    "enforceability_score": 0-10,
    "enforceability_notes": "–∞–Ω–∞–ª–∏–∑ –∏—Å–ø–æ–ª–Ω–∏–º–æ—Å—Ç–∏"
  }},
  "risks_with_precedents": [
    {{
      "risk_type": "—Ç–∏–ø",
      "severity": "critical|high|medium|low",
      "probability_percent": 0-100,
      "description": "–¥–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ",
      "financial_impact_range": "–æ—Ç X –¥–æ Y —Ä—É–±–ª–µ–π",
      "precedents": [
        {{
          "case_number": "–Ω–æ–º–µ—Ä –¥–µ–ª–∞",
          "court": "—Å—É–¥",
          "date": "–¥–∞—Ç–∞",
          "outcome": "–∏—Å—Ö–æ–¥",
          "relevance": "–ø–æ—á–µ–º—É —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ"
        }}
      ],
      "mitigation": "–∫–∞–∫ –º–∏–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å"
    }}
  ],
  "alternative_formulations": [
    {{
      "variant_number": 1,
      "formulation": "—Ç–µ–∫—Å—Ç —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏",
      "advantages": ["–ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ 1", "–ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ 2"],
      "legal_basis": "–æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ",
      "best_practice_reference": "—Å—Å—ã–ª–∫–∞ –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫—É"
    }}
  ],
  "expert_recommendations": [
    {{
      "source": "–í–° –†–§ / —ç–∫—Å–ø–µ—Ä—Ç",
      "recommendation": "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è",
      "citation": "—Å—Å—ã–ª–∫–∞ –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫"
    }}
  ],
  "overall_risk_score": 0-100,
  "priority": "critical|high|medium|low",
  "summary": "–∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ –≥–ª—É–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"
}}"""

            try:
                response = deep_llm.call(
                    prompt=prompt,
                    system_prompt="–¢—ã –≤–µ–¥—É—â–∏–π —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –¥–æ–≥–æ–≤–æ—Ä–Ω–æ–º—É –ø—Ä–∞–≤—É –†–§. –ü—Ä–æ–≤–æ–¥–∏—à—å –¥–µ—Ç–∞–ª—å–Ω—É—é —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—É –Ω–∞ —É—Ä–æ–≤–Ω–µ —Å—Ç–∞—Ä—à–µ–≥–æ –ø–∞—Ä—Ç–Ω—ë—Ä–∞ —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–π —Ñ–∏—Ä–º—ã. –ò—Å–ø–æ–ª—å–∑—É–µ—à—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ –∑–∞–∫–æ–Ω—ã, —Å—É–¥–µ–±–Ω—É—é –ø—Ä–∞–∫—Ç–∏–∫—É –∏ –ø—Ä–µ—Ü–µ–¥–µ–Ω—Ç—ã.",
                    response_format="json",
                    temperature=0.3,
                    max_tokens=settings.llm_max_tokens,
                    use_cache=True,
                    db_session=self.db
                )
                
                response['clause_id'] = clause['id']
                response['clause_xpath'] = clause['xpath']
                response['clause_title'] = clause['title']
                response['analysis_level'] = 'deep'
                response['model_used'] = settings.llm_deep_model
                
                deep_analyses.append(response)
                logger.info(f"‚úì Deep analysis complete for clause {clause['number']}: {response.get('overall_risk_score', 'N/A')}/100 risk score")
                
            except Exception as e:
                logger.error(f"Deep analysis failed for clause {clause['number']}: {e}")
                # Fallback
                deep_analyses.append({
                    'clause_number': clause['number'],
                    'clause_id': clause['id'],
                    'error': str(e),
                    'analysis_level': 'deep',
                    'summary': '–ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –Ω–µ —É–¥–∞–ª—Å—è –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏'
                })
        
        logger.info(f"Deep analysis complete: {len(deep_analyses)} clauses analyzed with {settings.llm_deep_model}")
        return deep_analyses

    def _analyze_clause_detailed(
        self, clause: Dict[str, Any], rag_context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        –î–µ—Ç–∞–ª—å–Ω—ã–π LLM-–∞–Ω–∞–ª–∏–∑ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ –ø—É–Ω–∫—Ç–∞ –¥–æ–≥–æ–≤–æ—Ä–∞
        Returns detailed analysis including risks, issues, recommendations
        """
        try:
            # –°–æ–∫—Ä–∞—â—ë–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏—è
            prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø—É–Ω–∫—Ç –¥–æ–≥–æ–≤–æ—Ä–∞:

–ü–£–ù–ö–¢ ‚Ññ{clause['number']}: {clause['title']}
–¢–ï–ö–°–¢: {clause['text']}

–û—Ü–µ–Ω–∏:
1. –ß—ë—Ç–∫–æ—Å—Ç—å —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ (0-10)
2. –ü—Ä–∞–≤–æ–≤–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ (0-10)
3. –†–∏—Å–∫–∏ (—Ç–∏–ø, —Å–µ—Ä—å—ë–∑–Ω–æ—Å—Ç—å, –æ–ø–∏—Å–∞–Ω–∏–µ)
4. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é
5. –î–≤—É—Å–º—ã—Å–ª–µ–Ω–Ω–æ—Å—Ç–∏
6. –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã

JSON —Ñ–æ—Ä–º–∞—Ç:
{{
  "clause_id": "{clause['id']}",
  "clarity_score": 0-10,
  "clarity_assessment": "–ø–æ–¥—Ä–æ–±–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —á—ë—Ç–∫–æ—Å—Ç–∏ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏",
  "legal_compliance": {{
    "score": 0-10,
    "issues": ["–ø—Ä–æ–±–ª–µ–º–∞ 1", "–ø—Ä–æ–±–ª–µ–º–∞ 2"],
    "relevant_laws": ["–ì–ö –†–§ —Å—Ç. XXX", "–∑–∞–∫–æ–Ω Y"]
  }},
  "risks": [
    {{
      "risk_type": "financial|legal|operational|reputational",
      "severity": "critical|significant|minor",
      "probability": "high|medium|low",
      "title": "–∫—Ä–∞—Ç–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ä–∏—Å–∫–∞",
      "description": "–ü–û–î–†–û–ë–ù–û–ï –æ–ø–∏—Å–∞–Ω–∏–µ —Ä–∏—Å–∫–∞",
      "consequences": "–≤–æ–∑–º–æ–∂–Ω—ã–µ –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è",
      "affected_party": "–∫—Ç–æ –ø–æ—Å—Ç—Ä–∞–¥–∞–µ—Ç"
    }}
  ],
  "ambiguities": ["–¥–≤—É—Å–º—ã—Å–ª–µ–Ω–Ω–æ—Å—Ç—å 1", "–¥–≤—É—Å–º—ã—Å–ª–µ–Ω–Ω–æ—Å—Ç—å 2"],
  "missing_elements": ["—á—Ç–æ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –ø—É–Ω–∫—Ç–µ"],
  "recommendations": [
    {{
      "priority": "critical|high|medium|low",
      "recommendation": "—á—Ç–æ —Å–¥–µ–ª–∞—Ç—å",
      "reasoning": "–ø–æ—á–µ–º—É —ç—Ç–æ –≤–∞–∂–Ω–æ",
      "suggested_text": "–ø—Ä–µ–¥–ª–∞–≥–∞–µ–º–∞—è —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞ (–µ—Å–ª–∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ)"
    }}
  ],
  "precedents": ["—Å—É–¥–µ–±–Ω–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞"],
  "overall_assessment": "–æ–±—â–∞—è –æ—Ü–µ–Ω–∫–∞",
  "improvement_priority": "critical|high|medium|low"
}}"""

            logger.info(f"Analyzing clause {clause['number']}: {clause['title'][:50]}")

            # Try with JSON format first
            try:
                response = self.llm.call(
                    prompt=prompt,
                    system_prompt=self.get_system_prompt(),
                    response_format="json",
                    temperature=0.2
                )

                # Parse JSON response (already parsed if response_format='json')
                analysis = response if isinstance(response, dict) else json.loads(response)

            except (json.JSONDecodeError, ValueError) as e:
                # Fallback: try with text format and parse manually
                logger.warning(f"JSON format failed for clause {clause['number']}, trying text format: {e}")

                try:
                    response = self.llm.call(
                        prompt=prompt + "\n\n–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û JSON, –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞.",
                        system_prompt=self.get_system_prompt(),
                        response_format="text",
                        temperature=0.2
                    )

                    # Try to extract JSON from response
                    import re
                    json_match = re.search(r'\{.*\}', response, re.DOTALL)
                    if json_match:
                        analysis = json.loads(json_match.group(0))
                    else:
                        logger.error(f"No JSON found in text response for clause {clause['number']}")
                        return self._get_fallback_analysis(clause)

                except Exception as e2:
                    logger.error(f"Text format also failed for clause {clause['number']}: {e2}")
                    return self._get_fallback_analysis(clause)

            analysis['clause_number'] = clause['number']
            analysis['clause_xpath'] = clause['xpath']

            logger.info(f"‚úì Clause {clause['number']} analyzed: {len(analysis.get('risks', []))} risks, {len(analysis.get('recommendations', []))} recommendations")

            return analysis

        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse LLM response for clause {clause['number']}: {e}")
            return self._get_fallback_analysis(clause)
        except Exception as e:
            logger.error(f"Clause analysis failed for {clause['number']}: {e}")
            return self._get_fallback_analysis(clause)

    def _get_fallback_analysis(self, clause: Dict[str, Any]) -> Dict[str, Any]:
        """Fallback analysis if LLM fails"""
        return {
            'clause_id': clause['id'],
            'clause_number': clause['number'],
            'clause_xpath': clause['xpath'],
            'clarity_score': 5,
            'clarity_assessment': '–ê–Ω–∞–ª–∏–∑ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏',
            'legal_compliance': {'score': 5, 'issues': [], 'relevant_laws': []},
            'risks': [],
            'ambiguities': [],
            'missing_elements': [],
            'recommendations': [],
            'precedents': [],
            'overall_assessment': '–¢—Ä–µ–±—É–µ—Ç—Å—è –ø–æ–≤—Ç–æ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑',
            'improvement_priority': 'medium'
        }

    def _identify_risks(
        self,
        xml_content: str,
        structure: Dict[str, Any],
        rag_context: Dict[str, Any],
        counterparty_data: Optional[Dict[str, Any]]
    ) -> List[ContractRisk]:
        """Identify contract risks using detailed clause-by-clause LLM analysis"""
        logger.info("üîç DEBUG: _identify_risks called (NEW method with batching)")
        try:
            logger.info("Starting detailed clause-by-clause risk identification...")

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Å–µ –ø—É–Ω–∫—Ç—ã –¥–æ–≥–æ–≤–æ—Ä–∞
            clauses = self._extract_contract_clauses(xml_content)
            logger.info(f"Extracted {len(clauses)} clauses for analysis")

            if not clauses:
                logger.warning("No clauses extracted, falling back to legacy method")
                return self._identify_risks_legacy(xml_content, structure, rag_context, counterparty_data)

            all_risks = []
            all_clause_analyses = []

            # BATCH ANALYSIS - –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—É–Ω–∫—Ç–∞–º–∏ –ø–æ 5 –∑–∞ —Ä–∞–∑
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—É–Ω–∫—Ç–æ–≤ –≤ —Ç–µ—Å—Ç–æ–≤–æ–º —Ä–µ–∂–∏–º–µ
            from config.settings import settings
            max_clauses = settings.llm_test_max_clauses if settings.llm_test_mode else len(clauses)
            batch_size = settings.llm_batch_size
            
            logger.info(f"Will analyze {min(len(clauses), max_clauses)} clauses in batches of {batch_size}")

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–∞—Ç—á-–∞–Ω–∞–ª–∏–∑
            logger.info(f"üîç DEBUG: Starting batch analysis for {len(clauses[:max_clauses])} clauses")
            all_clause_analyses = self._analyze_clauses_batch(
                clauses[:max_clauses],
                rag_context,
                batch_size=batch_size
            )
            logger.info(f"üîç DEBUG: Batch analysis returned {len(all_clause_analyses)} results")

            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–∏—Å–∫–∏ –∏–∑ –∞–Ω–∞–ª–∏–∑–æ–≤
            logger.info(f"üîç DEBUG: Extracting risks from {len(all_clause_analyses)} clause analyses")
            for clause_analysis in all_clause_analyses:
                risks_in_clause = clause_analysis.get('risks', [])
                logger.info(f"üîç DEBUG: Clause {clause_analysis.get('clause_number')} has {len(risks_in_clause)} risks")
                for risk_dict in risks_in_clause:
                    risk = ContractRisk(
                        risk_type=risk_dict.get('risk_type', 'legal'),
                        severity=risk_dict.get('severity', 'minor'),
                        probability=risk_dict.get('probability', 'medium'),
                        title=risk_dict.get('title', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ä–∏—Å–∫'),
                        description=risk_dict.get('description', ''),
                        consequences=risk_dict.get('consequences'),
                        xpath_location=clause_analysis.get('clause_xpath', ''),
                        section_name=clause_analysis.get('clause_title', f"–ü—É–Ω–∫—Ç {clause_analysis.get('clause_number')}"),
                        rag_sources=[]
                    )
                    all_risks.append(risk)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–µ –∞–Ω–∞–ª–∏–∑—ã –ø—É–Ω–∫—Ç–æ–≤ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ UI
            if all_clause_analyses:
                self._store_clause_analyses(all_clause_analyses)
                logger.info(f"Detailed analysis complete: {len(all_risks)} risks from {len(all_clause_analyses)} clauses")
            else:
                logger.warning("No clauses were successfully analyzed, using legacy method")
                return self._identify_risks_legacy(xml_content, structure, rag_context, counterparty_data)

            return all_risks

        except Exception as e:
            logger.error(f"Detailed risk identification failed: {e}")
            import traceback
            traceback.print_exc()
            # Fallback to legacy method
            return self._identify_risks_legacy(xml_content, structure, rag_context, counterparty_data)

    def _store_clause_analyses(self, analyses: List[Dict[str, Any]]):
        """Store detailed clause analyses for UI display"""
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ø–∞–º—è—Ç–∏ –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if not hasattr(self, '_clause_analyses'):
            self._clause_analyses = []
        self._clause_analyses = analyses

    def _identify_risks_legacy(
        self,
        xml_content: str,
        structure: Dict[str, Any],
        rag_context: Dict[str, Any],
        counterparty_data: Optional[Dict[str, Any]]
    ) -> List[ContractRisk]:
        logger.info("‚ö†Ô∏è DEBUG: _identify_risks_legacy called (OLD method, NO batching, EXPENSIVE!)")
        """Legacy risk identification method (fallback)"""
        try:
            # Prepare prompt
            prompt = self._build_risk_identification_prompt(
                xml_content, structure, rag_context, counterparty_data
            )

            # Call LLM
            response = self.llm.call(
                prompt=prompt,
                system_prompt=self.get_system_prompt(),
                response_format="json",
                temperature=0.3
            )

            # Parse JSON response
            risks_data = response if isinstance(response, dict) else json.loads(response)

            # Convert to ContractRisk objects
            risks = []
            for risk_dict in risks_data.get('risks', []):
                risk = ContractRisk(
                    risk_type=risk_dict.get('risk_type', 'legal'),
                    severity=risk_dict.get('severity', 'minor'),
                    probability=risk_dict.get('probability'),
                    title=risk_dict.get('title', ''),
                    description=risk_dict.get('description', ''),
                    consequences=risk_dict.get('consequences'),
                    xpath_location=risk_dict.get('xpath_location'),
                    section_name=risk_dict.get('section_name'),
                    rag_sources=risk_dict.get('rag_sources', [])
                )
                risks.append(risk)

            return risks

        except Exception as e:
            logger.error(f"Legacy risk identification failed: {e}")
            return []

    def _build_risk_identification_prompt(
        self,
        xml_content: str,
        structure: Dict[str, Any],
        rag_context: Dict[str, Any],
        counterparty_data: Optional[Dict[str, Any]]
    ) -> str:
        """Build prompt for risk identification"""
        prompt = "Analyze this contract and identify ALL risks.\n\n"
        prompt += "CONTRACT XML:\n"
        prompt += xml_content[:5000]
        prompt += "\n\n"

        prompt += "CONTRACT STRUCTURE:\n"
        prompt += json.dumps(structure, ensure_ascii=False, indent=2)
        prompt += "\n\n"

        if rag_context.get('context'):
            prompt += "RELEVANT LEGAL CONTEXT (from RAG):\n"
            prompt += rag_context['context'][:3000]
            prompt += "\n\n"

        if counterparty_data:
            prompt += "COUNTERPARTY CHECK RESULTS:\n"
            prompt += json.dumps(counterparty_data, ensure_ascii=False, indent=2)
            prompt += "\n\n"

        prompt += """Identify ALL risks in these categories:
- financial (price, payment, penalties)
- legal (compliance, validity, enforceability)
- operational (execution, delivery, quality)
- reputational (brand, relationships)

For each risk, provide:
{
  "risks": [
    {
      "risk_type": "financial|legal|operational|reputational",
      "severity": "critical|significant|minor",
      "probability": "high|medium|low",
      "title": "Short title",
      "description": "Detailed description",
      "consequences": "Qualitative consequences (no monetary)",
      "xpath_location": "XPath to problem section",
      "section_name": "Section name",
      "rag_sources": ["Source 1", "Source 2"]
    }
  ]
}

Return ONLY valid JSON, no additional text."""

        return prompt

    def _generate_recommendations(
        self,
        xml_content: str,
        structure: Dict[str, Any],
        risks: List[ContractRisk],
        rag_context: Dict[str, Any]
    ) -> List[ContractRecommendation]:
        """Generate recommendations based on risks"""
        try:
            prompt = "Based on identified risks, generate recommendations.\n\n"

            prompt += "IDENTIFIED RISKS:\n"
            risks_summary = [
                {
                    'id': i,
                    'type': r.risk_type,
                    'severity': r.severity,
                    'title': r.title,
                    'description': r.description
                }
                for i, r in enumerate(risks)
            ]
            prompt += json.dumps(risks_summary, ensure_ascii=False, indent=2)
            prompt += "\n\n"

            if rag_context.get('context'):
                prompt += "LEGAL CONTEXT:\n"
                prompt += rag_context['context'][:2000]
                prompt += "\n\n"

            prompt += """Generate recommendations for each risk.

Return JSON:
{
  "recommendations": [
    {
      "category": "legal_compliance|risk_mitigation|financial_optimization|etc",
      "priority": "critical|high|medium|low",
      "title": "Short title",
      "description": "What to do",
      "reasoning": "Why this recommendation",
      "expected_benefit": "Expected outcome",
      "related_risk_id": 0,
      "implementation_complexity": "easy|medium|hard"
    }
  ]
}

Return ONLY valid JSON."""

            response = self.llm.call(
                prompt=prompt,
                system_prompt=self.get_system_prompt(),
                response_format="json",
                temperature=0.3
            )

            recommendations_data = response if isinstance(response, dict) else json.loads(response)

            recommendations = []
            for rec_dict in recommendations_data.get('recommendations', []):
                recommendation = ContractRecommendation(
                    category=rec_dict.get('category', 'general'),
                    priority=rec_dict.get('priority', 'medium'),
                    title=rec_dict.get('title', ''),
                    description=rec_dict.get('description', ''),
                    reasoning=rec_dict.get('reasoning'),
                    expected_benefit=rec_dict.get('expected_benefit'),
                    implementation_complexity=rec_dict.get('implementation_complexity')
                )
                recommendations.append(recommendation)

            return recommendations

        except Exception as e:
            logger.error(f"Recommendation generation failed: {e}")
            return []

    def _generate_suggested_changes(
        self,
        xml_content: str,
        structure: Dict[str, Any],
        risks: List[ContractRisk],
        recommendations: List[ContractRecommendation],
        rag_context: Dict[str, Any]
    ) -> List[ContractSuggestedChange]:
        """Generate automatic suggested changes via LLM"""
        try:
            prompt = "Generate specific text changes to fix identified risks.\n\n"

            prompt += "RISKS:\n"
            prompt += json.dumps([
                {'id': i, 'title': r.title, 'description': r.description, 'xpath': r.xpath_location}
                for i, r in enumerate(risks)
            ], ensure_ascii=False, indent=2)
            prompt += "\n\n"

            prompt += "CONTRACT SECTIONS:\n"
            prompt += json.dumps(structure.get('sections', [])[:20], ensure_ascii=False, indent=2)
            prompt += "\n\n"

            if rag_context.get('context'):
                prompt += "LEGAL REFERENCES:\n"
                prompt += rag_context['context'][:2000]
                prompt += "\n\n"

            prompt += """For each risk that can be fixed by changing contract text, provide:

{
  "changes": [
    {
      "xpath_location": "XPath to section",
      "section_name": "Section name",
      "original_text": "Current problematic text",
      "suggested_text": "Improved version",
      "change_type": "addition|modification|deletion|clarification",
      "issue": "What's the problem",
      "reasoning": "Why this change fixes it",
      "legal_basis": "Reference to law/article if applicable",
      "related_risk_id": 0
    }
  ]
}

Return ONLY valid JSON."""

            response = self.llm.call(
                prompt=prompt,
                system_prompt=self.get_system_prompt(),
                response_format="json",
                temperature=0.4
            )

            changes_data = response if isinstance(response, dict) else json.loads(response)

            changes = []
            for change_dict in changes_data.get('changes', []):
                change = ContractSuggestedChange(
                    xpath_location=change_dict.get('xpath_location', ''),
                    section_name=change_dict.get('section_name'),
                    original_text=change_dict.get('original_text', ''),
                    suggested_text=change_dict.get('suggested_text', ''),
                    change_type=change_dict.get('change_type'),
                    issue=change_dict.get('issue', ''),
                    reasoning=change_dict.get('reasoning', ''),
                    legal_basis=change_dict.get('legal_basis'),
                    status='pending'
                )
                changes.append(change)

            return changes

        except Exception as e:
            logger.error(f"Suggested changes generation failed: {e}")
            return []

    def _generate_annotations(
        self,
        risks: List[ContractRisk],
        recommendations: List[ContractRecommendation],
        suggested_changes: List[ContractSuggestedChange]
    ) -> List[ContractAnnotation]:
        """Generate annotations for document sections"""
        annotations = []

        for risk in risks:
            if risk.xpath_location:
                annotation = ContractAnnotation(
                    xpath_location=risk.xpath_location,
                    section_name=risk.section_name,
                    annotation_type='risk' if risk.severity == 'critical' else 'warning',
                    content=f"{risk.title}: {risk.description}",
                    highlight_color='red' if risk.severity == 'critical' else 'yellow'
                )
                annotations.append(annotation)

        for change in suggested_changes:
            if change.xpath_location:
                annotation = ContractAnnotation(
                    xpath_location=change.xpath_location,
                    section_name=change.section_name,
                    annotation_type='suggestion',
                    content=f"–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ: {change.issue}",
                    highlight_color='yellow'
                )
                annotations.append(annotation)

        return annotations

    def _predict_disputes(
        self,
        xml_content: str,
        risks: List[ContractRisk],
        rag_context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Predict dispute probability using LLM"""
        try:
            prompt = "Predict the probability of disputes arising from this contract.\n\n"

            prompt += "IDENTIFIED RISKS:\n"
            prompt += json.dumps([
                {'type': r.risk_type, 'severity': r.severity, 'title': r.title}
                for r in risks
            ], ensure_ascii=False, indent=2)
            prompt += "\n\n"

            if rag_context.get('context'):
                prompt += "PRECEDENTS:\n"
                prompt += rag_context['context'][:1500]
                prompt += "\n\n"

            prompt += """Analyze dispute probability.

Return JSON:
{
  "overall_score": 0-100,
  "level": "low|medium|high|critical",
  "reasoning": "Why this score",
  "dispute_prone_clauses": [
    {
      "clause": "Clause description",
      "reason": "Why disputes may arise",
      "probability": "low|medium|high"
    }
  ]
}

Return ONLY valid JSON."""

            response = self.llm.call(
                prompt=prompt,
                system_prompt=self.get_system_prompt(),
                response_format="json",
                temperature=0.3
            )

            return response if isinstance(response, dict) else json.loads(response)

        except Exception as e:
            logger.error(f"Dispute prediction failed: {e}")
            return {
                'overall_score': 50,
                'level': 'medium',
                'reasoning': 'Analysis failed',
                'dispute_prone_clauses': []
            }

    def _compare_with_templates(
        self, xml_content: str, contract_type: Optional[str]
    ) -> Dict[str, Any]:
        """Compare contract with templates"""
        if not contract_type:
            return {'compared': False, 'reason': 'No contract type specified'}

        try:
            template = self.template_manager.get_template(contract_type)

            if not template:
                return {'compared': False, 'reason': f'No template for type {contract_type}'}

            root = etree.fromstring(xml_content.encode('utf-8'))
            template_root = etree.fromstring(template.xml_content.encode('utf-8'))

            contract_tags = set([elem.tag for elem in root.iter()])
            template_tags = set([elem.tag for elem in template_root.iter()])

            missing_sections = template_tags - contract_tags
            extra_sections = contract_tags - template_tags

            return {
                'compared': True,
                'template_name': template.name,
                'template_version': template.version,
                'missing_sections': list(missing_sections),
                'extra_sections': list(extra_sections),
                'match_percentage': len(contract_tags & template_tags) / len(template_tags) * 100 if template_tags else 0
            }

        except Exception as e:
            logger.error(f"Template comparison failed: {e}")
            return {'compared': False, 'reason': str(e)}

    def _determine_next_action(
        self, risks: List[ContractRisk], dispute_prediction: Dict[str, Any]
    ) -> str:
        """Determine next action based on analysis results"""
        has_critical = any(r.severity == 'critical' for r in risks)
        high_dispute_risk = dispute_prediction.get('level') in ['high', 'critical']

        if has_critical or high_dispute_risk:
            return 'review_queue'

        return 'export'

    def _save_risks(self, analysis_id: str, contract_id: str, risks: List[ContractRisk]):
        """Save risks to database"""
        for risk in risks:
            risk.analysis_id = analysis_id
            risk.contract_id = contract_id
            self.db.add(risk)
        self.db.commit()

    def _save_recommendations(
        self, analysis_id: str, contract_id: str, recommendations: List[ContractRecommendation]
    ):
        """Save recommendations to database"""
        for rec in recommendations:
            rec.analysis_id = analysis_id
            rec.contract_id = contract_id
            self.db.add(rec)
        self.db.commit()

    def _save_suggested_changes(
        self, analysis_id: str, contract_id: str, changes: List[ContractSuggestedChange]
    ):
        """Save suggested changes to database"""
        for change in changes:
            change.analysis_id = analysis_id
            change.contract_id = contract_id
            self.db.add(change)
        self.db.commit()

    def _save_annotations(
        self, analysis_id: str, contract_id: str, annotations: List[ContractAnnotation]
    ):
        """Save annotations to database"""
        for annotation in annotations:
            annotation.analysis_id = analysis_id
            annotation.contract_id = contract_id
            self.db.add(annotation)
        self.db.commit()

    def _risk_to_dict(self, risk: ContractRisk) -> Dict[str, Any]:
        """Convert ContractRisk to dict"""
        return {
            'id': risk.id,
            'risk_type': risk.risk_type,
            'severity': risk.severity,
            'probability': risk.probability,
            'title': risk.title,
            'description': risk.description,
            'consequences': risk.consequences,
            'xpath_location': risk.xpath_location,
            'section_name': risk.section_name
        }

    def _recommendation_to_dict(self, rec: ContractRecommendation) -> Dict[str, Any]:
        """Convert ContractRecommendation to dict"""
        return {
            'id': rec.id,
            'category': rec.category,
            'priority': rec.priority,
            'title': rec.title,
            'description': rec.description,
            'reasoning': rec.reasoning,
            'expected_benefit': rec.expected_benefit,
            'implementation_complexity': rec.implementation_complexity
        }

    def _change_to_dict(self, change: ContractSuggestedChange) -> Dict[str, Any]:
        """Convert ContractSuggestedChange to dict"""
        return {
            'id': change.id,
            'xpath_location': change.xpath_location,
            'section_name': change.section_name,
            'original_text': change.original_text,
            'suggested_text': change.suggested_text,
            'change_type': change.change_type,
            'issue': change.issue,
            'reasoning': change.reasoning,
            'legal_basis': change.legal_basis,
            'status': change.status
        }

    def _annotation_to_dict(self, annotation: ContractAnnotation) -> Dict[str, Any]:
        """Convert ContractAnnotation to dict"""
        return {
            'id': annotation.id,
            'xpath_location': annotation.xpath_location,
            'section_name': annotation.section_name,
            'annotation_type': annotation.annotation_type,
            'content': annotation.content,
            'highlight_color': annotation.highlight_color
        }


__all__ = ["ContractAnalyzerAgent"]
